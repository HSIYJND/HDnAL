Epoch: 0, iteration: 0
Autoencoder Loss: 0.35566407442092896
Discriminator Loss: 0.7507803440093994
Generator Loss: 0.4954516291618347
1:6.822229738980634

Epoch: 5, iteration: 0
Autoencoder Loss: 0.005845572333782911
Discriminator Loss: 0.42712491750717163
Generator Loss: 1.068915605545044
1:15.184474953818505

Epoch: 10, iteration: 0
Autoencoder Loss: 0.004836080130189657
Discriminator Loss: 0.6802104711532593
Generator Loss: 0.6926429867744446
1:18.672995381193672

Epoch: 15, iteration: 0
Autoencoder Loss: 0.0021050444338470697
Discriminator Loss: 0.6352939009666443
Generator Loss: 1.3109866380691528
1:26.7433710136441

Epoch: 20, iteration: 0
Autoencoder Loss: 0.0017179579008370638
Discriminator Loss: 0.6651098728179932
Generator Loss: 1.543414831161499
1:29.066357253583178

Epoch: 25, iteration: 0
Autoencoder Loss: 0.0018474333919584751
Discriminator Loss: 0.7977479696273804
Generator Loss: 0.9284288883209229
1:28.921487700179895

Epoch: 30, iteration: 0
Autoencoder Loss: 0.0015102192992344499
Discriminator Loss: 0.7097764015197754
Generator Loss: 1.0731507539749146
1:29.696667383120825

Epoch: 35, iteration: 0
Autoencoder Loss: 0.0015015683602541685
Discriminator Loss: 0.711743950843811
Generator Loss: 0.8326401114463806
1:28.936755369275737

Epoch: 40, iteration: 0
Autoencoder Loss: 0.0013561216183006763
Discriminator Loss: 0.6779853105545044
Generator Loss: 0.9475792646408081
1:29.79532833229706

Epoch: 45, iteration: 0
Autoencoder Loss: 0.001471529365517199
Discriminator Loss: 0.6677933931350708
Generator Loss: 0.9217578172683716
1:28.731057325393156

Epoch: 50, iteration: 0
Autoencoder Loss: 0.0016390170203521848
Discriminator Loss: 0.6908411979675293
Generator Loss: 0.8111177682876587
1:29.51307834605473

Epoch: 55, iteration: 0
Autoencoder Loss: 0.0014050500467419624
Discriminator Loss: 0.649168848991394
Generator Loss: 0.8948042988777161
1:29.460007996836957

Epoch: 60, iteration: 0
Autoencoder Loss: 0.0014172312803566456
Discriminator Loss: 0.6682847142219543
Generator Loss: 0.7954238653182983
1:29.25864130859788

Epoch: 65, iteration: 0
Autoencoder Loss: 0.001354640698991716
Discriminator Loss: 0.681594967842102
Generator Loss: 0.7602962851524353
1:29.533123821865942

Epoch: 70, iteration: 0
Autoencoder Loss: 0.0012634365120902658
Discriminator Loss: 0.7364827394485474
Generator Loss: 0.712399959564209
1:29.842969831490407

Epoch: 75, iteration: 0
Autoencoder Loss: 0.001371663180179894
Discriminator Loss: 0.7445803880691528
Generator Loss: 0.6699277758598328
1:29.185780151483137

Epoch: 80, iteration: 0
Autoencoder Loss: 0.0014516826486214995
Discriminator Loss: 0.7293295860290527
Generator Loss: 0.701354444026947
1:29.99826958569372

Epoch: 85, iteration: 0
Autoencoder Loss: 0.0013035153970122337
Discriminator Loss: 0.6881072521209717
Generator Loss: 0.7997509837150574
1:29.753120099494037

Epoch: 90, iteration: 0
Autoencoder Loss: 0.0012130540562793612
Discriminator Loss: 0.7221378087997437
Generator Loss: 0.697501003742218
1:29.884175011148333

Epoch: 95, iteration: 0
Autoencoder Loss: 0.0013717238325625658
Discriminator Loss: 0.6969678401947021
Generator Loss: 0.7592343688011169
1:30.48176601990068

Epoch: 100, iteration: 0
Autoencoder Loss: 0.0013703418662771583
Discriminator Loss: 0.7182601690292358
Generator Loss: 0.7200954556465149
1:30.20905149529835

Epoch: 105, iteration: 0
Autoencoder Loss: 0.0013313178205862641
Discriminator Loss: 0.7238736152648926
Generator Loss: 0.7519301772117615
1:30.08010408449529

Epoch: 110, iteration: 0
Autoencoder Loss: 0.0012839182745665312
Discriminator Loss: 0.7356249690055847
Generator Loss: 0.7104899883270264
1:30.119180361846624

Epoch: 115, iteration: 0
Autoencoder Loss: 0.0012121773324906826
Discriminator Loss: 0.7415540218353271
Generator Loss: 0.6993677020072937
1:30.54907272797049

Epoch: 120, iteration: 0
Autoencoder Loss: 0.0013206807198002934
Discriminator Loss: 0.7464492321014404
Generator Loss: 0.7170374393463135
1:30.637276440575974

Epoch: 125, iteration: 0
Autoencoder Loss: 0.0012192120775580406
Discriminator Loss: 0.8266859650611877
Generator Loss: 0.5657957792282104
1:30.373891604333856

Epoch: 130, iteration: 0
Autoencoder Loss: 0.0012503807665780187
Discriminator Loss: 0.6922032833099365
Generator Loss: 0.8403046727180481
1:30.608523090976682

Epoch: 135, iteration: 0
Autoencoder Loss: 0.0012659806525334716
Discriminator Loss: 0.7167724370956421
Generator Loss: 0.7686850428581238
1:30.165677650020296

Epoch: 140, iteration: 0
Autoencoder Loss: 0.0011424128897488117
Discriminator Loss: 0.7137441635131836
Generator Loss: 0.7521098256111145
1:30.626084867357676

Epoch: 145, iteration: 0
Autoencoder Loss: 0.001305272220633924
Discriminator Loss: 0.7240461707115173
Generator Loss: 0.7270223498344421
1:30.587671243887677

Epoch: 150, iteration: 0
Autoencoder Loss: 0.001317838323302567
Discriminator Loss: 0.7876216173171997
Generator Loss: 0.6153432130813599
1:30.914617533084016

Epoch: 155, iteration: 0
Autoencoder Loss: 0.001193406991660595
Discriminator Loss: 0.7525116205215454
Generator Loss: 0.7672459483146667
1:31.820142210423455

Epoch: 160, iteration: 0
Autoencoder Loss: 0.0011772355064749718
Discriminator Loss: 0.7377645969390869
Generator Loss: 0.7053171396255493
1:31.161228017138903

Epoch: 165, iteration: 0
Autoencoder Loss: 0.001157152932137251
Discriminator Loss: 0.6714874505996704
Generator Loss: 0.7405098080635071
1:31.945362470171542

Epoch: 170, iteration: 0
Autoencoder Loss: 0.0011191071243956685
Discriminator Loss: 0.8064082860946655
Generator Loss: 0.5114104747772217
1:32.39521302927221

Epoch: 175, iteration: 0
Autoencoder Loss: 0.0012210373533889651
Discriminator Loss: 0.6988001465797424
Generator Loss: 0.8310820460319519
1:30.262569574410925

Epoch: 180, iteration: 0
Autoencoder Loss: 0.0012044807663187385
Discriminator Loss: 0.8208299875259399
Generator Loss: 0.6074891686439514
1:30.394028073126652

Epoch: 185, iteration: 0
Autoencoder Loss: 0.0012558243470266461
Discriminator Loss: 0.7342396378517151
Generator Loss: 0.6979444622993469
1:31.446871367200448

Epoch: 190, iteration: 0
Autoencoder Loss: 0.0012494955444708467
Discriminator Loss: 0.7761882543563843
Generator Loss: 0.6765601634979248
1:30.466663747933623

Epoch: 195, iteration: 0
Autoencoder Loss: 0.001187975169159472
Discriminator Loss: 0.7981233596801758
Generator Loss: 0.6766601800918579
1:30.794618656523916

Epoch: 200, iteration: 0
Autoencoder Loss: 0.0011057964293286204
Discriminator Loss: 0.8079006671905518
Generator Loss: 0.6357282996177673
1:31.447131286446922

Epoch: 205, iteration: 0
Autoencoder Loss: 0.0011468769516795874
Discriminator Loss: 0.7023630142211914
Generator Loss: 0.8016735315322876
1:30.171809776857952

Epoch: 210, iteration: 0
Autoencoder Loss: 0.0011285305954515934
Discriminator Loss: 0.7594583630561829
Generator Loss: 0.6078892350196838
1:30.601914763783885

Epoch: 215, iteration: 0
Autoencoder Loss: 0.001300691394135356
Discriminator Loss: 0.7571840286254883
Generator Loss: 0.6358903646469116
1:30.84890425748073

Epoch: 220, iteration: 0
Autoencoder Loss: 0.0011014215415343642
Discriminator Loss: 0.7293378114700317
Generator Loss: 0.6934189200401306
1:30.630388969366436

Epoch: 225, iteration: 0
Autoencoder Loss: 0.0011166867334395647
Discriminator Loss: 0.7719689607620239
Generator Loss: 0.6409340500831604
1:31.21378932448044

Epoch: 230, iteration: 0
Autoencoder Loss: 0.0010420590406283736
Discriminator Loss: 0.7357801198959351
Generator Loss: 0.7135612964630127
1:31.716668359045016

Epoch: 235, iteration: 0
Autoencoder Loss: 0.0011216180864721537
Discriminator Loss: 0.7529115676879883
Generator Loss: 0.6584098935127258
1:31.44356359562462

Epoch: 240, iteration: 0
Autoencoder Loss: 0.0010430257534608245
Discriminator Loss: 0.7851163148880005
Generator Loss: 0.5772063136100769
1:30.994017669169605

Epoch: 245, iteration: 0
Autoencoder Loss: 0.0011397599009796977
Discriminator Loss: 0.6525479555130005
Generator Loss: 0.8126947283744812
1:32.04157429346403

Epoch: 250, iteration: 0
Autoencoder Loss: 0.0012674358440563083
Discriminator Loss: 0.7705252170562744
Generator Loss: 0.6480886936187744
1:31.577156509581748

Epoch: 255, iteration: 0
Autoencoder Loss: 0.0012698756763711572
Discriminator Loss: 0.779276967048645
Generator Loss: 0.9167865514755249
1:30.61669304239563

Epoch: 260, iteration: 0
Autoencoder Loss: 0.0010524876415729523
Discriminator Loss: 0.8051405549049377
Generator Loss: 0.6937100291252136
1:31.347235803818446

Epoch: 265, iteration: 0
Autoencoder Loss: 0.001020976109430194
Discriminator Loss: 0.7394105195999146
Generator Loss: 0.6689762473106384
1:32.08237336024314

Epoch: 270, iteration: 0
Autoencoder Loss: 0.0010614634957164526
Discriminator Loss: 0.6797593832015991
Generator Loss: 0.6924923062324524
1:31.210225772515805

Epoch: 275, iteration: 0
Autoencoder Loss: 0.001103397342376411
Discriminator Loss: 0.7800213098526001
Generator Loss: 0.5493107438087463
1:31.654607460131857

Epoch: 280, iteration: 0
Autoencoder Loss: 0.0013846522197127342
Discriminator Loss: 0.7104766964912415
Generator Loss: 1.0630689859390259
1:30.94656504054963

Epoch: 285, iteration: 0
Autoencoder Loss: 0.0011961229611188173
Discriminator Loss: 0.8527103066444397
Generator Loss: 0.7348039150238037
1:31.395450258874867

Epoch: 290, iteration: 0
Autoencoder Loss: 0.00094373500905931
Discriminator Loss: 0.820758581161499
Generator Loss: 0.6098998785018921
1:32.153292506027064

Epoch: 295, iteration: 0
Autoencoder Loss: 0.0011279169702902436
Discriminator Loss: 0.7666144371032715
Generator Loss: 0.6512366533279419
1:30.715780408885553

Epoch: 300, iteration: 0
Autoencoder Loss: 0.000997281284071505
Discriminator Loss: 0.768440842628479
Generator Loss: 0.5597318410873413
1:31.96331442414399

Epoch: 305, iteration: 0
Autoencoder Loss: 0.0010558778885751963
Discriminator Loss: 0.6797677278518677
Generator Loss: 0.7676479816436768
1:31.160914239224628

Epoch: 310, iteration: 0
Autoencoder Loss: 0.0011478072265163064
Discriminator Loss: 0.7256708741188049
Generator Loss: 0.7731646299362183
1:30.614271030961554

Epoch: 315, iteration: 0
Autoencoder Loss: 0.0012375528458505869
Discriminator Loss: 0.7552915215492249
Generator Loss: 0.7679822444915771
1:31.131277590839307

Epoch: 320, iteration: 0
Autoencoder Loss: 0.000998333329334855
Discriminator Loss: 0.8040101528167725
Generator Loss: 0.6517300009727478
1:31.873671558428086

Epoch: 325, iteration: 0
Autoencoder Loss: 0.0009954479755833745
Discriminator Loss: 0.7335894107818604
Generator Loss: 0.6657861471176147
1:32.08782018607179

Epoch: 330, iteration: 0
Autoencoder Loss: 0.0010215082438662648
Discriminator Loss: 0.7372169494628906
Generator Loss: 0.6081315875053406
1:31.973206790648728

Epoch: 335, iteration: 0
Autoencoder Loss: 0.0010376659920439124
Discriminator Loss: 0.7791558504104614
Generator Loss: 0.5441761612892151
1:31.832156512638754

Epoch: 340, iteration: 0
Autoencoder Loss: 0.001125706941820681
Discriminator Loss: 0.6306414604187012
Generator Loss: 0.9916344285011292
1:30.84560124092512

Epoch: 345, iteration: 0
Autoencoder Loss: 0.00099289626814425
Discriminator Loss: 0.800042986869812
Generator Loss: 0.5628343820571899
1:31.559440971190767

Epoch: 350, iteration: 0
Autoencoder Loss: 0.001096697524189949
Discriminator Loss: 0.7443384528160095
Generator Loss: 0.7320007681846619
1:30.808262286588803

Epoch: 355, iteration: 0
Autoencoder Loss: 0.000992583460174501
Discriminator Loss: 0.772637665271759
Generator Loss: 0.6580643653869629
1:31.818013565715198

Epoch: 360, iteration: 0
Autoencoder Loss: 0.0010169908637180924
Discriminator Loss: 0.7117519378662109
Generator Loss: 0.7446146011352539
1:31.43607986604039

Epoch: 365, iteration: 0
Autoencoder Loss: 0.0009792814962565899
Discriminator Loss: 0.7307604551315308
Generator Loss: 0.5918657779693604
1:31.79097635972086

Epoch: 370, iteration: 0
Autoencoder Loss: 0.0008854081970639527
Discriminator Loss: 0.673629879951477
Generator Loss: 0.7487539052963257
1:30.88044419830895

Epoch: 375, iteration: 0
Autoencoder Loss: 0.0011813651071861386
Discriminator Loss: 0.8017006516456604
Generator Loss: 0.6708967089653015
1:32.06678548463837

Epoch: 380, iteration: 0
Autoencoder Loss: 0.0010333301033824682
Discriminator Loss: 0.8706027269363403
Generator Loss: 0.5652993321418762
1:31.02929971472935

Epoch: 385, iteration: 0
Autoencoder Loss: 0.0010121554369106889
Discriminator Loss: 0.786362886428833
Generator Loss: 0.6360361576080322
1:31.33674786898499

Epoch: 390, iteration: 0
Autoencoder Loss: 0.0009970027022063732
Discriminator Loss: 0.7297877073287964
Generator Loss: 0.6330832839012146
1:31.808485343901907

Epoch: 395, iteration: 0
Autoencoder Loss: 0.0009493543766438961
Discriminator Loss: 0.693811297416687
Generator Loss: 0.6430638432502747
1:31.87135653276104

Epoch: 400, iteration: 0
Autoencoder Loss: 0.0010017971508204937
Discriminator Loss: 0.7363081574440002
Generator Loss: 0.65288907289505
1:30.702629265614817

Epoch: 405, iteration: 0
Autoencoder Loss: 0.001102970913052559
Discriminator Loss: 0.7639860510826111
Generator Loss: 0.6748356223106384
1:31.98681924748863

Epoch: 410, iteration: 0
Autoencoder Loss: 0.0009520089952275157
Discriminator Loss: 0.7781986594200134
Generator Loss: 0.6002093553543091
1:31.39573815521355

Epoch: 415, iteration: 0
Autoencoder Loss: 0.001031115767545998
Discriminator Loss: 0.791359007358551
Generator Loss: 0.6106432676315308
1:31.05849979353723

Epoch: 420, iteration: 0
Autoencoder Loss: 0.0009249694412574172
Discriminator Loss: 0.7565004825592041
Generator Loss: 0.6763808727264404
1:30.690090136374838

Epoch: 425, iteration: 0
Autoencoder Loss: 0.0009895506082102656
Discriminator Loss: 0.7127780914306641
Generator Loss: 0.651861310005188
1:31.423172854545356

Epoch: 430, iteration: 0
Autoencoder Loss: 0.0009189543197862804
Discriminator Loss: 0.6622763872146606
Generator Loss: 0.7174289226531982
1:32.569187948825665

Epoch: 435, iteration: 0
Autoencoder Loss: 0.001022233860567212
Discriminator Loss: 0.7209891080856323
Generator Loss: 0.6415530443191528
1:31.71872308950568

Epoch: 440, iteration: 0
Autoencoder Loss: 0.001076310407370329
Discriminator Loss: 0.755339503288269
Generator Loss: 0.7405875325202942
1:31.47529952183381

Epoch: 445, iteration: 0
Autoencoder Loss: 0.0011022979160770774
Discriminator Loss: 0.8660532236099243
Generator Loss: 0.582402765750885
1:31.91827372414425

Epoch: 450, iteration: 0
Autoencoder Loss: 0.0009395194938406348
Discriminator Loss: 0.7718029022216797
Generator Loss: 0.6496570706367493
1:31.709389490744115

Epoch: 455, iteration: 0
Autoencoder Loss: 0.000927342043723911
Discriminator Loss: 0.7172791957855225
Generator Loss: 0.66672283411026
1:30.96137808098133

Epoch: 460, iteration: 0
Autoencoder Loss: 0.0009322194382548332
Discriminator Loss: 0.7063451409339905
Generator Loss: 0.6753577589988708
1:31.99586987822752

Epoch: 465, iteration: 0
Autoencoder Loss: 0.0011873869225382805
Discriminator Loss: 0.7456064224243164
Generator Loss: 0.7998692393302917
1:31.965517251590313

Epoch: 470, iteration: 0
Autoencoder Loss: 0.0011141059221699834
Discriminator Loss: 0.8011313080787659
Generator Loss: 0.7662889361381531
1:31.167575443377178

Epoch: 475, iteration: 0
Autoencoder Loss: 0.0008873228798620403
Discriminator Loss: 0.78849196434021
Generator Loss: 0.5986897945404053
1:32.19311190364709

Epoch: 480, iteration: 0
Autoencoder Loss: 0.0008213143446482718
Discriminator Loss: 0.6959458589553833
Generator Loss: 0.6798220276832581
1:31.652201815387823

Epoch: 485, iteration: 0
Autoencoder Loss: 0.0009328377200290561
Discriminator Loss: 0.7131084203720093
Generator Loss: 0.636432409286499
1:30.889398263078384

Epoch: 490, iteration: 0
Autoencoder Loss: 0.0010759152937680483
Discriminator Loss: 0.7520249485969543
Generator Loss: 0.6341200470924377
1:31.883525829347754

Epoch: 495, iteration: 0
Autoencoder Loss: 0.0011486571747809649
Discriminator Loss: 0.7660037875175476
Generator Loss: 0.7751420736312866
1:32.50711484593823

Epoch: 500, iteration: 0
Autoencoder Loss: 0.0009671533480286598
Discriminator Loss: 0.7944605350494385
Generator Loss: 0.7396445870399475
1:31.174309332667228

Epoch: 505, iteration: 0
Autoencoder Loss: 0.0008969914051704109
Discriminator Loss: 0.7618123292922974
Generator Loss: 0.6553512215614319
1:32.12650864301398

Epoch: 510, iteration: 0
Autoencoder Loss: 0.0008838720386847854
Discriminator Loss: 0.7173982858657837
Generator Loss: 0.5957849621772766
1:32.1265467786439

Epoch: 515, iteration: 0
Autoencoder Loss: 0.0008672971744090319
Discriminator Loss: 0.6806467771530151
Generator Loss: 0.6667812466621399
1:32.17126496112978

Epoch: 520, iteration: 0
Autoencoder Loss: 0.0010224416619166732
Discriminator Loss: 0.7307926416397095
Generator Loss: 0.6939425468444824
1:31.030481420743442

Epoch: 525, iteration: 0
Autoencoder Loss: 0.0011192962992936373
Discriminator Loss: 0.7795623540878296
Generator Loss: 0.770638644695282
1:31.604009920302975

Epoch: 530, iteration: 0
Autoencoder Loss: 0.0009215371683239937
Discriminator Loss: 0.806291937828064
Generator Loss: 0.6226423978805542
1:32.64842863896934

Epoch: 535, iteration: 0
Autoencoder Loss: 0.0008466601138934493
Discriminator Loss: 0.7341563105583191
Generator Loss: 0.6162397861480713
1:32.47911302117179

Epoch: 540, iteration: 0
Autoencoder Loss: 0.0008967936737462878
Discriminator Loss: 0.6849125623703003
Generator Loss: 0.7313174605369568
1:31.546093990558543

Epoch: 545, iteration: 0
Autoencoder Loss: 0.0009987480007112026
Discriminator Loss: 0.7366735935211182
Generator Loss: 0.6611608862876892
1:31.947620545035967

Epoch: 550, iteration: 0
Autoencoder Loss: 0.0009881285950541496
Discriminator Loss: 0.7271245121955872
Generator Loss: 0.7696095705032349
1:30.410130992589966

Epoch: 555, iteration: 0
Autoencoder Loss: 0.0008474112837575376
Discriminator Loss: 0.746322512626648
Generator Loss: 0.6658647060394287
1:32.40304081872568

Epoch: 560, iteration: 0
Autoencoder Loss: 0.0008338856277987361
Discriminator Loss: 0.6976921558380127
Generator Loss: 0.6416634321212769
1:32.70822668513355

Epoch: 565, iteration: 0
Autoencoder Loss: 0.0009352840716019273
Discriminator Loss: 0.6653410196304321
Generator Loss: 0.6639605760574341
1:31.909643387485552

Epoch: 570, iteration: 0
Autoencoder Loss: 0.0010221641277894378
Discriminator Loss: 0.7075445652008057
Generator Loss: 0.6760897040367126
1:31.993735337024958

Epoch: 575, iteration: 0
Autoencoder Loss: 0.000940517580602318
Discriminator Loss: 0.6640787124633789
Generator Loss: 0.8510810136795044
1:32.805588323183926

Epoch: 580, iteration: 0
Autoencoder Loss: 0.0009458927088417113
Discriminator Loss: 0.7164603471755981
Generator Loss: 0.7718479037284851
1:30.446075692629684

Epoch: 585, iteration: 0
Autoencoder Loss: 0.0008309856057167053
Discriminator Loss: 0.7542062997817993
Generator Loss: 0.6635050773620605
1:32.30702731133676

Epoch: 590, iteration: 0
Autoencoder Loss: 0.000858037848956883
Discriminator Loss: 0.7292659282684326
Generator Loss: 0.6012709140777588
1:31.848979478691113

Epoch: 595, iteration: 0
Autoencoder Loss: 0.0008411053568124771
Discriminator Loss: 0.7305862903594971
Generator Loss: 0.6255717873573303
1:32.26083785065669

Epoch: 600, iteration: 0
Autoencoder Loss: 0.0009737508953548968
Discriminator Loss: 0.7122244834899902
Generator Loss: 0.7140406966209412
1:30.779637458960657

Epoch: 605, iteration: 0
Autoencoder Loss: 0.0009302393882535398
Discriminator Loss: 0.8835920095443726
Generator Loss: 0.4627583622932434
1:32.429212422224154

Epoch: 610, iteration: 0
Autoencoder Loss: 0.0010415433207526803
Discriminator Loss: 0.8252345323562622
Generator Loss: 0.6926280856132507
1:31.048709611601343

Epoch: 615, iteration: 0
Autoencoder Loss: 0.0008322757203131914
Discriminator Loss: 0.8002829551696777
Generator Loss: 0.6527619361877441
1:32.207438171737515

Epoch: 620, iteration: 0
Autoencoder Loss: 0.0007968994905240834
Discriminator Loss: 0.6995107531547546
Generator Loss: 0.6849191784858704
1:32.23241082722912

Epoch: 625, iteration: 0
Autoencoder Loss: 0.0007936004549264908
Discriminator Loss: 0.7076433897018433
Generator Loss: 0.5747987031936646
1:32.70182655327716

Epoch: 630, iteration: 0
Autoencoder Loss: 0.0008181080920621753
Discriminator Loss: 0.6787018775939941
Generator Loss: 0.634945273399353
1:32.811430911749504

Epoch: 635, iteration: 0
Autoencoder Loss: 0.0009410013444721699
Discriminator Loss: 0.6489503979682922
Generator Loss: 0.8764209151268005
1:32.62707499163339

Epoch: 640, iteration: 0
Autoencoder Loss: 0.001284570898860693
Discriminator Loss: 0.7855219841003418
Generator Loss: 0.8651449084281921
1:31.165260724394056

Epoch: 645, iteration: 0
Autoencoder Loss: 0.0009342578705400229
Discriminator Loss: 0.7874102592468262
Generator Loss: 0.6465821862220764
1:32.262039399486376

Epoch: 650, iteration: 0
Autoencoder Loss: 0.0007597540970891714
Discriminator Loss: 0.7569669485092163
Generator Loss: 0.5974032878875732
1:31.296989647909243

Epoch: 655, iteration: 0
Autoencoder Loss: 0.0009250722359865904
Discriminator Loss: 0.6783798336982727
Generator Loss: 0.7312996983528137
1:32.24796502197672

Epoch: 660, iteration: 0
Autoencoder Loss: 0.0008926856680773199
Discriminator Loss: 0.7387286424636841
Generator Loss: 0.6087580323219299
1:31.83203457017005

Epoch: 665, iteration: 0
Autoencoder Loss: 0.0009869039058685303
Discriminator Loss: 0.691010594367981
Generator Loss: 0.7921792268753052
1:32.11607161710314

Epoch: 670, iteration: 0
Autoencoder Loss: 0.0009503043256700039
Discriminator Loss: 0.7548093795776367
Generator Loss: 0.81426602602005
1:30.991180676451336

Epoch: 675, iteration: 0
Autoencoder Loss: 0.0009521507890895009
Discriminator Loss: 0.7917088270187378
Generator Loss: 0.6709970235824585
1:31.672828561578434

Epoch: 680, iteration: 0
Autoencoder Loss: 0.0008262806804850698
Discriminator Loss: 0.727750301361084
Generator Loss: 0.6522728204727173
1:31.658244527411313

Epoch: 685, iteration: 0
Autoencoder Loss: 0.0008151093497872353
Discriminator Loss: 0.6636177897453308
Generator Loss: 0.6923467516899109
1:31.942899174000388

Epoch: 690, iteration: 0
Autoencoder Loss: 0.0009028991917148232
Discriminator Loss: 0.702887237071991
Generator Loss: 0.6327846050262451
1:31.377318819375365

Epoch: 695, iteration: 0
Autoencoder Loss: 0.002092782873660326
Discriminator Loss: 0.7665697932243347
Generator Loss: 0.8045361042022705
1:30.12354156904804

Epoch: 700, iteration: 0
Autoencoder Loss: 0.000899356440640986
Discriminator Loss: 0.8392133712768555
Generator Loss: 0.6385958790779114
1:32.25300144756085

Epoch: 705, iteration: 0
Autoencoder Loss: 0.0007961944211274385
Discriminator Loss: 0.7541587352752686
Generator Loss: 0.658592164516449
1:31.223403621638553

Epoch: 710, iteration: 0
Autoencoder Loss: 0.0007671070634387434
Discriminator Loss: 0.7330853939056396
Generator Loss: 0.5935497283935547
1:32.312526392770586

Epoch: 715, iteration: 0
Autoencoder Loss: 0.0008643041364848614
Discriminator Loss: 0.6987305283546448
Generator Loss: 0.6378791928291321
1:32.83235559928048

Epoch: 720, iteration: 0
Autoencoder Loss: 0.0008911244221962988
Discriminator Loss: 0.7740925550460815
Generator Loss: 0.6087914109230042
1:30.81743468792013

Epoch: 725, iteration: 0
Autoencoder Loss: 0.0009274104959331453
Discriminator Loss: 0.7784044742584229
Generator Loss: 0.7637659311294556
1:31.576521883248123

Epoch: 730, iteration: 0
Autoencoder Loss: 0.0009542828775011003
Discriminator Loss: 0.780152440071106
Generator Loss: 0.7274646759033203
1:31.709065319954032

Epoch: 735, iteration: 0
Autoencoder Loss: 0.0008052093326114118
Discriminator Loss: 0.7778277397155762
Generator Loss: 0.5849388837814331
1:31.950214457484847

Epoch: 740, iteration: 0
Autoencoder Loss: 0.0008448604494333267
Discriminator Loss: 0.7150710821151733
Generator Loss: 0.7041938304901123
1:32.36285472136896

Epoch: 745, iteration: 0
Autoencoder Loss: 0.0008325194357894361
Discriminator Loss: 0.6979265213012695
Generator Loss: 0.6814961433410645
1:32.436209347476456

Epoch: 750, iteration: 0
Autoencoder Loss: 0.000758141977712512
Discriminator Loss: 0.6999900341033936
Generator Loss: 0.6620664596557617
1:32.29115057768383

Epoch: 755, iteration: 0
Autoencoder Loss: 0.0008655368583276868
Discriminator Loss: 0.7014474868774414
Generator Loss: 0.6479483246803284
1:32.2046118065036

Epoch: 760, iteration: 0
Autoencoder Loss: 0.0011031203903257847
Discriminator Loss: 0.7235543727874756
Generator Loss: 0.7493504881858826
1:30.201024006025435

Epoch: 765, iteration: 0
Autoencoder Loss: 0.0010522453812882304
Discriminator Loss: 0.7893038988113403
Generator Loss: 0.834578812122345
1:32.15680165096088

Epoch: 770, iteration: 0
Autoencoder Loss: 0.0008112488430924714
Discriminator Loss: 0.8014672994613647
Generator Loss: 0.585655927658081
1:32.05378174008909

Epoch: 775, iteration: 0
Autoencoder Loss: 0.0008330409182235599
Discriminator Loss: 0.7301766872406006
Generator Loss: 0.6200113892555237
1:32.15018008413939

Epoch: 780, iteration: 0
Autoencoder Loss: 0.000810591911431402
Discriminator Loss: 0.7347561120986938
Generator Loss: 0.5920548439025879
1:31.56986222070104

Epoch: 785, iteration: 0
Autoencoder Loss: 0.0008996808319352567
Discriminator Loss: 0.6932065486907959
Generator Loss: 0.7931054830551147
1:30.8845618496194

Epoch: 790, iteration: 0
Autoencoder Loss: 0.0009625600650906563
Discriminator Loss: 0.7772361636161804
Generator Loss: 0.7437898516654968
1:32.23409133561993

Epoch: 795, iteration: 0
Autoencoder Loss: 0.0008119165431708097
Discriminator Loss: 0.7848008871078491
Generator Loss: 0.6174858808517456
1:32.80428070362044

Epoch: 800, iteration: 0
Autoencoder Loss: 0.000774471671320498
Discriminator Loss: 0.7360639572143555
Generator Loss: 0.6036764979362488
1:32.47917634157949

Epoch: 805, iteration: 0
Autoencoder Loss: 0.0007313161622732878
Discriminator Loss: 0.7117902040481567
Generator Loss: 0.609121561050415
1:32.638082110616374

Epoch: 810, iteration: 0
Autoencoder Loss: 0.0007370371604338288
Discriminator Loss: 0.6569441556930542
Generator Loss: 0.7327103018760681
1:32.33258322219025

Epoch: 815, iteration: 0
Autoencoder Loss: 0.005416182801127434
Discriminator Loss: 0.6666058301925659
Generator Loss: 1.1345107555389404
1:33.66344968553398

Epoch: 820, iteration: 0
Autoencoder Loss: 0.000972744426690042
Discriminator Loss: 0.8170509338378906
Generator Loss: 0.6255565285682678
1:32.13566919384823

Epoch: 825, iteration: 0
Autoencoder Loss: 0.000892672105692327
Discriminator Loss: 0.7483075261116028
Generator Loss: 0.6560297608375549
1:33.201475937816205

Epoch: 830, iteration: 0
Autoencoder Loss: 0.0008167743217200041
Discriminator Loss: 0.7324972152709961
Generator Loss: 0.6053188443183899
1:32.555000303688814

Epoch: 835, iteration: 0
Autoencoder Loss: 0.0008490033214911819
Discriminator Loss: 0.707162618637085
Generator Loss: 0.6163808703422546
1:32.64805071796878

Epoch: 840, iteration: 0
Autoencoder Loss: 0.0011699596652761102
Discriminator Loss: 0.6964995265007019
Generator Loss: 0.8391068577766418
1:30.409199086252933

Epoch: 845, iteration: 0
Autoencoder Loss: 0.0010838594753295183
Discriminator Loss: 0.8089678287506104
Generator Loss: 0.7770745754241943
1:31.959638717602353

Epoch: 850, iteration: 0
Autoencoder Loss: 0.0009932242101058364
Discriminator Loss: 0.7725749611854553
Generator Loss: 0.6287314891815186
1:32.27218593441946

Epoch: 855, iteration: 0
Autoencoder Loss: 0.0007901530480012298
Discriminator Loss: 0.691215455532074
Generator Loss: 0.659575343132019
1:31.577057902246466

Epoch: 860, iteration: 0
Autoencoder Loss: 0.0008735405281186104
Discriminator Loss: 0.7191603183746338
Generator Loss: 0.5595125555992126
1:31.967201480981622

Epoch: 865, iteration: 0
Autoencoder Loss: 0.0009124632924795151
Discriminator Loss: 0.7282959222793579
Generator Loss: 0.6200600862503052
1:31.356195479963276

Epoch: 870, iteration: 0
Autoencoder Loss: 0.001083714421838522
Discriminator Loss: 0.7250624299049377
Generator Loss: 0.8936833143234253
1:31.745556722405183

Epoch: 875, iteration: 0
Autoencoder Loss: 0.0008143412997014821
Discriminator Loss: 0.805005669593811
Generator Loss: 0.6207202672958374
1:31.72828185805015

Epoch: 880, iteration: 0
Autoencoder Loss: 0.000924822234082967
Discriminator Loss: 0.6982924938201904
Generator Loss: 0.7187576293945312
1:31.819881767950548

Epoch: 885, iteration: 0
Autoencoder Loss: 0.0008600042201578617
Discriminator Loss: 0.7206496000289917
Generator Loss: 0.6225119829177856
1:31.382106093922925

Epoch: 890, iteration: 0
Autoencoder Loss: 0.0009115308057516813
Discriminator Loss: 0.7302969098091125
Generator Loss: 0.6367588043212891
1:32.72339857964597

Epoch: 895, iteration: 0
Autoencoder Loss: 0.000987596227787435
Discriminator Loss: 0.6931787729263306
Generator Loss: 0.8699502348899841
1:31.899313902615496

Epoch: 900, iteration: 0
Autoencoder Loss: 0.0008231703541241586
Discriminator Loss: 0.7609845995903015
Generator Loss: 0.645844042301178
1:32.21077416877543

Epoch: 905, iteration: 0
Autoencoder Loss: 0.0008047649171203375
Discriminator Loss: 0.7738374471664429
Generator Loss: 0.6084495782852173
1:32.59654166076717

Epoch: 910, iteration: 0
Autoencoder Loss: 0.0009043741738423705
Discriminator Loss: 0.704488217830658
Generator Loss: 0.7542017698287964
1:32.2889751236208

Epoch: 915, iteration: 0
Autoencoder Loss: 0.000783592346124351
Discriminator Loss: 0.7167598009109497
Generator Loss: 0.613857090473175
1:32.516391603035274

Epoch: 920, iteration: 0
Autoencoder Loss: 0.0008707158849574625
Discriminator Loss: 0.7286500334739685
Generator Loss: 0.6066206693649292
1:31.07149652159164

Epoch: 925, iteration: 0
Autoencoder Loss: 0.0009844651212915778
Discriminator Loss: 0.7502597570419312
Generator Loss: 0.6843363046646118
1:32.676175906418365

Epoch: 930, iteration: 0
Autoencoder Loss: 0.0008326179813593626
Discriminator Loss: 0.7899253368377686
Generator Loss: 0.6668920516967773
1:32.67560863365563

Epoch: 935, iteration: 0
Autoencoder Loss: 0.0008100002305582166
Discriminator Loss: 0.8046704530715942
Generator Loss: 0.5811532139778137
1:32.72903982511457

Epoch: 940, iteration: 0
Autoencoder Loss: 0.0007857118616811931
Discriminator Loss: 0.7188301086425781
Generator Loss: 0.725299060344696
1:32.431832371282745

Epoch: 945, iteration: 0
Autoencoder Loss: 0.0008787155384197831
Discriminator Loss: 0.7559979557991028
Generator Loss: 0.6075556874275208
1:32.717502938194755

Epoch: 950, iteration: 0
Autoencoder Loss: 0.000859371037222445
Discriminator Loss: 0.7675579786300659
Generator Loss: 0.7043046355247498
1:32.18129417273071

Epoch: 955, iteration: 0
Autoencoder Loss: 0.0007665809243917465
Discriminator Loss: 0.7698782086372375
Generator Loss: 0.6292093396186829
1:31.677505292002884

Epoch: 960, iteration: 0
Autoencoder Loss: 0.0008259789319708943
Discriminator Loss: 0.6757677793502808
Generator Loss: 0.7662671804428101
1:31.72537222508457

Epoch: 965, iteration: 0
Autoencoder Loss: 0.0007818218437023461
Discriminator Loss: 0.710921049118042
Generator Loss: 0.5873269438743591
1:32.650249555869934

Epoch: 970, iteration: 0
Autoencoder Loss: 0.000802007969468832
Discriminator Loss: 0.647559642791748
Generator Loss: 0.7383648753166199
1:32.906485764264914

Epoch: 975, iteration: 0
Autoencoder Loss: 0.0012865082826465368
Discriminator Loss: 0.7965836524963379
Generator Loss: 0.7038021683692932
1:31.490979159755042

Epoch: 980, iteration: 0
Autoencoder Loss: 0.000893200805876404
Discriminator Loss: 0.8770062327384949
Generator Loss: 0.6603854298591614
1:32.60515482449749

Epoch: 985, iteration: 0
Autoencoder Loss: 0.0007575653144158423
Discriminator Loss: 0.7775701284408569
Generator Loss: 0.6235255599021912
1:32.61342225218803

Epoch: 990, iteration: 0
Autoencoder Loss: 0.0007832740084268153
Discriminator Loss: 0.6843340396881104
Generator Loss: 0.6911022067070007
1:33.093034995918195

Epoch: 995, iteration: 0
Autoencoder Loss: 0.0008336218306794763
Discriminator Loss: 0.687663197517395
Generator Loss: 0.6190123558044434
1:33.14463498544457

Epoch: 1000, iteration: 0
Autoencoder Loss: 0.0009944100165739655
Discriminator Loss: 0.7077956199645996
Generator Loss: 0.8141248226165771
1:30.36146146105777

Epoch: 1005, iteration: 0
Autoencoder Loss: 0.0010269585764035583
Discriminator Loss: 0.7667644023895264
Generator Loss: 0.8847162127494812
1:31.560566678456503

Epoch: 1010, iteration: 0
Autoencoder Loss: 0.0008716461015865207
Discriminator Loss: 0.797832727432251
Generator Loss: 0.6299923062324524
1:32.27220958481237

Epoch: 1015, iteration: 0
Autoencoder Loss: 0.0008115702657960355
Discriminator Loss: 0.7218519449234009
Generator Loss: 0.6449680328369141
1:32.552073437651586

Epoch: 1020, iteration: 0
Autoencoder Loss: 0.0007760372827760875
Discriminator Loss: 0.7553160190582275
Generator Loss: 0.532228410243988
1:33.56457249820171

Epoch: 1025, iteration: 0
Autoencoder Loss: 0.0007584918639622629
Discriminator Loss: 0.7486730813980103
Generator Loss: 0.572925865650177
1:32.313935350040175

Epoch: 1030, iteration: 0
Autoencoder Loss: 0.0009702532552182674
Discriminator Loss: 0.7990013360977173
Generator Loss: 0.591646671295166
1:31.789843036911435

Epoch: 1035, iteration: 0
Autoencoder Loss: 0.0009449922363273799
Discriminator Loss: 0.8216640949249268
Generator Loss: 0.6907933354377747
1:33.304907208128434

Epoch: 1040, iteration: 0
Autoencoder Loss: 0.0008267132216133177
Discriminator Loss: 0.7808424234390259
Generator Loss: 0.6582677364349365
1:32.31844789328777

Epoch: 1045, iteration: 0
Autoencoder Loss: 0.000755287182983011
Discriminator Loss: 0.724819004535675
Generator Loss: 0.6287679076194763
1:32.9060380648476

Epoch: 1050, iteration: 0
Autoencoder Loss: 0.0007072411244735122
Discriminator Loss: 0.6818068027496338
Generator Loss: 0.6112654209136963
1:32.970339186009106

Epoch: 1055, iteration: 0
Autoencoder Loss: 0.0007820557220838964
Discriminator Loss: 0.6778585910797119
Generator Loss: 0.6169641613960266
1:31.36837529942957

Epoch: 1060, iteration: 0
Autoencoder Loss: 0.0030464150477200747
Discriminator Loss: 0.6872787475585938
Generator Loss: 1.2492607831954956
1:28.208161455991018

Epoch: 1065, iteration: 0
Autoencoder Loss: 0.0009306283318437636
Discriminator Loss: 0.8603090643882751
Generator Loss: 0.6592727899551392
1:33.063514277916994

Epoch: 1070, iteration: 0
Autoencoder Loss: 0.0007889412227086723
Discriminator Loss: 0.774590253829956
Generator Loss: 0.6529032588005066
1:32.55571170691609

Epoch: 1075, iteration: 0
Autoencoder Loss: 0.0006988595123402774
Discriminator Loss: 0.7427243590354919
Generator Loss: 0.6019291281700134
1:31.83601888796452

Epoch: 1080, iteration: 0
Autoencoder Loss: 0.000787812692578882
Discriminator Loss: 0.7031784057617188
Generator Loss: 0.6125016808509827
1:32.34787279773289

Epoch: 1085, iteration: 0
Autoencoder Loss: 0.0009041837765835226
Discriminator Loss: 0.7467776536941528
Generator Loss: 0.5939040780067444
1:31.675013303764906

Epoch: 1090, iteration: 0
Autoencoder Loss: 0.0009491684031672776
Discriminator Loss: 0.7427788972854614
Generator Loss: 0.8652679920196533
1:31.24710871903798

Epoch: 1095, iteration: 0
Autoencoder Loss: 0.0007145271520130336
Discriminator Loss: 0.784197211265564
Generator Loss: 0.6389328241348267
1:32.584766495327536

Epoch: 1100, iteration: 0
Autoencoder Loss: 0.000814831058960408
Discriminator Loss: 0.7250247001647949
Generator Loss: 0.683154821395874
1:32.706563742624354

Epoch: 1105, iteration: 0
Autoencoder Loss: 0.0007773571414873004
Discriminator Loss: 0.7086690068244934
Generator Loss: 0.6536616683006287
1:32.28234514804696

Epoch: 1110, iteration: 0
Autoencoder Loss: 0.0007720497669652104
Discriminator Loss: 0.7145583629608154
Generator Loss: 0.6811710596084595
1:31.942201458774058

Epoch: 1115, iteration: 0
Autoencoder Loss: 0.0007222201093100011
Discriminator Loss: 0.7574583888053894
Generator Loss: 0.6179122924804688
1:31.734204735064463

Epoch: 1120, iteration: 0
Autoencoder Loss: 0.0007755309925414622
Discriminator Loss: 0.7180694341659546
Generator Loss: 0.7712202668190002
1:32.28346015834419

Epoch: 1125, iteration: 0
Autoencoder Loss: 0.0008062213310040534
Discriminator Loss: 0.7576830387115479
Generator Loss: 0.7059646844863892
1:32.7977087488289

Epoch: 1130, iteration: 0
Autoencoder Loss: 0.0007072356529533863
Discriminator Loss: 0.7490678429603577
Generator Loss: 0.6240692734718323
1:32.59881336454502

Epoch: 1135, iteration: 0
Autoencoder Loss: 0.0006695909542031586
Discriminator Loss: 0.6644455194473267
Generator Loss: 0.6853234171867371
1:32.5571544872746

Epoch: 1140, iteration: 0
Autoencoder Loss: 0.0007018277538008988
Discriminator Loss: 0.6726345419883728
Generator Loss: 0.5960071086883545
1:32.371859102711305

Epoch: 1145, iteration: 0
Autoencoder Loss: 0.0013038263423368335
Discriminator Loss: 0.6793617010116577
Generator Loss: 0.8542219996452332
1:31.199063241558363

Epoch: 1150, iteration: 0
Autoencoder Loss: 0.001120514003559947
Discriminator Loss: 0.8128221035003662
Generator Loss: 0.7989027500152588
1:32.32460055177966

Epoch: 1155, iteration: 0
Autoencoder Loss: 0.0008271221304312348
Discriminator Loss: 0.8142153024673462
Generator Loss: 0.6114360690116882
1:32.406139411805526

Epoch: 1160, iteration: 0
Autoencoder Loss: 0.0006670862785540521
Discriminator Loss: 0.7258459329605103
Generator Loss: 0.6676585078239441
1:32.40126980971884

Epoch: 1165, iteration: 0
Autoencoder Loss: 0.0008179308497346938
Discriminator Loss: 0.7746114730834961
Generator Loss: 0.5171570181846619
1:32.44574157756789

Epoch: 1170, iteration: 0
Autoencoder Loss: 0.001041095587424934
Discriminator Loss: 0.7623960971832275
Generator Loss: 0.676537036895752
1:31.945480346524995

Epoch: 1175, iteration: 0
Autoencoder Loss: 0.0008664007182233036
Discriminator Loss: 0.8402435183525085
Generator Loss: 0.6437593698501587
1:32.35629619059984

Epoch: 1180, iteration: 0
Autoencoder Loss: 0.0006568031967617571
Discriminator Loss: 0.7381531000137329
Generator Loss: 0.6660276055335999
1:32.28349438247222

Epoch: 1185, iteration: 0
Autoencoder Loss: 0.0006537135341204703
Discriminator Loss: 0.7008644342422485
Generator Loss: 0.6152910590171814
1:32.5456685175094

Epoch: 1190, iteration: 0
Autoencoder Loss: 0.000778100045863539
Discriminator Loss: 0.6620796918869019
Generator Loss: 0.6582382917404175
1:33.193777691999436

Epoch: 1195, iteration: 0
Autoencoder Loss: 0.0008218606235459447
Discriminator Loss: 0.6820777654647827
Generator Loss: 0.6915250420570374
1:31.830943533096864

Epoch: 1200, iteration: 0
Autoencoder Loss: 0.0012209713459014893
Discriminator Loss: 0.7286654710769653
Generator Loss: 0.911893904209137
1:31.462224144461008

Epoch: 1205, iteration: 0
Autoencoder Loss: 0.0008185564656741917
Discriminator Loss: 0.8224818706512451
Generator Loss: 0.6218394637107849
1:32.1773279053199

Epoch: 1210, iteration: 0
Autoencoder Loss: 0.000678821699693799
Discriminator Loss: 0.7273523211479187
Generator Loss: 0.6600097417831421
1:31.44118260064007

Epoch: 1215, iteration: 0
Autoencoder Loss: 0.0007284919847734272
Discriminator Loss: 0.7049261331558228
Generator Loss: 0.6437333822250366
1:31.591212629446623

Epoch: 1220, iteration: 0
Autoencoder Loss: 0.0007451873389072716
Discriminator Loss: 0.7303479909896851
Generator Loss: 0.5601544380187988
1:32.37687136885171

Epoch: 1225, iteration: 0
Autoencoder Loss: 0.000766106357332319
Discriminator Loss: 0.6610642671585083
Generator Loss: 0.7571014761924744
1:32.03689051036387

Epoch: 1230, iteration: 0
Autoencoder Loss: 0.0010277238907292485
Discriminator Loss: 0.7226939797401428
Generator Loss: 0.8699279427528381
1:30.93964025254693

Epoch: 1235, iteration: 0
Autoencoder Loss: 0.0008349766721948981
Discriminator Loss: 0.8479677438735962
Generator Loss: 0.6366962790489197
1:32.09517551026915

Epoch: 1240, iteration: 0
Autoencoder Loss: 0.0007356898859143257
Discriminator Loss: 0.7822880148887634
Generator Loss: 0.6104673743247986
1:31.63714710528314

Epoch: 1245, iteration: 0
Autoencoder Loss: 0.0006397534743882716
Discriminator Loss: 0.686042308807373
Generator Loss: 0.678287923336029
1:31.83598023029044

Epoch: 1250, iteration: 0
Autoencoder Loss: 0.0007461746572516859
Discriminator Loss: 0.7234088778495789
Generator Loss: 0.6924829483032227
1:32.51972681835936

Epoch: 1255, iteration: 0
Autoencoder Loss: 0.0008617546991445124
Discriminator Loss: 0.7512317895889282
Generator Loss: 0.8055113554000854
1:32.011025922753205

Epoch: 1260, iteration: 0
Autoencoder Loss: 0.0007761098677292466
Discriminator Loss: 0.8119568824768066
Generator Loss: 0.608044445514679
1:32.05694913903435

Epoch: 1265, iteration: 0
Autoencoder Loss: 0.0007674104999750853
Discriminator Loss: 0.7608854174613953
Generator Loss: 0.5939340591430664
1:32.6001442692382

Epoch: 1270, iteration: 0
Autoencoder Loss: 0.0007392216357402503
Discriminator Loss: 0.675557017326355
Generator Loss: 0.6876863241195679
1:32.08463223536057

Epoch: 1275, iteration: 0
Autoencoder Loss: 0.0008559416746720672
Discriminator Loss: 0.7485882043838501
Generator Loss: 0.6105877757072449
1:31.940812044056553

Epoch: 1280, iteration: 0
Autoencoder Loss: 0.000986115075647831
Discriminator Loss: 0.8215864896774292
Generator Loss: 0.7535173296928406
1:31.8082459011751

Epoch: 1285, iteration: 0
Autoencoder Loss: 0.000666952517349273
Discriminator Loss: 0.788784384727478
Generator Loss: 0.6699023246765137
1:32.24978482862666

Epoch: 1290, iteration: 0
Autoencoder Loss: 0.0006804686854593456
Discriminator Loss: 0.7224661111831665
Generator Loss: 0.597305953502655
1:32.617759779530886

Epoch: 1295, iteration: 0
Autoencoder Loss: 0.0007114710169844329
Discriminator Loss: 0.7139401435852051
Generator Loss: 0.6170896887779236
1:32.30164003121458

Epoch: 1300, iteration: 0
Autoencoder Loss: 0.0009538136073388159
Discriminator Loss: 0.7622167468070984
Generator Loss: 0.7219969630241394
1:31.538242404794126

Epoch: 1305, iteration: 0
Autoencoder Loss: 0.000708171573933214
Discriminator Loss: 0.8132427930831909
Generator Loss: 0.6665991544723511
1:31.836827864170367

Epoch: 1310, iteration: 0
Autoencoder Loss: 0.0005835675983689725
Discriminator Loss: 0.7406798601150513
Generator Loss: 0.6073434948921204
1:32.459521359743626

Epoch: 1315, iteration: 0
Autoencoder Loss: 0.000631579605396837
Discriminator Loss: 0.7091576457023621
Generator Loss: 0.5978311896324158
1:32.89463065129536

Epoch: 1320, iteration: 0
Autoencoder Loss: 0.000879535626154393
Discriminator Loss: 0.7528519630432129
Generator Loss: 0.5860648155212402
1:30.446270806539808

Epoch: 1325, iteration: 0
Autoencoder Loss: 0.0011444820556789637
Discriminator Loss: 0.7101186513900757
Generator Loss: 1.0546108484268188
1:30.91826784893791

Epoch: 1330, iteration: 0
Autoencoder Loss: 0.0006679251091554761
Discriminator Loss: 0.8102065920829773
Generator Loss: 0.6775047183036804
1:32.7006454945386

Epoch: 1335, iteration: 0
Autoencoder Loss: 0.0006611171411350369
Discriminator Loss: 0.7473492622375488
Generator Loss: 0.5999858975410461
1:33.30069123050197

Epoch: 1340, iteration: 0
Autoencoder Loss: 0.0006988037494011223
Discriminator Loss: 0.7185695171356201
Generator Loss: 0.6454746127128601
1:32.05026919079434

Epoch: 1345, iteration: 0
Autoencoder Loss: 0.000788918521720916
Discriminator Loss: 0.8328734636306763
Generator Loss: 0.48906826972961426
1:32.58911325186177

Epoch: 1350, iteration: 0
Autoencoder Loss: 0.0007004068465903401
Discriminator Loss: 0.7199062705039978
Generator Loss: 0.7182902693748474
1:32.79745647507147

Epoch: 1355, iteration: 0
Autoencoder Loss: 0.0007353377877734601
Discriminator Loss: 0.7153340578079224
Generator Loss: 0.6538413166999817
1:32.40993456132842

Epoch: 1360, iteration: 0
Autoencoder Loss: 0.000852801778819412
Discriminator Loss: 0.7225241661071777
Generator Loss: 0.7420939803123474
1:31.959615870518082

Epoch: 1365, iteration: 0
Autoencoder Loss: 0.0007600723765790462
Discriminator Loss: 0.8057193756103516
Generator Loss: 0.5462980270385742
1:33.7559478011996

Epoch: 1370, iteration: 0
Autoencoder Loss: 0.0007090843864716589
Discriminator Loss: 0.7101300954818726
Generator Loss: 0.7154351472854614
1:32.48451149384255

Epoch: 1375, iteration: 0
Autoencoder Loss: 0.0007412375998683274
Discriminator Loss: 0.6951618194580078
Generator Loss: 0.7184712290763855
1:33.10650390317178

Epoch: 1380, iteration: 0
Autoencoder Loss: 0.0007410157704725862
Discriminator Loss: 0.6801866292953491
Generator Loss: 0.7947657108306885
1:32.59981669364404

Epoch: 1385, iteration: 0
Autoencoder Loss: 0.0011798780178651214
Discriminator Loss: 0.7485437989234924
Generator Loss: 0.7842327356338501
1:33.34065516147654

Epoch: 1390, iteration: 0
Autoencoder Loss: 0.0009084852645173669
Discriminator Loss: 0.7903318405151367
Generator Loss: 0.7262641191482544
1:32.145605049350266

Epoch: 1395, iteration: 0
Autoencoder Loss: 0.0006377325626090169
Discriminator Loss: 0.7561036348342896
Generator Loss: 0.5892206430435181
1:33.74571596343784

Epoch: 1400, iteration: 0
Autoencoder Loss: 0.0006240194197744131
Discriminator Loss: 0.6788074970245361
Generator Loss: 0.6443386673927307
1:32.92830114980295

Epoch: 1405, iteration: 0
Autoencoder Loss: 0.0006421583238989115
Discriminator Loss: 0.7039839029312134
Generator Loss: 0.5484516024589539
1:33.42651153414288

Epoch: 1410, iteration: 0
Autoencoder Loss: 0.00248881452716887
Discriminator Loss: 0.6792968511581421
Generator Loss: 1.0029535293579102
1:27.49724392966752

Epoch: 1415, iteration: 0
Autoencoder Loss: 0.0008745393133722246
Discriminator Loss: 0.8134863376617432
Generator Loss: 0.7238706946372986
1:32.147681298045576

Epoch: 1420, iteration: 0
Autoencoder Loss: 0.0007039826014079154
Discriminator Loss: 0.7916442155838013
Generator Loss: 0.5654517412185669
1:33.23699489820779

Epoch: 1425, iteration: 0
Autoencoder Loss: 0.0006857544649392366
Discriminator Loss: 0.652249813079834
Generator Loss: 0.7548575401306152
1:32.84809607572198

Epoch: 1430, iteration: 0
Autoencoder Loss: 0.0007548612193204463
Discriminator Loss: 0.769851803779602
Generator Loss: 0.5038556456565857
1:33.47490713381801

Epoch: 1435, iteration: 0
Autoencoder Loss: 0.0008308902033604681
Discriminator Loss: 0.7773760557174683
Generator Loss: 0.6794477701187134
1:32.33793994657389

Epoch: 1440, iteration: 0
Autoencoder Loss: 0.0009364734287373722
Discriminator Loss: 0.7844041585922241
Generator Loss: 0.7524831295013428
1:32.88312826739313

Epoch: 1445, iteration: 0
Autoencoder Loss: 0.0008220183663070202
Discriminator Loss: 0.7542154788970947
Generator Loss: 0.6616470813751221
1:32.894701192777205

Epoch: 1450, iteration: 0
Autoencoder Loss: 0.0006591299897991121
Discriminator Loss: 0.6867514848709106
Generator Loss: 0.612464189529419
1:32.72908171194519

Epoch: 1455, iteration: 0
Autoencoder Loss: 0.0007838384481146932
Discriminator Loss: 0.6441301107406616
Generator Loss: 0.6978240013122559
1:32.3589968441989

Epoch: 1460, iteration: 0
Autoencoder Loss: 0.0009465391049161553
Discriminator Loss: 0.7721841335296631
Generator Loss: 0.6123729944229126
1:32.5569813338142

Epoch: 1465, iteration: 0
Autoencoder Loss: 0.0008240711176767945
Discriminator Loss: 0.8106223344802856
Generator Loss: 0.7098954916000366
1:33.61906140568945

Epoch: 1470, iteration: 0
Autoencoder Loss: 0.0007021151832304895
Discriminator Loss: 0.8054500818252563
Generator Loss: 0.5926672220230103
1:32.60965967052926

Epoch: 1475, iteration: 0
Autoencoder Loss: 0.0007215921068564057
Discriminator Loss: 0.7141133546829224
Generator Loss: 0.818953812122345
1:32.74338427303012

Epoch: 1480, iteration: 0
Autoencoder Loss: 0.0005895817885175347
Discriminator Loss: 0.745142936706543
Generator Loss: 0.6021714210510254
1:33.242911252447826

Epoch: 1485, iteration: 0
Autoencoder Loss: 0.000621542043518275
Discriminator Loss: 0.6986668109893799
Generator Loss: 0.6182445883750916
1:32.31019909087355

Epoch: 1490, iteration: 0
Autoencoder Loss: 0.0010133147006854415
Discriminator Loss: 0.6958512663841248
Generator Loss: 0.7595564723014832
1:30.833552668448863

Epoch: 1495, iteration: 0
Autoencoder Loss: 0.0009351618937216699
Discriminator Loss: 0.8136215806007385
Generator Loss: 0.7404399514198303
1:32.426209909714515

Epoch: 1500, iteration: 0
Autoencoder Loss: 0.0006399223930202425
Discriminator Loss: 0.8003511428833008
Generator Loss: 0.6509813666343689
1:33.46091508026332

Epoch: 1505, iteration: 0
Autoencoder Loss: 0.0006016347906552255
Discriminator Loss: 0.7225830554962158
Generator Loss: 0.6792165040969849
1:33.20254748032551

Epoch: 1510, iteration: 0
Autoencoder Loss: 0.0005793223972432315
Discriminator Loss: 0.7088518738746643
Generator Loss: 0.5684919953346252
1:33.33382598894828

Epoch: 1515, iteration: 0
Autoencoder Loss: 0.0005941131385043263
Discriminator Loss: 0.6130657196044922
Generator Loss: 0.6804991960525513
1:32.71368071751255

Epoch: 1520, iteration: 0
Autoencoder Loss: 0.0007477855542674661
Discriminator Loss: 0.6801480650901794
Generator Loss: 0.6398712396621704
1:32.70603272123691

Epoch: 1525, iteration: 0
Autoencoder Loss: 0.0011689295060932636
Discriminator Loss: 0.674168586730957
Generator Loss: 1.2044800519943237
1:32.3269891473715

Epoch: 1530, iteration: 0
Autoencoder Loss: 0.0006622476503252983
Discriminator Loss: 0.8079677820205688
Generator Loss: 0.6328287124633789
1:32.509055130435335

Epoch: 1535, iteration: 0
Autoencoder Loss: 0.0006073890835978091
Discriminator Loss: 0.7315733432769775
Generator Loss: 0.6717907190322876
1:32.932223097612415

Epoch: 1540, iteration: 0
Autoencoder Loss: 0.0005997376283630729
Discriminator Loss: 0.6979425549507141
Generator Loss: 0.5931034088134766
1:32.98770496534493

Epoch: 1545, iteration: 0
Autoencoder Loss: 0.0008426309213973582
Discriminator Loss: 0.709954023361206
Generator Loss: 0.6264404058456421
1:33.334945391387315

Epoch: 1550, iteration: 0
Autoencoder Loss: 0.0010863717179745436
Discriminator Loss: 0.7864632606506348
Generator Loss: 0.9248124957084656
1:32.924665248151264

Epoch: 1555, iteration: 0
Autoencoder Loss: 0.000639022677205503
Discriminator Loss: 0.8308546543121338
Generator Loss: 0.6683253645896912
1:33.07842406495181

Epoch: 1560, iteration: 0
Autoencoder Loss: 0.0006568226963281631
Discriminator Loss: 0.7530568242073059
Generator Loss: 0.6699944734573364
1:32.36986517283961

Epoch: 1565, iteration: 0
Autoencoder Loss: 0.0006182535435073078
Discriminator Loss: 0.7155826091766357
Generator Loss: 0.6590889692306519
1:32.4282357779393

Epoch: 1570, iteration: 0
Autoencoder Loss: 0.0006811286439187825
Discriminator Loss: 0.7114626169204712
Generator Loss: 0.6368715763092041
1:32.94513521253391

Epoch: 1575, iteration: 0
Autoencoder Loss: 0.0008939984836615622
Discriminator Loss: 0.7642182111740112
Generator Loss: 0.6173897981643677
1:31.818081640071163

Epoch: 1580, iteration: 0
Autoencoder Loss: 0.0007770605152472854
Discriminator Loss: 0.7255780696868896
Generator Loss: 0.8148629665374756
1:32.736414195011456

Epoch: 1585, iteration: 0
Autoencoder Loss: 0.0007330149528570473
Discriminator Loss: 0.7441936731338501
Generator Loss: 0.753459632396698
1:32.48076849315528

Epoch: 1590, iteration: 0
Autoencoder Loss: 0.0006327283917926252
Discriminator Loss: 0.7583290338516235
Generator Loss: 0.6212904453277588
1:32.24938110702774

Epoch: 1595, iteration: 0
Autoencoder Loss: 0.0006280814413912594
Discriminator Loss: 0.7443149089813232
Generator Loss: 0.5904362201690674
1:32.91101346534619

Epoch: 1600, iteration: 0
Autoencoder Loss: 0.0007104901596903801
Discriminator Loss: 0.6893693804740906
Generator Loss: 0.7371892929077148
1:32.25318793434451

Epoch: 1605, iteration: 0
Autoencoder Loss: 0.0008523458382114768
Discriminator Loss: 0.7660703659057617
Generator Loss: 0.7595996260643005
1:32.62203973455222

Epoch: 1610, iteration: 0
Autoencoder Loss: 0.0006481822347268462
Discriminator Loss: 0.7883349657058716
Generator Loss: 0.6211901307106018
1:33.42373022063828

Epoch: 1615, iteration: 0
Autoencoder Loss: 0.0006051433156244457
Discriminator Loss: 0.7513017654418945
Generator Loss: 0.5787256956100464
1:33.577148007213175

Epoch: 1620, iteration: 0
Autoencoder Loss: 0.000551077420823276
Discriminator Loss: 0.6640893220901489
Generator Loss: 0.7388215661048889
1:33.38049827818255

Epoch: 1625, iteration: 0
Autoencoder Loss: 0.000683406600728631
Discriminator Loss: 0.7455581426620483
Generator Loss: 0.5774958729743958
1:32.55526870583679

Epoch: 1630, iteration: 0
Autoencoder Loss: 0.0009822017746046185
Discriminator Loss: 0.6294988393783569
Generator Loss: 1.250969409942627
1:32.67371339026035

Epoch: 1635, iteration: 0
Autoencoder Loss: 0.0006541196489706635
Discriminator Loss: 0.7796229720115662
Generator Loss: 0.6020445227622986
1:33.52046369562509

Epoch: 1640, iteration: 0
Autoencoder Loss: 0.0006730775930918753
Discriminator Loss: 0.7306286692619324
Generator Loss: 0.6207783222198486
1:33.63637277264375

Epoch: 1645, iteration: 0
Autoencoder Loss: 0.0006175627931952477
Discriminator Loss: 0.7645587921142578
Generator Loss: 0.578491747379303
1:33.46228152682151

Epoch: 1650, iteration: 0
Autoencoder Loss: 0.0006019188440404832
Discriminator Loss: 0.7073144912719727
Generator Loss: 0.6538504362106323
1:33.52171054471226

Epoch: 1655, iteration: 0
Autoencoder Loss: 0.0006305479910224676
Discriminator Loss: 0.7172130942344666
Generator Loss: 0.5821313261985779
1:33.22990762227572

Epoch: 1660, iteration: 0
Autoencoder Loss: 0.0009460150031372905
Discriminator Loss: 0.6749686002731323
Generator Loss: 0.8114407062530518
1:32.459747424563396

Epoch: 1665, iteration: 0
Autoencoder Loss: 0.0008747888496145606
Discriminator Loss: 0.8383905291557312
Generator Loss: 0.6945454478263855
1:32.82007660501002

Epoch: 1670, iteration: 0
Autoencoder Loss: 0.0006597836618311703
Discriminator Loss: 0.7824151515960693
Generator Loss: 0.6563100218772888
1:32.88333534082326

Epoch: 1675, iteration: 0
Autoencoder Loss: 0.0005874948110431433
Discriminator Loss: 0.7247698307037354
Generator Loss: 0.6017379760742188
1:33.24640397074541

Epoch: 1680, iteration: 0
Autoencoder Loss: 0.0006745726568624377
Discriminator Loss: 0.6900891661643982
Generator Loss: 0.6626672148704529
1:31.810519410053416

Epoch: 1685, iteration: 0
Autoencoder Loss: 0.0007683211588300765
Discriminator Loss: 0.7632654905319214
Generator Loss: 0.6453931927680969
1:32.97754096309413

Epoch: 1690, iteration: 0
Autoencoder Loss: 0.000762582232709974
Discriminator Loss: 0.7477798461914062
Generator Loss: 0.78855961561203
1:34.07374155820682

Epoch: 1695, iteration: 0
Autoencoder Loss: 0.0005900732357986271
Discriminator Loss: 0.769567608833313
Generator Loss: 0.6436816453933716
1:33.174314200400396

Epoch: 1700, iteration: 0
Autoencoder Loss: 0.0006970434915274382
Discriminator Loss: 0.7737951278686523
Generator Loss: 0.6129353046417236
1:31.891550089106243

Epoch: 1705, iteration: 0
Autoencoder Loss: 0.0005687801749445498
Discriminator Loss: 0.7569866180419922
Generator Loss: 0.5802185535430908
1:33.166165427221294

Epoch: 1710, iteration: 0
Autoencoder Loss: 0.0006328450399450958
Discriminator Loss: 0.7093350887298584
Generator Loss: 0.6639050245285034
1:33.1323616545985

Epoch: 1715, iteration: 0
Autoencoder Loss: 0.0007083412492647767
Discriminator Loss: 0.7900758981704712
Generator Loss: 0.6546902060508728
1:31.725046394174782

Epoch: 1720, iteration: 0
Autoencoder Loss: 0.0008478706004098058
Discriminator Loss: 0.8271512985229492
Generator Loss: 0.6937592029571533
1:33.012420335320925

Epoch: 1725, iteration: 0
Autoencoder Loss: 0.0005350289866328239
Discriminator Loss: 0.7474639415740967
Generator Loss: 0.6292532086372375
1:33.43515025354727

Epoch: 1730, iteration: 0
Autoencoder Loss: 0.0006056781858205795
Discriminator Loss: 0.6945632696151733
Generator Loss: 0.6567487716674805
1:33.22372574933976

Epoch: 1735, iteration: 0
Autoencoder Loss: 0.0005974049563519657
Discriminator Loss: 0.7066308259963989
Generator Loss: 0.6253471970558167
1:33.158050934877615

Epoch: 1740, iteration: 0
Autoencoder Loss: 0.0008767586550675333
Discriminator Loss: 0.727086067199707
Generator Loss: 0.8196510672569275
1:32.313611978345676

Epoch: 1745, iteration: 0
Autoencoder Loss: 0.0007611834444105625
Discriminator Loss: 0.7914267778396606
Generator Loss: 0.6814125776290894
1:33.04596445904954

Epoch: 1750, iteration: 0
Autoencoder Loss: 0.0005700672627426684
Discriminator Loss: 0.7113720178604126
Generator Loss: 0.6797565817832947
1:33.37492378885592

Epoch: 1755, iteration: 0
Autoencoder Loss: 0.0006981189944781363
Discriminator Loss: 0.734549880027771
Generator Loss: 0.5894928574562073
1:33.6696183188822

Epoch: 1760, iteration: 0
Autoencoder Loss: 0.0007005402003414929
Discriminator Loss: 0.7483674883842468
Generator Loss: 0.6888296008110046
1:32.692918142792664

Epoch: 1765, iteration: 0
Autoencoder Loss: 0.0006608273833990097
Discriminator Loss: 0.7555855512619019
Generator Loss: 0.7770352959632874
1:32.51156331979958

Epoch: 1770, iteration: 0
Autoencoder Loss: 0.0005755340098403394
Discriminator Loss: 0.7348394393920898
Generator Loss: 0.6194333434104919
1:32.637750442401

Epoch: 1775, iteration: 0
Autoencoder Loss: 0.0005990798235870898
Discriminator Loss: 0.6977219581604004
Generator Loss: 0.6026277542114258
1:33.68274177286695

Epoch: 1780, iteration: 0
Autoencoder Loss: 0.0008572485530748963
Discriminator Loss: 0.7835689783096313
Generator Loss: 0.6792658567428589
1:32.65340446423928

Epoch: 1785, iteration: 0
Autoencoder Loss: 0.0008724589133635163
Discriminator Loss: 0.884335994720459
Generator Loss: 0.7008775472640991
1:33.46196491899258

Epoch: 1790, iteration: 0
Autoencoder Loss: 0.0006022119196131825
Discriminator Loss: 0.7886174917221069
Generator Loss: 0.66033935546875
1:33.359716617521755

Epoch: 1795, iteration: 0
Autoencoder Loss: 0.0005252538830973208
Discriminator Loss: 0.7139146327972412
Generator Loss: 0.6133482456207275
1:33.46479005970031

Epoch: 1800, iteration: 0
Autoencoder Loss: 0.0005659501766785979
Discriminator Loss: 0.6727485656738281
Generator Loss: 0.6221852898597717
1:33.507399273198935

Epoch: 1805, iteration: 0
Autoencoder Loss: 0.0007008582470007241
Discriminator Loss: 0.6750118136405945
Generator Loss: 0.6437715888023376
1:33.07626327546852

Epoch: 1810, iteration: 0
Autoencoder Loss: 0.0012400103732943535
Discriminator Loss: 0.6827635169029236
Generator Loss: 1.456589937210083
1:30.65751257923401

Epoch: 1815, iteration: 0
Autoencoder Loss: 0.0007767585339024663
Discriminator Loss: 0.867938756942749
Generator Loss: 0.6657727956771851
1:33.79901897621447

Epoch: 1820, iteration: 0
Autoencoder Loss: 0.0006391519564203918
Discriminator Loss: 0.7784063220024109
Generator Loss: 0.6174692511558533
1:33.68661840195172

Epoch: 1825, iteration: 0
Autoencoder Loss: 0.0005916707450523973
Discriminator Loss: 0.728058397769928
Generator Loss: 0.592056393623352
1:33.12778120466409

Epoch: 1830, iteration: 0
Autoencoder Loss: 0.00059638632228598
Discriminator Loss: 0.6861871480941772
Generator Loss: 0.6334801316261292
1:33.25649947164798

Epoch: 1835, iteration: 0
Autoencoder Loss: 0.0005485916044563055
Discriminator Loss: 0.7281558513641357
Generator Loss: 0.6165577173233032
1:33.078288443133744

Epoch: 1840, iteration: 0
Autoencoder Loss: 0.0008007858414202929
Discriminator Loss: 0.7837558388710022
Generator Loss: 0.6861883997917175
1:31.85664254740473

Epoch: 1845, iteration: 0
Autoencoder Loss: 0.000812428304925561
Discriminator Loss: 0.7688921689987183
Generator Loss: 0.7778018116950989
1:32.23797251357063

Epoch: 1850, iteration: 0
Autoencoder Loss: 0.0005554708768613636
Discriminator Loss: 0.7547594904899597
Generator Loss: 0.6274387240409851
1:33.32300618219338

Epoch: 1855, iteration: 0
Autoencoder Loss: 0.0006467966013588011
Discriminator Loss: 0.6951913833618164
Generator Loss: 0.662582278251648
1:33.34127745830746

Epoch: 1860, iteration: 0
Autoencoder Loss: 0.000679564371239394
Discriminator Loss: 0.7265195846557617
Generator Loss: 0.6521950364112854
1:33.34468103131788

Epoch: 1865, iteration: 0
Autoencoder Loss: 0.0005884227575734258
Discriminator Loss: 0.722308874130249
Generator Loss: 0.7036585211753845
1:32.97106091273455

Epoch: 1870, iteration: 0
Autoencoder Loss: 0.0005062949494458735
Discriminator Loss: 0.738540768623352
Generator Loss: 0.5878596901893616
1:33.405283888026844

Epoch: 1875, iteration: 0
Autoencoder Loss: 0.0005945036537013948
Discriminator Loss: 0.698641300201416
Generator Loss: 0.6430699825286865
1:32.37959142771219

Epoch: 1880, iteration: 0
Autoencoder Loss: 0.0008656040299683809
Discriminator Loss: 0.6903774738311768
Generator Loss: 0.8482160568237305
1:32.70743321564603

Epoch: 1885, iteration: 0
Autoencoder Loss: 0.0007127663120627403
Discriminator Loss: 0.8152492046356201
Generator Loss: 0.6625650525093079
1:32.62215153583999

Epoch: 1890, iteration: 0
Autoencoder Loss: 0.000590005423873663
Discriminator Loss: 0.7623168230056763
Generator Loss: 0.6014159917831421
1:33.24643165071527

Epoch: 1895, iteration: 0
Autoencoder Loss: 0.0005736465100198984
Discriminator Loss: 0.6711835861206055
Generator Loss: 0.7500560879707336
1:33.33747825018974

Epoch: 1900, iteration: 0
Autoencoder Loss: 0.0006102255429141223
Discriminator Loss: 0.7252990007400513
Generator Loss: 0.5936769843101501
1:32.64081412709436

Epoch: 1905, iteration: 0
Autoencoder Loss: 0.0007776618585921824
Discriminator Loss: 0.7559771537780762
Generator Loss: 0.6842626333236694
1:32.85099334097393

Epoch: 1910, iteration: 0
Autoencoder Loss: 0.0006261085509322584
Discriminator Loss: 0.7612249255180359
Generator Loss: 0.7086313962936401
1:32.56834391316207

Epoch: 1915, iteration: 0
Autoencoder Loss: 0.0005899780662730336
Discriminator Loss: 0.7363401651382446
Generator Loss: 0.6286266446113586
1:32.647778656305235

Epoch: 1920, iteration: 0
Autoencoder Loss: 0.0006140344776213169
Discriminator Loss: 0.6822916269302368
Generator Loss: 0.7193474769592285
1:33.275043053905705

Epoch: 1925, iteration: 0
Autoencoder Loss: 0.0005675277789123356
Discriminator Loss: 0.696115255355835
Generator Loss: 0.698368489742279
1:33.130070772625764

Epoch: 1930, iteration: 0
Autoencoder Loss: 0.0006032328819856048
Discriminator Loss: 0.7130796909332275
Generator Loss: 0.6717221736907959
1:32.341541999175746

Epoch: 1935, iteration: 0
Autoencoder Loss: 0.0007065733661875129
Discriminator Loss: 0.729851245880127
Generator Loss: 0.7828307747840881
1:32.18050714285776

Epoch: 1940, iteration: 0
Autoencoder Loss: 0.0005487239686772227
Discriminator Loss: 0.780874490737915
Generator Loss: 0.608479380607605
1:33.485338886504444

Epoch: 1945, iteration: 0
Autoencoder Loss: 0.0004695176030509174
Discriminator Loss: 0.7209410667419434
Generator Loss: 0.6304987668991089
1:32.888027959596954

Epoch: 1950, iteration: 0
Autoencoder Loss: 0.0005169069045223296
Discriminator Loss: 0.6701090335845947
Generator Loss: 0.6507337689399719
1:32.67331032921577

Epoch: 1955, iteration: 0
Autoencoder Loss: 0.0007014864240773022
Discriminator Loss: 0.6234541535377502
Generator Loss: 0.8264034986495972
1:33.24405967493482

Epoch: 1960, iteration: 0
Autoencoder Loss: 0.0010155272902920842
Discriminator Loss: 0.7380431890487671
Generator Loss: 0.9217360615730286
1:31.756807889736255

Epoch: 1965, iteration: 0
Autoencoder Loss: 0.0005528073525056243
Discriminator Loss: 0.8073227405548096
Generator Loss: 0.639082670211792
1:33.26348444724154

Epoch: 1970, iteration: 0
Autoencoder Loss: 0.00045053684152662754
Discriminator Loss: 0.7157770991325378
Generator Loss: 0.6456003785133362
1:32.746697659213986

Epoch: 1975, iteration: 0
Autoencoder Loss: 0.0005188867799006402
Discriminator Loss: 0.6768307089805603
Generator Loss: 0.6370530128479004
1:32.842179435923846

Epoch: 1980, iteration: 0
Autoencoder Loss: 0.0006124629289843142
Discriminator Loss: 0.6359802484512329
Generator Loss: 0.7617862224578857
1:32.083805494555634

Epoch: 1985, iteration: 0
Autoencoder Loss: 0.0011261184699833393
Discriminator Loss: 0.7444581985473633
Generator Loss: 1.0510358810424805
1:31.65738648539048

Epoch: 1990, iteration: 0
Autoencoder Loss: 0.0006614984595216811
Discriminator Loss: 0.8078775405883789
Generator Loss: 0.6450279951095581
1:32.9621522158485

Epoch: 1995, iteration: 0
Autoencoder Loss: 0.0005716604646295309
Discriminator Loss: 0.726391077041626
Generator Loss: 0.6324729323387146
1:33.02039818054703

Epoch: 2000, iteration: 0
Autoencoder Loss: 0.0005501867271959782
Discriminator Loss: 0.7020134925842285
Generator Loss: 0.6014559864997864
1:33.78284935019546

Epoch: 2005, iteration: 0
Autoencoder Loss: 0.0007168110460042953
Discriminator Loss: 0.6850490570068359
Generator Loss: 0.691134512424469
1:32.25291968772659

Epoch: 2010, iteration: 0
Autoencoder Loss: 0.0009459397988393903
Discriminator Loss: 0.7293336987495422
Generator Loss: 0.9206947088241577
1:31.709007523528875

Epoch: 2015, iteration: 0
Autoencoder Loss: 0.0006293359911069274
Discriminator Loss: 0.8005426526069641
Generator Loss: 0.6534801125526428
1:33.1293302397305

Epoch: 2020, iteration: 0
Autoencoder Loss: 0.000504454190377146
Discriminator Loss: 0.7572283744812012
Generator Loss: 0.6433073282241821
1:32.85578327629772

Epoch: 2025, iteration: 0
Autoencoder Loss: 0.0004942151717841625
Discriminator Loss: 0.7142797708511353
Generator Loss: 0.6506931781768799
1:32.62762868310721

Epoch: 2030, iteration: 0
Autoencoder Loss: 0.0004828789096791297
Discriminator Loss: 0.708652138710022
Generator Loss: 0.5929810404777527
1:32.630697238207944

Epoch: 2035, iteration: 0
Autoencoder Loss: 0.0006763349520042539
Discriminator Loss: 0.7188419103622437
Generator Loss: 0.6658958792686462
1:32.792144576803835

Epoch: 2040, iteration: 0
Autoencoder Loss: 0.0007851762929931283
Discriminator Loss: 0.7619364261627197
Generator Loss: 0.8575783967971802
1:32.9005870869682

Epoch: 2045, iteration: 0
Autoencoder Loss: 0.0005389412981458008
Discriminator Loss: 0.7795517444610596
Generator Loss: 0.6371727585792542
1:33.1560493396271

Epoch: 2050, iteration: 0
Autoencoder Loss: 0.00046098316670395434
Discriminator Loss: 0.7184867262840271
Generator Loss: 0.614854097366333
1:32.428441880872406

Epoch: 2055, iteration: 0
Autoencoder Loss: 0.0006940714665688574
Discriminator Loss: 0.6913563013076782
Generator Loss: 0.6260653734207153
1:32.92227836978916

Epoch: 2060, iteration: 0
Autoencoder Loss: 0.0007066202815622091
Discriminator Loss: 0.7892742156982422
Generator Loss: 0.5547002553939819
1:32.68739426681324

Epoch: 2065, iteration: 0
Autoencoder Loss: 0.0006260491209104657
Discriminator Loss: 0.7475420236587524
Generator Loss: 0.7582994103431702
1:33.30922866164708

Epoch: 2070, iteration: 0
Autoencoder Loss: 0.0005652523832395673
Discriminator Loss: 0.7444014549255371
Generator Loss: 0.696988582611084
1:32.562246422995386

Epoch: 2075, iteration: 0
Autoencoder Loss: 0.0004857366729993373
Discriminator Loss: 0.7100231647491455
Generator Loss: 0.5941370725631714
1:32.80214372642619

Epoch: 2080, iteration: 0
Autoencoder Loss: 0.0005197931313887239
Discriminator Loss: 0.6467736959457397
Generator Loss: 0.687164306640625
1:32.552029856582216

Epoch: 2085, iteration: 0
Autoencoder Loss: 0.0007170002209022641
Discriminator Loss: 0.7749290466308594
Generator Loss: 0.5612142086029053
1:33.675773459472836

Epoch: 2090, iteration: 0
Autoencoder Loss: 0.0007447983953170478
Discriminator Loss: 0.7401863932609558
Generator Loss: 0.9202935099601746
1:33.39438309309172

Epoch: 2095, iteration: 0
Autoencoder Loss: 0.0005671716062352061
Discriminator Loss: 0.7861960530281067
Generator Loss: 0.6354896426200867
1:33.08151770443262

Epoch: 2100, iteration: 0
Autoencoder Loss: 0.0006256369524635375
Discriminator Loss: 0.7195034027099609
Generator Loss: 0.6520653367042542
1:33.239145138363256

Epoch: 2105, iteration: 0
Autoencoder Loss: 0.0006207286496646702
Discriminator Loss: 0.7526319026947021
Generator Loss: 0.6372024416923523
1:32.16855561713635

Epoch: 2110, iteration: 0
Autoencoder Loss: 0.00061218993505463
Discriminator Loss: 0.7283408641815186
Generator Loss: 0.6743570566177368
1:33.5255216132205

Epoch: 2115, iteration: 0
Autoencoder Loss: 0.0005136143299750984
Discriminator Loss: 0.722756028175354
Generator Loss: 0.6024187207221985
1:32.91806533465912

Epoch: 2120, iteration: 0
Autoencoder Loss: 0.000615395896602422
Discriminator Loss: 0.6380090713500977
Generator Loss: 0.7740943431854248
1:32.68756960287688

Epoch: 2125, iteration: 0
Autoencoder Loss: 0.0008993699448183179
Discriminator Loss: 0.7125198841094971
Generator Loss: 0.841683030128479
1:32.238677624941104

Epoch: 2130, iteration: 0
Autoencoder Loss: 0.0006151514244265854
Discriminator Loss: 0.7938185930252075
Generator Loss: 0.616335928440094
1:32.99865416650733

Epoch: 2135, iteration: 0
Autoencoder Loss: 0.0005459540407173336
Discriminator Loss: 0.7313410639762878
Generator Loss: 0.6532902717590332
1:32.93198091261738

Epoch: 2140, iteration: 0
Autoencoder Loss: 0.0004992146859876812
Discriminator Loss: 0.6999310255050659
Generator Loss: 0.6451635956764221
1:32.384743224250926

Epoch: 2145, iteration: 0
Autoencoder Loss: 0.0006698816432617605
Discriminator Loss: 0.779711127281189
Generator Loss: 0.5132019519805908
1:31.58419862762961

Epoch: 2150, iteration: 0
Autoencoder Loss: 0.0007972880266606808
Discriminator Loss: 0.7404191493988037
Generator Loss: 0.6850705742835999
1:33.406022054757216

Epoch: 2155, iteration: 0
Autoencoder Loss: 0.0006727740401402116
Discriminator Loss: 0.7206764221191406
Generator Loss: 0.8034403324127197
1:32.26456409009325

Epoch: 2160, iteration: 0
Autoencoder Loss: 0.0005592720699496567
Discriminator Loss: 0.7597132325172424
Generator Loss: 0.6969584822654724
1:32.691472775855416

Epoch: 2165, iteration: 0
Autoencoder Loss: 0.0005218477454036474
Discriminator Loss: 0.7147069573402405
Generator Loss: 0.6703673005104065
1:32.73083731218698

Epoch: 2170, iteration: 0
Autoencoder Loss: 0.00046572982682846487
Discriminator Loss: 0.7017545700073242
Generator Loss: 0.6124940514564514
1:33.05585562765228

Epoch: 2175, iteration: 0
Autoencoder Loss: 0.0007790339877828956
Discriminator Loss: 0.6934934854507446
Generator Loss: 0.7341393232345581
1:32.6645607290522

Epoch: 2180, iteration: 0
Autoencoder Loss: 0.0007472942816093564
Discriminator Loss: 0.7756489515304565
Generator Loss: 0.8423491716384888
1:31.92151794978789

Epoch: 2185, iteration: 0
Autoencoder Loss: 0.0005663490737788379
Discriminator Loss: 0.7921872138977051
Generator Loss: 0.6486688256263733
1:32.91325656535018

Epoch: 2190, iteration: 0
Autoencoder Loss: 0.0005092044011689723
Discriminator Loss: 0.7388571500778198
Generator Loss: 0.6286416053771973
1:32.88845417850165

Epoch: 2195, iteration: 0
Autoencoder Loss: 0.0005230166134424508
Discriminator Loss: 0.7260411977767944
Generator Loss: 0.608033299446106
1:33.437946200055585

Epoch: 2200, iteration: 0
Autoencoder Loss: 0.0005113009246997535
Discriminator Loss: 0.719190239906311
Generator Loss: 0.6478509902954102
1:32.05680232339939

Epoch: 2205, iteration: 0
Autoencoder Loss: 0.0006019928259775043
Discriminator Loss: 0.6915068626403809
Generator Loss: 0.7365302443504333
1:32.51759040720604

Epoch: 2210, iteration: 0
Autoencoder Loss: 0.0006203855737112463
Discriminator Loss: 0.7249820828437805
Generator Loss: 0.6899648904800415
1:32.10739504059972

Epoch: 2215, iteration: 0
Autoencoder Loss: 0.0006111162365414202
Discriminator Loss: 0.7614837884902954
Generator Loss: 0.6308791637420654
1:31.725021842336623

Epoch: 2220, iteration: 0
Autoencoder Loss: 0.0005199607112444937
Discriminator Loss: 0.7681446075439453
Generator Loss: 0.6644683480262756
1:33.15460188496195

Epoch: 2225, iteration: 0
Autoencoder Loss: 0.00046556227607652545
Discriminator Loss: 0.7329180240631104
Generator Loss: 0.6311234831809998
1:33.03464831650607

Epoch: 2230, iteration: 0
Autoencoder Loss: 0.00048411288298666477
Discriminator Loss: 0.674286961555481
Generator Loss: 0.694451093673706
1:34.0677351894502

Epoch: 2235, iteration: 0
Autoencoder Loss: 0.0007211719639599323
Discriminator Loss: 0.7178786396980286
Generator Loss: 0.6183537840843201
1:31.713465555438198

Epoch: 2240, iteration: 0
Autoencoder Loss: 0.0010130222653970122
Discriminator Loss: 0.702725887298584
Generator Loss: 1.1470720767974854
1:31.630416447728294

Epoch: 2245, iteration: 0
Autoencoder Loss: 0.0006335500511340797
Discriminator Loss: 0.8095897436141968
Generator Loss: 0.6209564805030823
1:32.45969363831934

Epoch: 2250, iteration: 0
Autoencoder Loss: 0.0005459821550175548
Discriminator Loss: 0.7216095924377441
Generator Loss: 0.6793226003646851
1:32.85412947926632

Epoch: 2255, iteration: 0
Autoencoder Loss: 0.00045922480057924986
Discriminator Loss: 0.6841405630111694
Generator Loss: 0.6292567849159241
1:33.84718467813843

Epoch: 2260, iteration: 0
Autoencoder Loss: 0.0006218941998668015
Discriminator Loss: 0.7261422276496887
Generator Loss: 0.5542033910751343
1:33.83065295920724

Epoch: 2265, iteration: 0
Autoencoder Loss: 0.0011000228114426136
Discriminator Loss: 0.7845714092254639
Generator Loss: 0.7888745069503784
1:34.99038680089668

Epoch: 2270, iteration: 0
Autoencoder Loss: 0.0006677900673821568
Discriminator Loss: 0.835537850856781
Generator Loss: 0.673653781414032
1:32.900731336964434

Epoch: 2275, iteration: 0
Autoencoder Loss: 0.0005265231593511999
Discriminator Loss: 0.7600754499435425
Generator Loss: 0.6330592632293701
1:32.617153291954885

Epoch: 2280, iteration: 0
Autoencoder Loss: 0.0005155090475454926
Discriminator Loss: 0.6882154941558838
Generator Loss: 0.6853589415550232
1:32.17244038352553

Epoch: 2285, iteration: 0
Autoencoder Loss: 0.0005491720512509346
Discriminator Loss: 0.6604912281036377
Generator Loss: 0.6814628839492798
1:32.94090197065599

Epoch: 2290, iteration: 0
Autoencoder Loss: 0.0005461203400045633
Discriminator Loss: 0.7091370820999146
Generator Loss: 0.6022643446922302
1:33.19244424509027

Epoch: 2295, iteration: 0
Autoencoder Loss: 0.0006695441552437842
Discriminator Loss: 0.6846616268157959
Generator Loss: 0.8102335333824158
1:32.83558731261047

Epoch: 2300, iteration: 0
Autoencoder Loss: 0.0006155757000669837
Discriminator Loss: 0.757315993309021
Generator Loss: 0.7182741165161133
1:33.78473815675419

Epoch: 2305, iteration: 0
Autoencoder Loss: 0.0005730081466026604
Discriminator Loss: 0.7434478998184204
Generator Loss: 0.6969916224479675
1:32.81702961065626

Epoch: 2310, iteration: 0
Autoencoder Loss: 0.000559936510398984
Discriminator Loss: 0.7653526663780212
Generator Loss: 0.5842922925949097
1:33.080026528185975

Epoch: 2315, iteration: 0
Autoencoder Loss: 0.0005745186936110258
Discriminator Loss: 0.7411594390869141
Generator Loss: 0.6494631767272949
1:33.03636002435214

Epoch: 2320, iteration: 0
Autoencoder Loss: 0.0006199315539561212
Discriminator Loss: 0.6831135749816895
Generator Loss: 0.7473344802856445
1:33.72767117289231

Epoch: 2325, iteration: 0
Autoencoder Loss: 0.0006239857757464051
Discriminator Loss: 0.7089172005653381
Generator Loss: 0.7013774514198303
1:33.21098863413371

Epoch: 2330, iteration: 0
Autoencoder Loss: 0.0005064255092293024
Discriminator Loss: 0.7237765192985535
Generator Loss: 0.6899466514587402
1:33.61672128939857

Epoch: 2335, iteration: 0
Autoencoder Loss: 0.000544337963219732
Discriminator Loss: 0.7161715030670166
Generator Loss: 0.6348029971122742
1:33.65856156072467

Epoch: 2340, iteration: 0
Autoencoder Loss: 0.0007689538761042058
Discriminator Loss: 0.6455203294754028
Generator Loss: 0.9065310955047607
1:31.88102768886393

Epoch: 2345, iteration: 0
Autoencoder Loss: 0.0005088956677354872
Discriminator Loss: 0.7742565870285034
Generator Loss: 0.6753131747245789
1:33.19863071143586

Epoch: 2350, iteration: 0
Autoencoder Loss: 0.0004732161178253591
Discriminator Loss: 0.7670584917068481
Generator Loss: 0.5756940841674805
1:33.39108024567316

Epoch: 2355, iteration: 0
Autoencoder Loss: 0.0005460641696117818
Discriminator Loss: 0.7335166931152344
Generator Loss: 0.6824299693107605
1:33.2128118277206

Epoch: 2360, iteration: 0
Autoencoder Loss: 0.0005557349068112671
Discriminator Loss: 0.7493416666984558
Generator Loss: 0.5760068297386169
1:33.3539949773433

Epoch: 2365, iteration: 0
Autoencoder Loss: 0.0006344232824631035
Discriminator Loss: 0.7951241731643677
Generator Loss: 0.6391568779945374
1:33.40741794861731

Epoch: 2370, iteration: 0
Autoencoder Loss: 0.0005352927255444229
Discriminator Loss: 0.7880674600601196
Generator Loss: 0.6660417914390564
1:33.02098771594846

Epoch: 2375, iteration: 0
Autoencoder Loss: 0.0004812030529137701
Discriminator Loss: 0.7259035110473633
Generator Loss: 0.6549715399742126
1:33.52501561925068

Epoch: 2380, iteration: 0
Autoencoder Loss: 0.0005637936992570758
Discriminator Loss: 0.7038267850875854
Generator Loss: 0.6382238864898682
1:32.46816615014316

Epoch: 2385, iteration: 0
Autoencoder Loss: 0.0008227687794715166
Discriminator Loss: 0.7666171789169312
Generator Loss: 0.7293490171432495
1:32.94737507145476

Epoch: 2390, iteration: 0
Autoencoder Loss: 0.0005678137531504035
Discriminator Loss: 0.7973281145095825
Generator Loss: 0.6698251962661743
1:33.459305827058294

Epoch: 2395, iteration: 0
Autoencoder Loss: 0.00042952882358804345
Discriminator Loss: 0.7364674210548401
Generator Loss: 0.6653799414634705
1:33.70730351427017

Epoch: 2400, iteration: 0
Autoencoder Loss: 0.0004256549582350999
Discriminator Loss: 0.7077311277389526
Generator Loss: 0.6123937368392944
1:33.42574807578356

Epoch: 2405, iteration: 0
Autoencoder Loss: 0.0005792999290861189
Discriminator Loss: 0.7223709225654602
Generator Loss: 0.6024566888809204
1:32.39826462553089

Epoch: 2410, iteration: 0
Autoencoder Loss: 0.0008751132991164923
Discriminator Loss: 0.7277001142501831
Generator Loss: 0.8911047577857971
1:33.021543335519674

Epoch: 2415, iteration: 0
Autoencoder Loss: 0.00045881030382588506
Discriminator Loss: 0.7985864281654358
Generator Loss: 0.6491770148277283
1:33.335849706676235

Epoch: 2420, iteration: 0
Autoencoder Loss: 0.0004421663179527968
Discriminator Loss: 0.7262179851531982
Generator Loss: 0.6913933753967285
1:33.627440591058296

Epoch: 2425, iteration: 0
Autoencoder Loss: 0.0004252027138136327
Discriminator Loss: 0.6987099647521973
Generator Loss: 0.637682318687439
1:33.434928652860904

Epoch: 2430, iteration: 0
Autoencoder Loss: 0.0004001101478934288
Discriminator Loss: 0.6714376211166382
Generator Loss: 0.5976521968841553
1:33.23454955891154

Epoch: 2435, iteration: 0
Autoencoder Loss: 0.0008544748416170478
Discriminator Loss: 0.7337327003479004
Generator Loss: 0.6236868500709534
1:34.07683294113648

Epoch: 2440, iteration: 0
Autoencoder Loss: 0.001099182409234345
Discriminator Loss: 0.8397399187088013
Generator Loss: 0.8190961480140686
1:32.62782108388612

Epoch: 2445, iteration: 0
Autoencoder Loss: 0.0006109533715061843
Discriminator Loss: 0.8132320046424866
Generator Loss: 0.6672885417938232
1:33.91506019794257

Epoch: 2450, iteration: 0
Autoencoder Loss: 0.00048180893645621836
Discriminator Loss: 0.750433623790741
Generator Loss: 0.6264216303825378
1:33.28024640861901

Epoch: 2455, iteration: 0
Autoencoder Loss: 0.0005363617092370987
Discriminator Loss: 0.7009009122848511
Generator Loss: 0.6645297408103943
1:33.123183967481175

Epoch: 2460, iteration: 0
Autoencoder Loss: 0.0005262151244096458
Discriminator Loss: 0.7034327983856201
Generator Loss: 0.6279162168502808
1:32.669843405509496

Epoch: 2465, iteration: 0
Autoencoder Loss: 0.0005997425760142505
Discriminator Loss: 0.7193543314933777
Generator Loss: 0.6768376231193542
1:32.05925377898943

Epoch: 2470, iteration: 0
Autoencoder Loss: 0.000652047514449805
Discriminator Loss: 0.763748288154602
Generator Loss: 0.6199963092803955
1:32.27788082861568

Epoch: 2475, iteration: 0
Autoencoder Loss: 0.000681009260006249
Discriminator Loss: 0.7161022424697876
Generator Loss: 0.7515671849250793
1:33.17529487868549

Epoch: 2480, iteration: 0
Autoencoder Loss: 0.0005292479763738811
Discriminator Loss: 0.7559928297996521
Generator Loss: 0.6185383200645447
1:33.195724737370185

Epoch: 2485, iteration: 0
Autoencoder Loss: 0.00046933209523558617
Discriminator Loss: 0.714975118637085
Generator Loss: 0.6174524426460266
1:32.81632261872587

Epoch: 2490, iteration: 0
Autoencoder Loss: 0.000561741238925606
Discriminator Loss: 0.7166723012924194
Generator Loss: 0.6170457005500793
1:32.677087269945986

Epoch: 2495, iteration: 0
Autoencoder Loss: 0.0006200452917255461
Discriminator Loss: 0.7710440754890442
Generator Loss: 0.6443648338317871
1:32.94665298919134

Epoch: 2500, iteration: 0
Autoencoder Loss: 0.0005406615091487765
Discriminator Loss: 0.7430068254470825
Generator Loss: 0.6730251312255859
1:32.77443197996841

Epoch: 2505, iteration: 0
Autoencoder Loss: 0.00048668397357687354
Discriminator Loss: 0.6951428651809692
Generator Loss: 0.7069251537322998
1:33.62348392372556

Epoch: 2510, iteration: 0
Autoencoder Loss: 0.0004772186803165823
Discriminator Loss: 0.718129575252533
Generator Loss: 0.5838238000869751
1:34.2008545099077

Epoch: 2515, iteration: 0
Autoencoder Loss: 0.0007216482190415263
Discriminator Loss: 0.718523383140564
Generator Loss: 0.6977019906044006
1:32.51246815744529

Epoch: 2520, iteration: 0
Autoencoder Loss: 0.0006478797877207398
Discriminator Loss: 0.7960450649261475
Generator Loss: 0.7022163271903992
1:32.62026925021906

Epoch: 2525, iteration: 0
Autoencoder Loss: 0.0004531877930276096
Discriminator Loss: 0.7446393966674805
Generator Loss: 0.648094117641449
1:33.44548229867068

Epoch: 2530, iteration: 0
Autoencoder Loss: 0.0004914876772090793
Discriminator Loss: 0.6806131601333618
Generator Loss: 0.650850236415863
1:33.50327656113979

Epoch: 2535, iteration: 0
Autoencoder Loss: 0.0005718250758945942
Discriminator Loss: 0.7338098287582397
Generator Loss: 0.5367838740348816
1:33.3920931195014

Epoch: 2540, iteration: 0
Autoencoder Loss: 0.0006846929900348186
Discriminator Loss: 0.7377755641937256
Generator Loss: 0.6338511109352112
1:32.87787281406618

Epoch: 2545, iteration: 0
Autoencoder Loss: 0.0007696456741541624
Discriminator Loss: 0.7670413851737976
Generator Loss: 0.7833750247955322
1:34.21921331758415

Epoch: 2550, iteration: 0
Autoencoder Loss: 0.0005005319835618138
Discriminator Loss: 0.7647444009780884
Generator Loss: 0.6414106488227844
1:33.06838879604506

Epoch: 2555, iteration: 0
Autoencoder Loss: 0.0004004200454801321
Discriminator Loss: 0.7426398396492004
Generator Loss: 0.5961505770683289
1:33.06942380947769

Epoch: 2560, iteration: 0
Autoencoder Loss: 0.0004517798370216042
Discriminator Loss: 0.6683523654937744
Generator Loss: 0.6897922158241272
1:33.10136207586376

Epoch: 2565, iteration: 0
Autoencoder Loss: 0.0006049858639016747
Discriminator Loss: 0.7192113995552063
Generator Loss: 0.6584513187408447
1:33.44138369823647

Epoch: 2570, iteration: 0
Autoencoder Loss: 0.0007648732862435281
Discriminator Loss: 0.8198670744895935
Generator Loss: 0.7392850518226624
1:32.64876004763718

Epoch: 2575, iteration: 0
Autoencoder Loss: 0.0004631151969078928
Discriminator Loss: 0.7841587066650391
Generator Loss: 0.6427460312843323
1:32.53281043851149

Epoch: 2580, iteration: 0
Autoencoder Loss: 0.00047757034189999104
Discriminator Loss: 0.723702073097229
Generator Loss: 0.6340399980545044
1:32.8389940083779

Epoch: 2585, iteration: 0
Autoencoder Loss: 0.00047757502761669457
Discriminator Loss: 0.6804566383361816
Generator Loss: 0.6524568796157837
1:32.97474572530536

Epoch: 2590, iteration: 0
Autoencoder Loss: 0.00043218667269684374
Discriminator Loss: 0.6696071028709412
Generator Loss: 0.6255358457565308
1:33.73360982379552

Epoch: 2595, iteration: 0
Autoencoder Loss: 0.0007273254450410604
Discriminator Loss: 0.6389381885528564
Generator Loss: 0.8671582937240601
1:31.696396798352332

Epoch: 2600, iteration: 0
Autoencoder Loss: 0.000709350744727999
Discriminator Loss: 0.7969440817832947
Generator Loss: 0.6967278718948364
1:34.003750730976165

Epoch: 2605, iteration: 0
Autoencoder Loss: 0.0005413386970758438
Discriminator Loss: 0.7757171392440796
Generator Loss: 0.6263654232025146
1:33.1813732961751

Epoch: 2610, iteration: 0
Autoencoder Loss: 0.0004555471532512456
Discriminator Loss: 0.7301149368286133
Generator Loss: 0.633803129196167
1:33.47206271425173

Epoch: 2615, iteration: 0
Autoencoder Loss: 0.0005298338946886361
Discriminator Loss: 0.6832015514373779
Generator Loss: 0.7183048129081726
1:33.43309737128772

Epoch: 2620, iteration: 0
Autoencoder Loss: 0.0008077087113633752
Discriminator Loss: 0.7292999029159546
Generator Loss: 0.7211146950721741
1:32.71136376086217

Epoch: 2625, iteration: 0
Autoencoder Loss: 0.000627623638138175
Discriminator Loss: 0.7732784748077393
Generator Loss: 0.7257565259933472
1:32.527169840015326

Epoch: 2630, iteration: 0
Autoencoder Loss: 0.00045000959653407335
Discriminator Loss: 0.7542020082473755
Generator Loss: 0.6356973052024841
1:33.003656623506046

Epoch: 2635, iteration: 0
Autoencoder Loss: 0.00043955788714811206
Discriminator Loss: 0.703350305557251
Generator Loss: 0.6539077162742615
1:32.98356157103504

Epoch: 2640, iteration: 0
Autoencoder Loss: 0.00047085669939406216
Discriminator Loss: 0.6848903298377991
Generator Loss: 0.6285088658332825
1:32.50231014308696

Epoch: 2645, iteration: 0
Autoencoder Loss: 0.000531174533534795
Discriminator Loss: 0.7133939862251282
Generator Loss: 0.6008841395378113
1:32.46232204622591

Epoch: 2650, iteration: 0
Autoencoder Loss: 0.0008814682951197028
Discriminator Loss: 0.6655873656272888
Generator Loss: 1.2341760396957397
1:31.046303919409013

Epoch: 2655, iteration: 0
Autoencoder Loss: 0.0005791261792182922
Discriminator Loss: 0.8156470060348511
Generator Loss: 0.6328215599060059
1:32.60744698161297

Epoch: 2660, iteration: 0
Autoencoder Loss: 0.0005137095577083528
Discriminator Loss: 0.7429870367050171
Generator Loss: 0.6764690279960632
1:33.77579470216097

Epoch: 2665, iteration: 0
Autoencoder Loss: 0.0005563243175856769
Discriminator Loss: 0.731927752494812
Generator Loss: 0.617033839225769
1:33.16230729051841

Epoch: 2670, iteration: 0
Autoencoder Loss: 0.0005187894566915929
Discriminator Loss: 0.7245778441429138
Generator Loss: 0.6265498399734497
1:32.88616464153474

Epoch: 2675, iteration: 0
Autoencoder Loss: 0.0005377773195505142
Discriminator Loss: 0.7002432942390442
Generator Loss: 0.719180703163147
1:32.232311251946705

Epoch: 2680, iteration: 0
Autoencoder Loss: 0.0005411765305325389
Discriminator Loss: 0.7688571214675903
Generator Loss: 0.6097541451454163
1:33.00268836589906

Epoch: 2685, iteration: 0
Autoencoder Loss: 0.00048793363384902477
Discriminator Loss: 0.721320390701294
Generator Loss: 0.6478723883628845
1:33.7899853170184

Epoch: 2690, iteration: 0
Autoencoder Loss: 0.0004992421600036323
Discriminator Loss: 0.7095413208007812
Generator Loss: 0.6215027570724487
1:33.7487555519572

Epoch: 2695, iteration: 0
Autoencoder Loss: 0.0006009091739542782
Discriminator Loss: 0.6832502484321594
Generator Loss: 0.7745720744132996
1:32.55968533823164

Epoch: 2700, iteration: 0
Autoencoder Loss: 0.000536297564394772
Discriminator Loss: 0.7889485359191895
Generator Loss: 0.6670382022857666
1:33.84266632636434

Epoch: 2705, iteration: 0
Autoencoder Loss: 0.00042532195220701396
Discriminator Loss: 0.7562909126281738
Generator Loss: 0.6584110260009766
1:33.378617039148445

Epoch: 2710, iteration: 0
Autoencoder Loss: 0.0003625475219450891
Discriminator Loss: 0.7032288312911987
Generator Loss: 0.6382244825363159
1:33.4167749421804

Epoch: 2715, iteration: 0
Autoencoder Loss: 0.0004535822954494506
Discriminator Loss: 0.6750671863555908
Generator Loss: 0.6061538457870483
1:33.31011113701528

Epoch: 2720, iteration: 0
Autoencoder Loss: 0.0013122959062457085
Discriminator Loss: 0.6922284960746765
Generator Loss: 0.9102635383605957
1:30.358806724154057

Epoch: 2725, iteration: 0
Autoencoder Loss: 0.0005744827212765813
Discriminator Loss: 0.8347633481025696
Generator Loss: 0.6613293886184692
1:33.14759857229758

Epoch: 2730, iteration: 0
Autoencoder Loss: 0.000490014033857733
Discriminator Loss: 0.7710182070732117
Generator Loss: 0.6422076225280762
1:32.76257022060796

Epoch: 2735, iteration: 0
Autoencoder Loss: 0.00039758722414262593
Discriminator Loss: 0.7333129644393921
Generator Loss: 0.6222972273826599
1:32.968969474652745

Epoch: 2740, iteration: 0
Autoencoder Loss: 0.0004899433115497231
Discriminator Loss: 0.6982344388961792
Generator Loss: 0.7022749185562134
1:32.850287273255084

Epoch: 2745, iteration: 0
Autoencoder Loss: 0.0004673958756029606
Discriminator Loss: 0.7688754796981812
Generator Loss: 0.5701337456703186
1:32.446674990477725

Epoch: 2750, iteration: 0
Autoencoder Loss: 0.0004729455686174333
Discriminator Loss: 0.694333553314209
Generator Loss: 0.7122249603271484
1:32.865241418469836

Epoch: 2755, iteration: 0
Autoencoder Loss: 0.0005068151513114572
Discriminator Loss: 0.7234503626823425
Generator Loss: 0.5895186066627502
1:32.93816906673433

Epoch: 2760, iteration: 0
Autoencoder Loss: 0.000596056052017957
Discriminator Loss: 0.7378914952278137
Generator Loss: 0.6612967252731323
1:33.21162551637712

Epoch: 2765, iteration: 0
Autoencoder Loss: 0.000467437319457531
Discriminator Loss: 0.7715901136398315
Generator Loss: 0.6222742795944214
1:32.604354311028416

Epoch: 2770, iteration: 0
Autoencoder Loss: 0.0004448138643056154
Discriminator Loss: 0.7369936108589172
Generator Loss: 0.6552633047103882
1:32.62219978353597

Epoch: 0, iteration: 0
Autoencoder Loss: 0.3406364321708679
Discriminator Loss: 0.7739286422729492
Generator Loss: 0.46329987049102783
1:7.908260547914164

Epoch: 5, iteration: 0
Autoencoder Loss: 0.005211749114096165
Discriminator Loss: 0.4253966808319092
Generator Loss: 1.0608999729156494
1:15.597521731050499

Epoch: 10, iteration: 0
Autoencoder Loss: 0.003655490465462208
Discriminator Loss: 0.7894012928009033
Generator Loss: 0.5413298010826111
1:19.061746162986996

Epoch: 15, iteration: 0
Autoencoder Loss: 0.001678631640970707
Discriminator Loss: 0.7633682489395142
Generator Loss: 1.0325042009353638
1:18.72401993333957

Epoch: 20, iteration: 0
Autoencoder Loss: 0.0013265104498714209
Discriminator Loss: 0.6787529587745667
Generator Loss: 1.8163056373596191
1:19.56722539457906

Epoch: 25, iteration: 0
Autoencoder Loss: 0.0012603558134287596
Discriminator Loss: 0.740309476852417
Generator Loss: 1.0622020959854126
1:19.721384157049897

Epoch: 30, iteration: 0
Autoencoder Loss: 0.0011556522222235799
Discriminator Loss: 0.7385954856872559
Generator Loss: 0.9408589601516724
1:19.72628882272889

Epoch: 35, iteration: 0
Autoencoder Loss: 0.0010651121847331524
Discriminator Loss: 0.7417324185371399
Generator Loss: 0.9443996548652649
1:19.188439222097575

Epoch: 40, iteration: 0
Autoencoder Loss: 0.0009715269552543759
Discriminator Loss: 0.6965606212615967
Generator Loss: 0.9759456515312195
1:19.156019123455142

Epoch: 45, iteration: 0
Autoencoder Loss: 0.0009948360966518521
Discriminator Loss: 0.7111701369285583
Generator Loss: 0.8605350255966187
1:19.355584284792783

Epoch: 50, iteration: 0
Autoencoder Loss: 0.0011131666833534837
Discriminator Loss: 0.7352571487426758
Generator Loss: 0.8554857969284058
1:19.305788965137186

Epoch: 55, iteration: 0
Autoencoder Loss: 0.0009630811982788146
Discriminator Loss: 0.7179529070854187
Generator Loss: 0.8357875347137451
1:19.29922642427677

Epoch: 60, iteration: 0
Autoencoder Loss: 0.0010360995074734092
Discriminator Loss: 0.7287465333938599
Generator Loss: 0.8083386421203613
1:19.751348395341225

Epoch: 65, iteration: 0
Autoencoder Loss: 0.0009307092404924333
Discriminator Loss: 0.7469303607940674
Generator Loss: 0.7809323072433472
1:19.64265277061343

Epoch: 70, iteration: 0
Autoencoder Loss: 0.0008204740006476641
Discriminator Loss: 0.6712604761123657
Generator Loss: 0.8399134278297424
1:19.78439259460429

Epoch: 75, iteration: 0
Autoencoder Loss: 0.0009243689710274339
Discriminator Loss: 0.7374417781829834
Generator Loss: 0.6729958057403564
1:19.937623830803684

Epoch: 80, iteration: 0
Autoencoder Loss: 0.0010098766069859266
Discriminator Loss: 0.724134087562561
Generator Loss: 0.7307897210121155
1:20.03031900201252

Epoch: 85, iteration: 0
Autoencoder Loss: 0.0009222346707247198
Discriminator Loss: 0.7525937557220459
Generator Loss: 0.7244973182678223
1:20.017562429066984

Epoch: 90, iteration: 0
Autoencoder Loss: 0.000878772116266191
Discriminator Loss: 0.7263497114181519
Generator Loss: 0.7712249159812927
1:19.89957287878814

Epoch: 95, iteration: 0
Autoencoder Loss: 0.0008996310643851757
Discriminator Loss: 0.7077672481536865
Generator Loss: 0.8098047971725464
1:19.611039445867217

Epoch: 100, iteration: 0
Autoencoder Loss: 0.0008726596715860069
Discriminator Loss: 0.7595704793930054
Generator Loss: 0.6421031951904297
1:20.028559638643344

Epoch: 105, iteration: 0
Autoencoder Loss: 0.0009031608351506293
Discriminator Loss: 0.7420128583908081
Generator Loss: 0.6428351402282715
1:20.01785378450362

Epoch: 110, iteration: 0
Autoencoder Loss: 0.0008619530708529055
Discriminator Loss: 0.7293990254402161
Generator Loss: 0.7050170302391052
1:19.893939117024445

Epoch: 115, iteration: 0
Autoencoder Loss: 0.0008325750823132694
Discriminator Loss: 0.6983410120010376
Generator Loss: 0.8065236806869507
1:19.837339675340793

Epoch: 120, iteration: 0
Autoencoder Loss: 0.0008685371722094715
Discriminator Loss: 0.774864673614502
Generator Loss: 0.6180372834205627
1:20.01247569435522

Epoch: 125, iteration: 0
Autoencoder Loss: 0.0007905591046437621
Discriminator Loss: 0.7413208484649658
Generator Loss: 0.7042727470397949
1:19.97809699471209

Epoch: 130, iteration: 0
Autoencoder Loss: 0.0008714040159247816
Discriminator Loss: 0.7519863843917847
Generator Loss: 0.7455468773841858
1:19.831262058511726

Epoch: 135, iteration: 0
Autoencoder Loss: 0.0008154617971740663
Discriminator Loss: 0.7449314594268799
Generator Loss: 0.7372457385063171
1:20.063927216796287

Epoch: 140, iteration: 0
Autoencoder Loss: 0.0007444715010933578
Discriminator Loss: 0.7638659477233887
Generator Loss: 0.684605598449707
1:20.01232559827885

Epoch: 145, iteration: 0
Autoencoder Loss: 0.0007985053234733641
Discriminator Loss: 0.7762857675552368
Generator Loss: 0.632840633392334
1:20.116585678913992

Epoch: 150, iteration: 0
Autoencoder Loss: 0.0008895041537471116
Discriminator Loss: 0.7413992881774902
Generator Loss: 0.663124144077301
1:20.09878035191672

Epoch: 155, iteration: 0
Autoencoder Loss: 0.0007965381955727935
Discriminator Loss: 0.8133766651153564
Generator Loss: 0.5757029056549072
1:20.14971110538779

Epoch: 160, iteration: 0
Autoencoder Loss: 0.0007474687299691141
Discriminator Loss: 0.805786669254303
Generator Loss: 0.5872825384140015
1:20.146777651833148

Epoch: 165, iteration: 0
Autoencoder Loss: 0.0008616280974820256
Discriminator Loss: 0.7502031326293945
Generator Loss: 0.7059697508811951
1:20.07319052231285

Epoch: 170, iteration: 0
Autoencoder Loss: 0.0007141287787817419
Discriminator Loss: 0.6983494758605957
Generator Loss: 0.7464752793312073
1:20.25823044282221

Epoch: 175, iteration: 0
Autoencoder Loss: 0.0007670047925785184
Discriminator Loss: 0.7420508861541748
Generator Loss: 0.5629863739013672
1:20.2037182205487

Epoch: 180, iteration: 0
Autoencoder Loss: 0.0008805289398878813
Discriminator Loss: 0.7104431986808777
Generator Loss: 0.807064950466156
1:20.01809299763224

Epoch: 185, iteration: 0
Autoencoder Loss: 0.0009609714616090059
Discriminator Loss: 0.7513376474380493
Generator Loss: 0.8369272947311401
1:20.06695491752671

Epoch: 190, iteration: 0
Autoencoder Loss: 0.0008203916368074715
Discriminator Loss: 0.7959790229797363
Generator Loss: 0.6223236322402954
1:20.12797077410481

Epoch: 195, iteration: 0
Autoencoder Loss: 0.0007300099241547287
Discriminator Loss: 0.7304519414901733
Generator Loss: 0.6684891581535339
1:20.175122896757355

Epoch: 200, iteration: 0
Autoencoder Loss: 0.0007205179426819086
Discriminator Loss: 0.7016231417655945
Generator Loss: 0.6757411956787109
1:20.258678230131153

Epoch: 205, iteration: 0
Autoencoder Loss: 0.0008289086981676519
Discriminator Loss: 0.776996374130249
Generator Loss: 0.5693554282188416
1:20.25530402340869

Epoch: 210, iteration: 0
Autoencoder Loss: 0.000819480512291193
Discriminator Loss: 0.7573702335357666
Generator Loss: 0.7680344581604004
1:19.894300120873044

Epoch: 215, iteration: 0
Autoencoder Loss: 0.0009165551164187491
Discriminator Loss: 0.8110716938972473
Generator Loss: 0.6655077338218689
1:20.103222625298432

Epoch: 220, iteration: 0
Autoencoder Loss: 0.0007449936820194125
Discriminator Loss: 0.7599654197692871
Generator Loss: 0.7164627313613892
1:19.936379713952896

Epoch: 225, iteration: 0
Autoencoder Loss: 0.0007336203125305474
Discriminator Loss: 0.7583444714546204
Generator Loss: 0.594597578048706
1:20.277009900672915

Epoch: 230, iteration: 0
Autoencoder Loss: 0.0007322037126868963
Discriminator Loss: 0.6817173361778259
Generator Loss: 0.7103524208068848
1:20.31386884692932

Epoch: 235, iteration: 0
Autoencoder Loss: 0.0007935002213343978
Discriminator Loss: 0.7435156106948853
Generator Loss: 0.6760256290435791
1:20.095436923649487

Epoch: 240, iteration: 0
Autoencoder Loss: 0.0008309461991302669
Discriminator Loss: 0.8436797857284546
Generator Loss: 0.6242904663085938
1:20.072122766197968

Epoch: 245, iteration: 0
Autoencoder Loss: 0.0007474389858543873
Discriminator Loss: 0.8225383758544922
Generator Loss: 0.6459565758705139
1:20.22582751760611

Epoch: 250, iteration: 0
Autoencoder Loss: 0.0007702080765739083
Discriminator Loss: 0.8326770663261414
Generator Loss: 0.5981175899505615
1:20.185749423569245

Epoch: 255, iteration: 0
Autoencoder Loss: 0.0006887144409120083
Discriminator Loss: 0.7843794822692871
Generator Loss: 0.6366235017776489
1:20.078704819136593

Epoch: 260, iteration: 0
Autoencoder Loss: 0.0006585114751942456
Discriminator Loss: 0.7364999055862427
Generator Loss: 0.7407703995704651
1:20.0632641533196

Epoch: 265, iteration: 0
Autoencoder Loss: 0.000696542498189956
Discriminator Loss: 0.7341377139091492
Generator Loss: 0.7434507012367249
1:20.189991514415524

Epoch: 270, iteration: 0
Autoencoder Loss: 0.0007309367065317929
Discriminator Loss: 0.777381420135498
Generator Loss: 0.6335036158561707
1:20.04304321854352

Epoch: 275, iteration: 0
Autoencoder Loss: 0.0007156515493988991
Discriminator Loss: 0.7379930019378662
Generator Loss: 0.6636486649513245
1:20.09013458752623

Epoch: 280, iteration: 0
Autoencoder Loss: 0.0007736761472187936
Discriminator Loss: 0.7263184785842896
Generator Loss: 0.7185553908348083
1:20.270043113702148

Epoch: 285, iteration: 0
Autoencoder Loss: 0.0007966734119690955
Discriminator Loss: 0.7554459571838379
Generator Loss: 0.7161192297935486
1:20.346258512026978

Epoch: 290, iteration: 0
Autoencoder Loss: 0.0007204508292488754
Discriminator Loss: 0.7401326894760132
Generator Loss: 0.7164990901947021
1:20.080619375828448

Epoch: 295, iteration: 0
Autoencoder Loss: 0.0007734628743492067
Discriminator Loss: 0.7796891331672668
Generator Loss: 0.5906962156295776
1:20.244177595128427

Epoch: 300, iteration: 0
Autoencoder Loss: 0.0006721074460074306
Discriminator Loss: 0.7631694674491882
Generator Loss: 0.6206642985343933
1:20.222653687394928

Epoch: 305, iteration: 0
Autoencoder Loss: 0.0007316400296986103
Discriminator Loss: 0.7341529130935669
Generator Loss: 0.7061388492584229
1:20.156626177805798

Epoch: 310, iteration: 0
Autoencoder Loss: 0.0007014928851276636
Discriminator Loss: 0.82363361120224
Generator Loss: 0.5559309124946594
1:20.19834425022051

Epoch: 315, iteration: 0
Autoencoder Loss: 0.0006999375764280558
Discriminator Loss: 0.7774786949157715
Generator Loss: 0.625159502029419
1:20.04171887541593

Epoch: 320, iteration: 0
Autoencoder Loss: 0.0006990975816734135
Discriminator Loss: 0.7234855890274048
Generator Loss: 0.7511044144630432
1:20.21547628826246

Epoch: 325, iteration: 0
Autoencoder Loss: 0.000742450647521764
Discriminator Loss: 0.7114636898040771
Generator Loss: 0.7246232032775879
1:20.115800351242097

Epoch: 330, iteration: 0
Autoencoder Loss: 0.0006953429547138512
Discriminator Loss: 0.7778216600418091
Generator Loss: 0.6147167086601257
1:20.224718280388792

Epoch: 335, iteration: 0
Autoencoder Loss: 0.0006826511234976351
Discriminator Loss: 0.7681633234024048
Generator Loss: 0.5914645195007324
1:20.24669262888583

Epoch: 340, iteration: 0
Autoencoder Loss: 0.0007125207339413464
Discriminator Loss: 0.7106845378875732
Generator Loss: 0.7163978219032288
1:20.48352032792247

Epoch: 345, iteration: 0
Autoencoder Loss: 0.0007095575565472245
Discriminator Loss: 0.7435071468353271
Generator Loss: 0.695538341999054
1:20.23413351799993

Epoch: 350, iteration: 0
Autoencoder Loss: 0.000714674184564501
Discriminator Loss: 0.7672573328018188
Generator Loss: 0.67009437084198
1:20.262606773565388

Epoch: 355, iteration: 0
Autoencoder Loss: 0.0006343370187096298
Discriminator Loss: 0.7293016314506531
Generator Loss: 0.633866548538208
1:20.264043459707747

Epoch: 360, iteration: 0
Autoencoder Loss: 0.0007582792895846069
Discriminator Loss: 0.7284926176071167
Generator Loss: 0.6839202642440796
1:20.03116528980374

Epoch: 365, iteration: 0
Autoencoder Loss: 0.0007456900202669203
Discriminator Loss: 0.857632577419281
Generator Loss: 0.5005570650100708
1:20.15113430172324

Epoch: 370, iteration: 0
Autoencoder Loss: 0.0006702958489768207
Discriminator Loss: 0.7432772517204285
Generator Loss: 0.7710855007171631
1:20.16326207566219

Epoch: 375, iteration: 0
Autoencoder Loss: 0.0007036755559965968
Discriminator Loss: 0.7852285504341125
Generator Loss: 0.5821408629417419
1:20.324641913206733

Epoch: 380, iteration: 0
Autoencoder Loss: 0.0007073207525536418
Discriminator Loss: 0.7219033241271973
Generator Loss: 0.6599234342575073
1:20.138279845024627

Epoch: 385, iteration: 0
Autoencoder Loss: 0.0007385745993815362
Discriminator Loss: 0.8177798986434937
Generator Loss: 0.510617733001709
1:20.212891872765493

Epoch: 390, iteration: 0
Autoencoder Loss: 0.0008135052630677819
Discriminator Loss: 0.7740234136581421
Generator Loss: 0.7011414170265198
1:20.32321925925124

Epoch: 395, iteration: 0
Autoencoder Loss: 0.0007146623102016747
Discriminator Loss: 0.7720087766647339
Generator Loss: 0.658433735370636
1:20.38498005009679

Epoch: 400, iteration: 0
Autoencoder Loss: 0.0006479290896095335
Discriminator Loss: 0.694592297077179
Generator Loss: 0.7194463610649109
1:20.215718118915433

Epoch: 405, iteration: 0
Autoencoder Loss: 0.0006944695487618446
Discriminator Loss: 0.6608797311782837
Generator Loss: 0.8064865469932556
1:20.227446600896187

Epoch: 410, iteration: 0
Autoencoder Loss: 0.0006897816201671958
Discriminator Loss: 0.7812398672103882
Generator Loss: 0.6797993779182434
1:20.27656387304458

Epoch: 415, iteration: 0
Autoencoder Loss: 0.0007286094478331506
Discriminator Loss: 0.7785807251930237
Generator Loss: 0.713012158870697
1:20.02668745200649

Epoch: 420, iteration: 0
Autoencoder Loss: 0.0006336253136396408
Discriminator Loss: 0.7318704128265381
Generator Loss: 0.6505757570266724
1:20.150642180946605

Epoch: 425, iteration: 0
Autoencoder Loss: 0.0007771178497932851
Discriminator Loss: 0.7716724276542664
Generator Loss: 0.5873064994812012
1:20.160448061996497

Epoch: 430, iteration: 0
Autoencoder Loss: 0.0007260650163516402
Discriminator Loss: 0.8181668519973755
Generator Loss: 0.6620627641677856
1:19.985387722168575

Epoch: 435, iteration: 0
Autoencoder Loss: 0.0007265097228810191
Discriminator Loss: 0.7803630828857422
Generator Loss: 0.7186676859855652
1:20.296947997992596

Epoch: 440, iteration: 0
Autoencoder Loss: 0.0006517038564197719
Discriminator Loss: 0.738723635673523
Generator Loss: 0.6271235942840576
1:20.40898208111418

Epoch: 445, iteration: 0
Autoencoder Loss: 0.0007438171305693686
Discriminator Loss: 0.7071278095245361
Generator Loss: 0.6474635601043701
1:20.426059758264028

Epoch: 450, iteration: 0
Autoencoder Loss: 0.0011641074670478702
Discriminator Loss: 0.8228102922439575
Generator Loss: 0.550660252571106
1:19.995410842736824

Epoch: 455, iteration: 0
Autoencoder Loss: 0.0007255035452544689
Discriminator Loss: 0.7845615744590759
Generator Loss: 0.7271742224693298
1:20.414584528604344

Epoch: 460, iteration: 0
Autoencoder Loss: 0.0006254298496060073
Discriminator Loss: 0.7742255330085754
Generator Loss: 0.6281458735466003
1:20.519427238528696

Epoch: 465, iteration: 0
Autoencoder Loss: 0.0006769197061657906
Discriminator Loss: 0.737606406211853
Generator Loss: 0.6259762644767761
1:20.391956548709878

Epoch: 470, iteration: 0
Autoencoder Loss: 0.0006661161314696074
Discriminator Loss: 0.7108468413352966
Generator Loss: 0.5964890718460083
1:20.476250391112302

Epoch: 475, iteration: 0
Autoencoder Loss: 0.0006706470157951117
Discriminator Loss: 0.6856116056442261
Generator Loss: 0.6507236957550049
1:20.33772561927837

Epoch: 480, iteration: 0
Autoencoder Loss: 0.0009928029030561447
Discriminator Loss: 0.6902443170547485
Generator Loss: 0.9272100925445557
1:20.624734749982814

Epoch: 485, iteration: 0
Autoencoder Loss: 0.0008298635366372764
Discriminator Loss: 0.836135983467102
Generator Loss: 0.711037814617157
1:20.8166960695294

Epoch: 490, iteration: 0
Autoencoder Loss: 0.0006577728199772537
Discriminator Loss: 0.7761933207511902
Generator Loss: 0.5951052904129028
1:20.524217752935083

Epoch: 495, iteration: 0
Autoencoder Loss: 0.0007845615036785603
Discriminator Loss: 0.7084895968437195
Generator Loss: 0.6925974488258362
1:20.2309374026601

Epoch: 500, iteration: 0
Autoencoder Loss: 0.0007488721166737378
Discriminator Loss: 0.7174679636955261
Generator Loss: 0.7501800060272217
1:20.384405990315923

Epoch: 505, iteration: 0
Autoencoder Loss: 0.0007122253882698715
Discriminator Loss: 0.7072953581809998
Generator Loss: 0.7338758111000061
1:20.230072391757744

Epoch: 510, iteration: 0
Autoencoder Loss: 0.000712148321326822
Discriminator Loss: 0.7467149496078491
Generator Loss: 0.6941806674003601
1:20.5667024300841

Epoch: 515, iteration: 0
Autoencoder Loss: 0.0005890747997909784
Discriminator Loss: 0.7274218797683716
Generator Loss: 0.6687036752700806
1:20.435648982705715

Epoch: 520, iteration: 0
Autoencoder Loss: 0.0006546817603521049
Discriminator Loss: 0.7443351149559021
Generator Loss: 0.6053441762924194
1:20.210209720418227

Epoch: 525, iteration: 0
Autoencoder Loss: 0.0006991345435380936
Discriminator Loss: 0.7635696530342102
Generator Loss: 0.7019892930984497
1:20.386611750377455

Epoch: 530, iteration: 0
Autoencoder Loss: 0.0006808635080233216
Discriminator Loss: 0.7629423141479492
Generator Loss: 0.7084091901779175
1:20.447830846646916

Epoch: 535, iteration: 0
Autoencoder Loss: 0.0005950354970991611
Discriminator Loss: 0.7550008893013
Generator Loss: 0.5941053032875061
1:20.350857115005088

Epoch: 540, iteration: 0
Autoencoder Loss: 0.0006778591778129339
Discriminator Loss: 0.7177073955535889
Generator Loss: 0.631122887134552
1:20.36500135937915

Epoch: 545, iteration: 0
Autoencoder Loss: 0.0007498527993448079
Discriminator Loss: 0.7773619890213013
Generator Loss: 0.594358503818512
1:20.430310755753034

Epoch: 550, iteration: 0
Autoencoder Loss: 0.0006357321981340647
Discriminator Loss: 0.7545862793922424
Generator Loss: 0.6558419466018677
1:20.307787787538686

Epoch: 555, iteration: 0
Autoencoder Loss: 0.0006412219954654574
Discriminator Loss: 0.7582866549491882
Generator Loss: 0.6251885890960693
1:20.45099009706556

Epoch: 560, iteration: 0
Autoencoder Loss: 0.000657903787214309
Discriminator Loss: 0.694137692451477
Generator Loss: 0.7727351188659668
1:20.540014222869978

Epoch: 565, iteration: 0
Autoencoder Loss: 0.0006745596183463931
Discriminator Loss: 0.6931638717651367
Generator Loss: 0.6761675477027893
1:20.48723888165483

Epoch: 570, iteration: 0
Autoencoder Loss: 0.000772960833273828
Discriminator Loss: 0.7730128765106201
Generator Loss: 0.557552695274353
1:20.16706244202929

Epoch: 575, iteration: 0
Autoencoder Loss: 0.0006671947776339948
Discriminator Loss: 0.7377029657363892
Generator Loss: 0.7146931886672974
1:20.55343424156316

Epoch: 580, iteration: 0
Autoencoder Loss: 0.0006347946473397315
Discriminator Loss: 0.7667645215988159
Generator Loss: 0.5853566527366638
1:20.524560189874222

Epoch: 585, iteration: 0
Autoencoder Loss: 0.0006150996778160334
Discriminator Loss: 0.7475400567054749
Generator Loss: 0.57763671875
1:20.234777817034345

Epoch: 590, iteration: 0
Autoencoder Loss: 0.0006683336105197668
Discriminator Loss: 0.7778327465057373
Generator Loss: 0.5622885823249817
1:20.123708091171743

Epoch: 595, iteration: 0
Autoencoder Loss: 0.0007030446431599557
Discriminator Loss: 0.7182595729827881
Generator Loss: 0.9885916113853455
1:20.411252719706525

Epoch: 600, iteration: 0
Autoencoder Loss: 0.000643380859401077
Discriminator Loss: 0.825812578201294
Generator Loss: 0.6044556498527527
1:20.3885582554553

Epoch: 605, iteration: 0
Autoencoder Loss: 0.0006048520444892347
Discriminator Loss: 0.7122251987457275
Generator Loss: 0.7348210215568542
1:20.255214259130007

Epoch: 610, iteration: 0
Autoencoder Loss: 0.000664140738081187
Discriminator Loss: 0.7411448955535889
Generator Loss: 0.6527313590049744
1:20.229100472968845

Epoch: 615, iteration: 0
Autoencoder Loss: 0.0006893372628837824
Discriminator Loss: 0.7444525957107544
Generator Loss: 0.6478905081748962
1:20.556171877214254

Epoch: 620, iteration: 0
Autoencoder Loss: 0.0006907985080033541
Discriminator Loss: 0.7757198810577393
Generator Loss: 0.626774787902832
1:20.508868229628327

Epoch: 625, iteration: 0
Autoencoder Loss: 0.0005919343093410134
Discriminator Loss: 0.7509710788726807
Generator Loss: 0.6176670789718628
1:20.547071104758512

Epoch: 630, iteration: 0
Autoencoder Loss: 0.0005806579138152301
Discriminator Loss: 0.6932421922683716
Generator Loss: 0.6905525922775269
1:20.520546473750496

Epoch: 635, iteration: 0
Autoencoder Loss: 0.0006342849228531122
Discriminator Loss: 0.7251174449920654
Generator Loss: 0.5917189717292786
1:20.415121713842762

Epoch: 640, iteration: 0
Autoencoder Loss: 0.0007507425034418702
Discriminator Loss: 0.6586158275604248
Generator Loss: 0.7882606387138367
1:19.951975154106265

Epoch: 645, iteration: 0
Autoencoder Loss: 0.0008046114235185087
Discriminator Loss: 0.7663348913192749
Generator Loss: 0.7965918183326721
1:20.495585988650763

Epoch: 650, iteration: 0
Autoencoder Loss: 0.0006420760182663798
Discriminator Loss: 0.7597271203994751
Generator Loss: 0.7154987454414368
1:20.275967634353698

Epoch: 655, iteration: 0
Autoencoder Loss: 0.0006566504016518593
Discriminator Loss: 0.7136342525482178
Generator Loss: 0.6559288501739502
1:20.458023377397566

Epoch: 660, iteration: 0
Autoencoder Loss: 0.0006177725153975189
Discriminator Loss: 0.708109974861145
Generator Loss: 0.580743670463562
1:20.45284383144191

Epoch: 665, iteration: 0
Autoencoder Loss: 0.0007876500021666288
Discriminator Loss: 0.7096801400184631
Generator Loss: 0.6882534027099609
1:20.271490861828788

Epoch: 670, iteration: 0
Autoencoder Loss: 0.0008630382362753153
Discriminator Loss: 0.7181954383850098
Generator Loss: 0.8798353672027588
1:20.2069851528552

Epoch: 675, iteration: 0
Autoencoder Loss: 0.0007956763147376478
Discriminator Loss: 0.8093334436416626
Generator Loss: 0.6514858603477478
1:20.42109059453574

Epoch: 680, iteration: 0
Autoencoder Loss: 0.0006395140662789345
Discriminator Loss: 0.7511390447616577
Generator Loss: 0.6346654295921326
1:20.33478064629189

Epoch: 685, iteration: 0
Autoencoder Loss: 0.000665050174575299
Discriminator Loss: 0.752557635307312
Generator Loss: 0.6422532796859741
1:19.982164082572755

Epoch: 690, iteration: 0
Autoencoder Loss: 0.0006402068538591266
Discriminator Loss: 0.7743834257125854
Generator Loss: 0.6335040926933289
1:20.51658931339591

Epoch: 695, iteration: 0
Autoencoder Loss: 0.0006719534285366535
Discriminator Loss: 0.7081282138824463
Generator Loss: 0.6569192409515381
1:20.574953426953133

Epoch: 700, iteration: 0
Autoencoder Loss: 0.0006690718582831323
Discriminator Loss: 0.7043116688728333
Generator Loss: 0.6831515431404114
1:20.344807051350095

Epoch: 705, iteration: 0
Autoencoder Loss: 0.0006417225813493133
Discriminator Loss: 0.8412764668464661
Generator Loss: 0.5199506878852844
1:20.387567810756725

Epoch: 710, iteration: 0
Autoencoder Loss: 0.0006846739561296999
Discriminator Loss: 0.7318457365036011
Generator Loss: 0.7719966769218445
1:20.605146393223595

Epoch: 715, iteration: 0
Autoencoder Loss: 0.0006380461272783577
Discriminator Loss: 0.7555920481681824
Generator Loss: 0.5865915417671204
1:20.610533539713146

Epoch: 720, iteration: 0
Autoencoder Loss: 0.0006505095516331494
Discriminator Loss: 0.7240489721298218
Generator Loss: 0.6791553497314453
1:20.443120257933863

Epoch: 725, iteration: 0
Autoencoder Loss: 0.0005953690269961953
Discriminator Loss: 0.7080308794975281
Generator Loss: 0.6844719052314758
1:20.51063629219914

Epoch: 730, iteration: 0
Autoencoder Loss: 0.0007009261753410101
Discriminator Loss: 0.6945025324821472
Generator Loss: 0.7018480896949768
1:20.385317162927574

Epoch: 735, iteration: 0
Autoencoder Loss: 0.0008433162001892924
Discriminator Loss: 0.7502562999725342
Generator Loss: 0.8162641525268555
1:19.951743377956944

Epoch: 740, iteration: 0
Autoencoder Loss: 0.0006733339978381991
Discriminator Loss: 0.7996386885643005
Generator Loss: 0.7314757108688354
1:20.209686391457787

Epoch: 745, iteration: 0
Autoencoder Loss: 0.0006184704252518713
Discriminator Loss: 0.7366793155670166
Generator Loss: 0.6396917700767517
1:20.514012488950947

Epoch: 750, iteration: 0
Autoencoder Loss: 0.0006028019706718624
Discriminator Loss: 0.6574122309684753
Generator Loss: 0.7034478783607483
1:20.51191064188339

Epoch: 755, iteration: 0
Autoencoder Loss: 0.0006569655961357057
Discriminator Loss: 0.7341350317001343
Generator Loss: 0.5179356932640076
1:20.505587847061616

Epoch: 760, iteration: 0
Autoencoder Loss: 0.0007341759628616273
Discriminator Loss: 0.7334638833999634
Generator Loss: 0.6423065662384033
1:20.518290791399973

Epoch: 765, iteration: 0
Autoencoder Loss: 0.0013567603891715407
Discriminator Loss: 0.7015262246131897
Generator Loss: 1.366297960281372
1:20.130307155094545

Epoch: 770, iteration: 0
Autoencoder Loss: 0.0006407237960956991
Discriminator Loss: 0.827853798866272
Generator Loss: 0.6387951374053955
1:20.56459686160787

Epoch: 775, iteration: 0
Autoencoder Loss: 0.0006551400292664766
Discriminator Loss: 0.7610722780227661
Generator Loss: 0.6156674027442932
1:20.58088144069005

Epoch: 780, iteration: 0
Autoencoder Loss: 0.0006483395700342953
Discriminator Loss: 0.7169585824012756
Generator Loss: 0.6497750878334045
1:20.585268540046965

Epoch: 785, iteration: 0
Autoencoder Loss: 0.0006680456572212279
Discriminator Loss: 0.7641584873199463
Generator Loss: 0.5568395853042603
1:20.43691084798055

Epoch: 790, iteration: 0
Autoencoder Loss: 0.0007330437656491995
Discriminator Loss: 0.7272809147834778
Generator Loss: 0.6978299617767334
1:20.614504629914606

Epoch: 795, iteration: 0
Autoencoder Loss: 0.0006124948849901557
Discriminator Loss: 0.7184157371520996
Generator Loss: 0.6805278062820435
1:20.59416508953953

Epoch: 800, iteration: 0
Autoencoder Loss: 0.0007223987486213446
Discriminator Loss: 0.7196350693702698
Generator Loss: 0.6844152212142944
1:20.070611429064265

Epoch: 805, iteration: 0
Autoencoder Loss: 0.0007786333444528282
Discriminator Loss: 0.7547578811645508
Generator Loss: 0.7759425044059753
1:20.189280012485348

Epoch: 810, iteration: 0
Autoencoder Loss: 0.0006341604748740792
Discriminator Loss: 0.7897305488586426
Generator Loss: 0.6877511739730835
1:20.64540020599425

Epoch: 815, iteration: 0
Autoencoder Loss: 0.0007088779238983989
Discriminator Loss: 0.7523667812347412
Generator Loss: 0.6169835329055786
1:20.57776251216527

Epoch: 820, iteration: 0
Autoencoder Loss: 0.0006749838939867914
Discriminator Loss: 0.7393011450767517
Generator Loss: 0.6124175786972046
1:20.36431212518871

Epoch: 825, iteration: 0
Autoencoder Loss: 0.0006743515841662884
Discriminator Loss: 0.7262766361236572
Generator Loss: 0.6050573587417603
1:20.557655289063554

Epoch: 830, iteration: 0
Autoencoder Loss: 0.0008557418477721512
Discriminator Loss: 0.6930988430976868
Generator Loss: 0.7347459197044373
1:20.206009201468863

Epoch: 835, iteration: 0
Autoencoder Loss: 0.0007629970205016434
Discriminator Loss: 0.7415976524353027
Generator Loss: 0.6318181753158569
1:20.34435303528123

Epoch: 840, iteration: 0
Autoencoder Loss: 0.0007581477984786034
Discriminator Loss: 0.7764485478401184
Generator Loss: 0.5614373683929443
1:20.261832602417712

Epoch: 845, iteration: 0
Autoencoder Loss: 0.0006999974721111357
Discriminator Loss: 0.7626519203186035
Generator Loss: 0.762843906879425
1:20.19951570202515

Epoch: 850, iteration: 0
Autoencoder Loss: 0.0007467326940968633
Discriminator Loss: 0.7733299136161804
Generator Loss: 0.6547448039054871
1:20.58821766139802

Epoch: 855, iteration: 0
Autoencoder Loss: 0.0005846944986842573
Discriminator Loss: 0.7115927338600159
Generator Loss: 0.6518540978431702
1:20.58304313031993

Epoch: 860, iteration: 0
Autoencoder Loss: 0.0006588528631255031
Discriminator Loss: 0.6811256408691406
Generator Loss: 0.6077610850334167
1:20.589321643693346

Epoch: 865, iteration: 0
Autoencoder Loss: 0.0006463043973781168
Discriminator Loss: 0.6739902496337891
Generator Loss: 0.6314716339111328
1:20.50042228343488

Epoch: 870, iteration: 0
Autoencoder Loss: 0.001435325713828206
Discriminator Loss: 0.7105512619018555
Generator Loss: 1.0352121591567993
1:19.591902010672282

Epoch: 875, iteration: 0
Autoencoder Loss: 0.0007346748025156558
Discriminator Loss: 0.8647427558898926
Generator Loss: 0.6824865341186523
1:20.62469023685238

Epoch: 880, iteration: 0
Autoencoder Loss: 0.0006593416910618544
Discriminator Loss: 0.7740427255630493
Generator Loss: 0.6414039134979248
1:20.665378976473974

Epoch: 885, iteration: 0
Autoencoder Loss: 0.0006570992991328239
Discriminator Loss: 0.7497783899307251
Generator Loss: 0.5785007476806641
1:20.550090945834206

Epoch: 890, iteration: 0
Autoencoder Loss: 0.00066848547430709
Discriminator Loss: 0.7334959506988525
Generator Loss: 0.6137001514434814
1:20.427573922176535

Epoch: 895, iteration: 0
Autoencoder Loss: 0.0007254560478031635
Discriminator Loss: 0.7464984655380249
Generator Loss: 0.649043619632721
1:20.46145944144119

Epoch: 900, iteration: 0
Autoencoder Loss: 0.0006461325101554394
Discriminator Loss: 0.7516301870346069
Generator Loss: 0.7331769466400146
1:20.38983127148309

Epoch: 905, iteration: 0
Autoencoder Loss: 0.0006399158155545592
Discriminator Loss: 0.7516408562660217
Generator Loss: 0.6685723066329956
1:20.3772687491389

Epoch: 910, iteration: 0
Autoencoder Loss: 0.0006820455892011523
Discriminator Loss: 0.7504466772079468
Generator Loss: 0.696312665939331
1:20.606416452335026

Epoch: 915, iteration: 0
Autoencoder Loss: 0.000660813762806356
Discriminator Loss: 0.7643236517906189
Generator Loss: 0.5735358595848083
1:20.55023069709147

Epoch: 920, iteration: 0
Autoencoder Loss: 0.0006575428997166455
Discriminator Loss: 0.6595094799995422
Generator Loss: 0.754696786403656
1:20.540781101472874

Epoch: 925, iteration: 0
Autoencoder Loss: 0.0006904154433868825
Discriminator Loss: 0.7736544609069824
Generator Loss: 0.49812036752700806
1:20.68616974854176

Epoch: 930, iteration: 0
Autoencoder Loss: 0.0008908168529160321
Discriminator Loss: 0.6610063314437866
Generator Loss: 0.9956099987030029
1:20.905953657911965

Epoch: 935, iteration: 0
Autoencoder Loss: 0.000669251021463424
Discriminator Loss: 0.8244727253913879
Generator Loss: 0.6855190992355347
1:20.471529004914665

Epoch: 940, iteration: 0
Autoencoder Loss: 0.0006197120528668165
Discriminator Loss: 0.7681103944778442
Generator Loss: 0.6606440544128418
1:20.55531260851701

Epoch: 945, iteration: 0
Autoencoder Loss: 0.0006021690205670893
Discriminator Loss: 0.6941110491752625
Generator Loss: 0.6425900459289551
1:20.778978615150912

Epoch: 950, iteration: 0
Autoencoder Loss: 0.0005706492811441422
Discriminator Loss: 0.6738098859786987
Generator Loss: 0.5816352367401123
1:20.65711913150002

Epoch: 955, iteration: 0
Autoencoder Loss: 0.0006581803318113089
Discriminator Loss: 0.6933904886245728
Generator Loss: 0.5681758522987366
1:20.30173004914891

Epoch: 960, iteration: 0
Autoencoder Loss: 0.0009145843214355409
Discriminator Loss: 0.7641121745109558
Generator Loss: 0.75142902135849
1:20.304607282988623

Epoch: 965, iteration: 0
Autoencoder Loss: 0.0007455757004208863
Discriminator Loss: 0.8854387998580933
Generator Loss: 0.7036558985710144
1:20.46130056621715

Epoch: 970, iteration: 0
Autoencoder Loss: 0.0005973283550702035
Discriminator Loss: 0.7984767556190491
Generator Loss: 0.6552581191062927
1:20.485970428026622

Epoch: 975, iteration: 0
Autoencoder Loss: 0.0006698323413729668
Discriminator Loss: 0.7384534478187561
Generator Loss: 0.6085196137428284
1:20.53832635867858

Epoch: 980, iteration: 0
Autoencoder Loss: 0.0006582257337868214
Discriminator Loss: 0.7124537825584412
Generator Loss: 0.6450731754302979
1:20.723371841441317

Epoch: 985, iteration: 0
Autoencoder Loss: 0.000675220915582031
Discriminator Loss: 0.6925853490829468
Generator Loss: 0.7304625511169434
1:20.36848910978239

Epoch: 990, iteration: 0
Autoencoder Loss: 0.0006940744933672249
Discriminator Loss: 0.7189227342605591
Generator Loss: 0.7290430665016174
1:20.620766581345812

Epoch: 995, iteration: 0
Autoencoder Loss: 0.0007066289545036852
Discriminator Loss: 0.7344207763671875
Generator Loss: 0.6964128613471985
1:20.47867884637851

Epoch: 1000, iteration: 0
Autoencoder Loss: 0.0006919579464010894
Discriminator Loss: 0.7253657579421997
Generator Loss: 0.7543707489967346
1:20.69594326128554

Epoch: 1005, iteration: 0
Autoencoder Loss: 0.0006190564017742872
Discriminator Loss: 0.7082586884498596
Generator Loss: 0.6548993587493896
1:20.614907309379493

Epoch: 1010, iteration: 0
Autoencoder Loss: 0.0006752856425009668
Discriminator Loss: 0.7146966457366943
Generator Loss: 0.5947462916374207
1:20.264740955059594

Epoch: 1015, iteration: 0
Autoencoder Loss: 0.0007737230625934899
Discriminator Loss: 0.7831435203552246
Generator Loss: 0.7085419297218323
1:20.554536858946967

Epoch: 1020, iteration: 0
Autoencoder Loss: 0.0006480224546976388
Discriminator Loss: 0.7930934429168701
Generator Loss: 0.5994543433189392
1:20.305118590242284

Epoch: 1025, iteration: 0
Autoencoder Loss: 0.0006385442684404552
Discriminator Loss: 0.70688796043396
Generator Loss: 0.6821603775024414
1:20.57805807966327

Epoch: 1030, iteration: 0
Autoencoder Loss: 0.0006708439905196428
Discriminator Loss: 0.6979124546051025
Generator Loss: 0.7427796721458435
1:20.609948730365172

Epoch: 1035, iteration: 0
Autoencoder Loss: 0.0007624528370797634
Discriminator Loss: 0.7270545959472656
Generator Loss: 0.6822072267532349
1:20.73992381989974

Epoch: 1040, iteration: 0
Autoencoder Loss: 0.000734576431568712
Discriminator Loss: 0.7673412561416626
Generator Loss: 0.65732342004776
1:20.416753904430056

Epoch: 1045, iteration: 0
Autoencoder Loss: 0.0006626644753850996
Discriminator Loss: 0.8097686767578125
Generator Loss: 0.6061828136444092
1:20.640934678841187

Epoch: 1050, iteration: 0
Autoencoder Loss: 0.000630515452940017
Discriminator Loss: 0.7863753437995911
Generator Loss: 0.6607387065887451
1:20.549451370719915

Epoch: 1055, iteration: 0
Autoencoder Loss: 0.0005962139694020152
Discriminator Loss: 0.7614100575447083
Generator Loss: 0.6512240171432495
1:20.471702985021565

Epoch: 1060, iteration: 0
Autoencoder Loss: 0.0006531270337291062
Discriminator Loss: 0.7230761051177979
Generator Loss: 0.6213245391845703
1:20.572087121130807

Epoch: 1065, iteration: 0
Autoencoder Loss: 0.0007086378755047917
Discriminator Loss: 0.7817829847335815
Generator Loss: 0.5503825545310974
1:20.42988115625953

Epoch: 1070, iteration: 0
Autoencoder Loss: 0.0007480776403099298
Discriminator Loss: 0.6865657567977905
Generator Loss: 0.9127956628799438
1:20.499992229790802

Epoch: 1075, iteration: 0
Autoencoder Loss: 0.0006136040319688618
Discriminator Loss: 0.7650201320648193
Generator Loss: 0.6514666676521301
1:20.70971282898704

Epoch: 1080, iteration: 0
Autoencoder Loss: 0.0006797665264457464
Discriminator Loss: 0.7336345911026001
Generator Loss: 0.6613687872886658
1:20.65642074117743

Epoch: 1085, iteration: 0
Autoencoder Loss: 0.0006526334909722209
Discriminator Loss: 0.7201868295669556
Generator Loss: 0.6358717679977417
1:20.761637772427516

Epoch: 1090, iteration: 0
Autoencoder Loss: 0.0006497427239082754
Discriminator Loss: 0.709321141242981
Generator Loss: 0.7107487320899963
1:20.624255347386153

Epoch: 1095, iteration: 0
Autoencoder Loss: 0.000644890358671546
Discriminator Loss: 0.7713155150413513
Generator Loss: 0.6141481995582581
1:20.553836564497097

Epoch: 1100, iteration: 0
Autoencoder Loss: 0.0007396001601591706
Discriminator Loss: 0.7694032192230225
Generator Loss: 0.7328423261642456
1:20.476594657510127

Epoch: 1105, iteration: 0
Autoencoder Loss: 0.0006761558470316231
Discriminator Loss: 0.7559729814529419
Generator Loss: 0.7075560092926025
1:20.515576156512374

Epoch: 1110, iteration: 0
Autoencoder Loss: 0.0006333525525406003
Discriminator Loss: 0.6999176740646362
Generator Loss: 0.6776177883148193
1:20.69498342993272

Epoch: 1115, iteration: 0
Autoencoder Loss: 0.0005478680250234902
Discriminator Loss: 0.7138917446136475
Generator Loss: 0.5491898059844971
1:20.734707266753002

Epoch: 1120, iteration: 0
Autoencoder Loss: 0.0006581414490938187
Discriminator Loss: 0.7206830978393555
Generator Loss: 0.6133711934089661
1:20.310428896838395

Epoch: 0, iteration: 0
Autoencoder Loss: 0.35608622431755066
Discriminator Loss: 0.8757208585739136
Generator Loss: 0.3507736623287201
1:8.066394399858327

Epoch: 5, iteration: 0
Autoencoder Loss: 0.004905251320451498
Discriminator Loss: 0.43974870443344116
Generator Loss: 1.071549415588379
1:17.494457720204295

Epoch: 10, iteration: 0
Autoencoder Loss: 0.0032549677416682243
Discriminator Loss: 0.6588188409805298
Generator Loss: 0.7699264287948608
1:17.651300594091456

Epoch: 15, iteration: 0
Autoencoder Loss: 0.0015804710565134883
Discriminator Loss: 0.7633711099624634
Generator Loss: 1.1283817291259766
1:19.857193393669753

Epoch: 20, iteration: 0
Autoencoder Loss: 0.0012688006972894073
Discriminator Loss: 0.6779451370239258
Generator Loss: 1.6398977041244507
1:19.503794329622192

Epoch: 25, iteration: 0
Autoencoder Loss: 0.001230041030794382
Discriminator Loss: 0.718432605266571
Generator Loss: 1.1239087581634521
1:19.26053678084426

Epoch: 30, iteration: 0
Autoencoder Loss: 0.0011674510315060616
Discriminator Loss: 0.7076512575149536
Generator Loss: 0.9538292288780212
1:19.029824838761517

Epoch: 35, iteration: 0
Autoencoder Loss: 0.0011427379213273525
Discriminator Loss: 0.7184116840362549
Generator Loss: 0.8153834342956543
1:18.786329020365546

Epoch: 40, iteration: 0
Autoencoder Loss: 0.00099950993899256
Discriminator Loss: 0.6827419996261597
Generator Loss: 1.0154778957366943
1:19.583278172725652

Epoch: 45, iteration: 0
Autoencoder Loss: 0.0010302860755473375
Discriminator Loss: 0.6458271741867065
Generator Loss: 1.0269826650619507
1:18.97927356929562

Epoch: 50, iteration: 0
Autoencoder Loss: 0.0011447251308709383
Discriminator Loss: 0.7609894871711731
Generator Loss: 0.6887343525886536
1:19.327308358693553

Epoch: 55, iteration: 0
Autoencoder Loss: 0.0009791820775717497
Discriminator Loss: 0.697667121887207
Generator Loss: 0.8700504302978516
1:19.462715523884476

Epoch: 60, iteration: 0
Autoencoder Loss: 0.0010090084979310632
Discriminator Loss: 0.7891830205917358
Generator Loss: 0.6798095107078552
1:19.539194681209196

Epoch: 65, iteration: 0
Autoencoder Loss: 0.0009174163569696248
Discriminator Loss: 0.6908153891563416
Generator Loss: 0.8625102639198303
1:19.302917862822593

Epoch: 70, iteration: 0
Autoencoder Loss: 0.0008664785418659449
Discriminator Loss: 0.6709963083267212
Generator Loss: 0.8699344396591187
1:19.32086328325662

Epoch: 75, iteration: 0
Autoencoder Loss: 0.0009250907460227609
Discriminator Loss: 0.7242854237556458
Generator Loss: 0.6993589997291565
1:19.475556755443094

Epoch: 80, iteration: 0
Autoencoder Loss: 0.0009525686036795378
Discriminator Loss: 0.6997138261795044
Generator Loss: 0.725214958190918
1:19.832969817516503

Epoch: 85, iteration: 0
Autoencoder Loss: 0.0009320690878666937
Discriminator Loss: 0.7678569555282593
Generator Loss: 0.6206530332565308
1:19.662987547209685

Epoch: 90, iteration: 0
Autoencoder Loss: 0.0008800621144473553
Discriminator Loss: 0.7231544256210327
Generator Loss: 0.7064051628112793
1:19.60608475316986

Epoch: 95, iteration: 0
Autoencoder Loss: 0.0008961223647929728
Discriminator Loss: 0.7139681577682495
Generator Loss: 0.7139551043510437
1:19.53943614765145

Epoch: 100, iteration: 0
Autoencoder Loss: 0.000922563427593559
Discriminator Loss: 0.7355135679244995
Generator Loss: 0.6704152822494507
1:19.72832145342478

Epoch: 105, iteration: 0
Autoencoder Loss: 0.0009275599732063711
Discriminator Loss: 0.7166252732276917
Generator Loss: 0.7193763256072998
1:19.56670741544449

Epoch: 110, iteration: 0
Autoencoder Loss: 0.0008563530282117426
Discriminator Loss: 0.812016487121582
Generator Loss: 0.5639846920967102
1:19.851827872751002

Epoch: 115, iteration: 0
Autoencoder Loss: 0.0008045122376643121
Discriminator Loss: 0.73658287525177
Generator Loss: 0.7311535477638245
1:19.76181292179895

Epoch: 120, iteration: 0
Autoencoder Loss: 0.0009079385781660676
Discriminator Loss: 0.7115710973739624
Generator Loss: 0.8330839276313782
1:20.093396014731905

Epoch: 125, iteration: 0
Autoencoder Loss: 0.0007790021481923759
Discriminator Loss: 0.7138404846191406
Generator Loss: 0.7790622115135193
1:19.590930724733145

Epoch: 130, iteration: 0
Autoencoder Loss: 0.0008433982147835195
Discriminator Loss: 0.7255796194076538
Generator Loss: 0.6619431972503662
1:19.481808169756697

Epoch: 135, iteration: 0
Autoencoder Loss: 0.0008731723064556718
Discriminator Loss: 0.8014276027679443
Generator Loss: 0.5631313323974609
1:19.692578931432895

Epoch: 140, iteration: 0
Autoencoder Loss: 0.000835895596537739
Discriminator Loss: 0.7649369239807129
Generator Loss: 0.7643499374389648
1:19.700089388609072

Epoch: 145, iteration: 0
Autoencoder Loss: 0.0008430199231952429
Discriminator Loss: 0.7929632663726807
Generator Loss: 0.6825525760650635
1:19.768944284219167

Epoch: 150, iteration: 0
Autoencoder Loss: 0.0008133441442623734
Discriminator Loss: 0.7410913705825806
Generator Loss: 0.7085118889808655
1:20.057245705026737

Epoch: 155, iteration: 0
Autoencoder Loss: 0.0007787753129377961
Discriminator Loss: 0.7226865291595459
Generator Loss: 0.6388346552848816
1:20.336337995923977

Epoch: 160, iteration: 0
Autoencoder Loss: 0.000898077036254108
Discriminator Loss: 0.76485276222229
Generator Loss: 0.6269683837890625
1:20.07289086758591

Epoch: 165, iteration: 0
Autoencoder Loss: 0.0008799118804745376
Discriminator Loss: 0.781643271446228
Generator Loss: 0.7092103958129883
1:19.980337832528697

Epoch: 170, iteration: 0
Autoencoder Loss: 0.0007924969540908933
Discriminator Loss: 0.7556235194206238
Generator Loss: 0.7406635284423828
1:20.006603725625848

Epoch: 175, iteration: 0
Autoencoder Loss: 0.0007881583296693861
Discriminator Loss: 0.7707010507583618
Generator Loss: 0.6787172555923462
1:19.918515042935727

Epoch: 180, iteration: 0
Autoencoder Loss: 0.000785966229159385
Discriminator Loss: 0.7830650806427002
Generator Loss: 0.5898062586784363
1:20.0672624687634

Epoch: 185, iteration: 0
Autoencoder Loss: 0.0008905929862521589
Discriminator Loss: 0.6794540286064148
Generator Loss: 0.7631599307060242
1:20.041235119873996

Epoch: 190, iteration: 0
Autoencoder Loss: 0.0008720496552996337
Discriminator Loss: 0.7901239991188049
Generator Loss: 0.5567817091941833
1:20.192600155568464

Epoch: 195, iteration: 0
Autoencoder Loss: 0.0008463714621029794
Discriminator Loss: 0.7457113265991211
Generator Loss: 0.8388733267784119
1:20.208179552800146

Epoch: 200, iteration: 0
Autoencoder Loss: 0.0007883888320066035
Discriminator Loss: 0.8969887495040894
Generator Loss: 0.48348838090896606
1:20.13714743006352

Epoch: 205, iteration: 0
Autoencoder Loss: 0.0008679423481225967
Discriminator Loss: 0.7723322510719299
Generator Loss: 0.7278674244880676
1:20.11799514644173

Epoch: 210, iteration: 0
Autoencoder Loss: 0.0007597617222927511
Discriminator Loss: 0.7943671941757202
Generator Loss: 0.6989424824714661
1:19.804823326542895

Epoch: 215, iteration: 0
Autoencoder Loss: 0.0008257446461357176
Discriminator Loss: 0.7534981966018677
Generator Loss: 0.7113045454025269
1:20.068973914186383

Epoch: 220, iteration: 0
Autoencoder Loss: 0.0006980616017244756
Discriminator Loss: 0.7061652541160583
Generator Loss: 0.6675950288772583
1:20.15849634652879

Epoch: 225, iteration: 0
Autoencoder Loss: 0.0007843882194720209
Discriminator Loss: 0.7214605808258057
Generator Loss: 0.6231879591941833
1:20.071559297753247

Epoch: 230, iteration: 0
Autoencoder Loss: 0.0007733275415375829
Discriminator Loss: 0.785824179649353
Generator Loss: 0.6402326822280884
1:20.241694847659456

Epoch: 235, iteration: 0
Autoencoder Loss: 0.000877568032592535
Discriminator Loss: 0.7857182025909424
Generator Loss: 0.7309946417808533
1:20.08608894459651

Epoch: 240, iteration: 0
Autoencoder Loss: 0.0007576690404675901
Discriminator Loss: 0.8521076440811157
Generator Loss: 0.6422457695007324
1:19.89791047964239

Epoch: 245, iteration: 0
Autoencoder Loss: 0.0007529404829256237
Discriminator Loss: 0.7484070062637329
Generator Loss: 0.6995343565940857
1:20.134960913315957

Epoch: 250, iteration: 0
Autoencoder Loss: 0.0007647680467925966
Discriminator Loss: 0.7145736813545227
Generator Loss: 0.7104685306549072
1:20.099966875499604

Epoch: 255, iteration: 0
Autoencoder Loss: 0.000729748688172549
Discriminator Loss: 0.7153162956237793
Generator Loss: 0.7609409093856812
1:20.274648345640177

Epoch: 260, iteration: 0
Autoencoder Loss: 0.0007594384951516986
Discriminator Loss: 0.7770556807518005
Generator Loss: 0.7401667833328247
1:20.498244381304968

Epoch: 265, iteration: 0
Autoencoder Loss: 0.000718063092790544
Discriminator Loss: 0.7981454133987427
Generator Loss: 0.6656903624534607
1:20.325858880265383

Epoch: 270, iteration: 0
Autoencoder Loss: 0.0007271011709235609
Discriminator Loss: 0.7973368167877197
Generator Loss: 0.6140469312667847
1:20.28549070006646

Epoch: 275, iteration: 0
Autoencoder Loss: 0.00069882080424577
Discriminator Loss: 0.7780801653862
Generator Loss: 0.5899963974952698
1:20.240065888436867

Epoch: 280, iteration: 0
Autoencoder Loss: 0.0007819997845217586
Discriminator Loss: 0.7666459679603577
Generator Loss: 0.6051074266433716
1:20.17094494800542

Epoch: 285, iteration: 0
Autoencoder Loss: 0.0007801826577633619
Discriminator Loss: 0.7555665969848633
Generator Loss: 0.6596588492393494
1:20.281987278853293

Epoch: 290, iteration: 0
Autoencoder Loss: 0.0006846027681604028
Discriminator Loss: 0.7316186428070068
Generator Loss: 0.7522986531257629
1:20.237630538775953

Epoch: 295, iteration: 0
Autoencoder Loss: 0.0007395604043267667
Discriminator Loss: 0.7169286012649536
Generator Loss: 0.6885432004928589
1:20.36275335520614

Epoch: 300, iteration: 0
Autoencoder Loss: 0.0006665554828941822
Discriminator Loss: 0.6906431913375854
Generator Loss: 0.7239429354667664
1:20.173419432821362

Epoch: 305, iteration: 0
Autoencoder Loss: 0.0007309630163945258
Discriminator Loss: 0.7757972478866577
Generator Loss: 0.6654401421546936
1:20.371928974892214

Epoch: 310, iteration: 0
Autoencoder Loss: 0.0007606051512993872
Discriminator Loss: 0.8055447340011597
Generator Loss: 0.6712496280670166
1:20.077732293988966

Epoch: 315, iteration: 0
Autoencoder Loss: 0.0006863757153041661
Discriminator Loss: 0.7301190495491028
Generator Loss: 0.7209538221359253
1:20.295977083205557

Epoch: 320, iteration: 0
Autoencoder Loss: 0.0006944391643628478
Discriminator Loss: 0.8055552244186401
Generator Loss: 0.5188901424407959
1:20.201526200749885

Epoch: 325, iteration: 0
Autoencoder Loss: 0.0006939744926057756
Discriminator Loss: 0.7066393494606018
Generator Loss: 0.6506428718566895
1:20.43201469839039

Epoch: 330, iteration: 0
Autoencoder Loss: 0.0007100586663000286
Discriminator Loss: 0.6299476623535156
Generator Loss: 0.8621762990951538
1:20.29648172163085

Epoch: 335, iteration: 0
Autoencoder Loss: 0.0007014331640675664
Discriminator Loss: 0.7595130205154419
Generator Loss: 0.6323317885398865
1:20.095107278825854

Epoch: 340, iteration: 0
Autoencoder Loss: 0.0007270392379723489
Discriminator Loss: 0.8028504252433777
Generator Loss: 0.5722209215164185
1:20.332663119153715

Epoch: 345, iteration: 0
Autoencoder Loss: 0.0007619945681653917
Discriminator Loss: 0.74032062292099
Generator Loss: 0.7796815633773804
1:20.286178137496552

Epoch: 350, iteration: 0
Autoencoder Loss: 0.0006898469873704016
Discriminator Loss: 0.741692066192627
Generator Loss: 0.7523062229156494
1:20.151636882148686

Epoch: 355, iteration: 0
Autoencoder Loss: 0.0006307454314082861
Discriminator Loss: 0.7387193441390991
Generator Loss: 0.6056497693061829
1:20.47572488256778

Epoch: 360, iteration: 0
Autoencoder Loss: 0.0007518331985920668
Discriminator Loss: 0.6955274343490601
Generator Loss: 0.6988779902458191
1:20.34209563979776

Epoch: 365, iteration: 0
Autoencoder Loss: 0.0007963882526382804
Discriminator Loss: 0.8669663667678833
Generator Loss: 0.5537030696868896
1:19.93570366826811

Epoch: 370, iteration: 0
Autoencoder Loss: 0.0007669891347177327
Discriminator Loss: 0.8172980546951294
Generator Loss: 0.843453586101532
1:20.055727259034875

Epoch: 375, iteration: 0
Autoencoder Loss: 0.0007043145014904439
Discriminator Loss: 0.8358230590820312
Generator Loss: 0.5765033960342407
1:20.300949420221563

Epoch: 380, iteration: 0
Autoencoder Loss: 0.000678612501360476
Discriminator Loss: 0.6867469549179077
Generator Loss: 0.6974761486053467
1:20.398334743554546

Epoch: 385, iteration: 0
Autoencoder Loss: 0.0007204392459243536
Discriminator Loss: 0.7295070886611938
Generator Loss: 0.5901010632514954
1:20.24056405216843

Epoch: 390, iteration: 0
Autoencoder Loss: 0.000868774252012372
Discriminator Loss: 0.7341451644897461
Generator Loss: 0.7498244047164917
1:20.23543367306023

Epoch: 395, iteration: 0
Autoencoder Loss: 0.0008339309133589268
Discriminator Loss: 0.7722158432006836
Generator Loss: 0.9508029818534851
1:19.57372272860878

Epoch: 400, iteration: 0
Autoencoder Loss: 0.0006392706418409944
Discriminator Loss: 0.8348880410194397
Generator Loss: 0.6297802925109863
1:20.276263068650955

Epoch: 405, iteration: 0
Autoencoder Loss: 0.0006523217307403684
Discriminator Loss: 0.7737737894058228
Generator Loss: 0.5731161236763
1:20.312364923541168

Epoch: 410, iteration: 0
Autoencoder Loss: 0.0006505409255623817
Discriminator Loss: 0.663865327835083
Generator Loss: 0.7798954844474792
1:20.28325308357594

Epoch: 415, iteration: 0
Autoencoder Loss: 0.0007251842762343585
Discriminator Loss: 0.8204238414764404
Generator Loss: 0.4835204780101776
1:20.1911167814005

Epoch: 420, iteration: 0
Autoencoder Loss: 0.0008539799018763006
Discriminator Loss: 0.71088707447052
Generator Loss: 0.9167028069496155
1:19.303092333801224

Epoch: 425, iteration: 0
Autoencoder Loss: 0.0007255728705786169
Discriminator Loss: 0.8217915296554565
Generator Loss: 0.6387824416160583
1:20.264829676534678

Epoch: 430, iteration: 0
Autoencoder Loss: 0.0006040215957909822
Discriminator Loss: 0.7342633008956909
Generator Loss: 0.6193440556526184
1:20.552504105680836

Epoch: 435, iteration: 0
Autoencoder Loss: 0.0007124310941435397
Discriminator Loss: 0.6896488666534424
Generator Loss: 0.6726773977279663
1:20.068634612545125

Epoch: 440, iteration: 0
Autoencoder Loss: 0.0007141029345802963
Discriminator Loss: 0.7583185434341431
Generator Loss: 0.5928477048873901
1:19.96851260762847

Epoch: 445, iteration: 0
Autoencoder Loss: 0.0007694439264014363
Discriminator Loss: 0.734001874923706
Generator Loss: 0.8520282506942749
1:20.070093797808816

Epoch: 450, iteration: 0
Autoencoder Loss: 0.0006756568909622729
Discriminator Loss: 0.84715735912323
Generator Loss: 0.5628418922424316
1:20.41026636150309

Epoch: 455, iteration: 0
Autoencoder Loss: 0.0006533206906169653
Discriminator Loss: 0.7316051125526428
Generator Loss: 0.6915946006774902
1:20.287218963161987

Epoch: 460, iteration: 0
Autoencoder Loss: 0.0005938738468103111
Discriminator Loss: 0.7081118822097778
Generator Loss: 0.6631374955177307
1:20.301492684844792

Epoch: 465, iteration: 0
Autoencoder Loss: 0.0007101517403498292
Discriminator Loss: 0.7202885150909424
Generator Loss: 0.6466710567474365
1:20.082356749897706

Epoch: 470, iteration: 0
Autoencoder Loss: 0.0007581075769849122
Discriminator Loss: 0.7194347381591797
Generator Loss: 0.7830445766448975
1:19.98782343418831

Epoch: 475, iteration: 0
Autoencoder Loss: 0.0006837047985754907
Discriminator Loss: 0.8683691620826721
Generator Loss: 0.5065587162971497
1:20.175443698253353

Epoch: 480, iteration: 0
Autoencoder Loss: 0.000606980815064162
Discriminator Loss: 0.7884577512741089
Generator Loss: 0.5904541611671448
1:20.533105506147482

Epoch: 485, iteration: 0
Autoencoder Loss: 0.0006622680812142789
Discriminator Loss: 0.7257146239280701
Generator Loss: 0.6606533527374268
1:20.46982083652035

Epoch: 490, iteration: 0
Autoencoder Loss: 0.0006943871849216521
Discriminator Loss: 0.7188517451286316
Generator Loss: 0.6104722619056702
1:20.300836907118946

Epoch: 495, iteration: 0
Autoencoder Loss: 0.0007861601770855486
Discriminator Loss: 0.635245680809021
Generator Loss: 0.9285992383956909
1:20.31700922287992

Epoch: 500, iteration: 0
Autoencoder Loss: 0.0007505553076043725
Discriminator Loss: 0.8018321990966797
Generator Loss: 0.6198222041130066
1:19.81361301657816

Epoch: 505, iteration: 0
Autoencoder Loss: 0.0007087088306434453
Discriminator Loss: 0.730171263217926
Generator Loss: 0.8630872368812561
1:20.190517165418992

Epoch: 510, iteration: 0
Autoencoder Loss: 0.0006567927775904536
Discriminator Loss: 0.7642285823822021
Generator Loss: 0.5943115949630737
1:20.671685805635246

Epoch: 515, iteration: 0
Autoencoder Loss: 0.0005874537746421993
Discriminator Loss: 0.6894587278366089
Generator Loss: 0.6159713268280029
1:20.70356269851549

Epoch: 520, iteration: 0
Autoencoder Loss: 0.0006533022387884557
Discriminator Loss: 0.6807436347007751
Generator Loss: 0.6843245029449463
1:20.44562113284805

Epoch: 525, iteration: 0
Autoencoder Loss: 0.0007906827377155423
Discriminator Loss: 0.6895366907119751
Generator Loss: 0.9408752918243408
1:20.46548316583927

Epoch: 530, iteration: 0
Autoencoder Loss: 0.0007262896397151053
Discriminator Loss: 0.8208338022232056
Generator Loss: 0.7087950110435486
1:20.585765605892924

Epoch: 535, iteration: 0
Autoencoder Loss: 0.0006282152608036995
Discriminator Loss: 0.7586822509765625
Generator Loss: 0.6103429794311523
1:20.717334182909276

Epoch: 540, iteration: 0
Autoencoder Loss: 0.0006982967024669051
Discriminator Loss: 0.6264907121658325
Generator Loss: 0.8651864528656006
1:20.317863610895284

Epoch: 545, iteration: 0
Autoencoder Loss: 0.0007652739295735955
Discriminator Loss: 0.7391407489776611
Generator Loss: 0.6509542465209961
1:20.34961498957514

Epoch: 550, iteration: 0
Autoencoder Loss: 0.0006890012882649899
Discriminator Loss: 0.6987560987472534
Generator Loss: 0.7556465268135071
1:20.459506451342104

Epoch: 555, iteration: 0
Autoencoder Loss: 0.0006681033410131931
Discriminator Loss: 0.7509337067604065
Generator Loss: 0.6961156725883484
1:20.338617021068018

Epoch: 560, iteration: 0
Autoencoder Loss: 0.0006726045976392925
Discriminator Loss: 0.7471569180488586
Generator Loss: 0.6407197713851929
1:20.633980076377824

Epoch: 565, iteration: 0
Autoencoder Loss: 0.0007576267817057669
Discriminator Loss: 0.7006860971450806
Generator Loss: 0.683974027633667
1:20.625173759703358

Epoch: 570, iteration: 0
Autoencoder Loss: 0.0007280682330019772
Discriminator Loss: 0.7952923774719238
Generator Loss: 0.5742266178131104
1:20.42741218932891

Epoch: 575, iteration: 0
Autoencoder Loss: 0.0006682758103124797
Discriminator Loss: 0.7962207794189453
Generator Loss: 0.5585154891014099
1:20.605465880047454

Epoch: 580, iteration: 0
Autoencoder Loss: 0.0006743324920535088
Discriminator Loss: 0.7183563113212585
Generator Loss: 0.8353475332260132
1:20.458242336113038

Epoch: 585, iteration: 0
Autoencoder Loss: 0.0006433972739614546
Discriminator Loss: 0.7688027024269104
Generator Loss: 0.6451177000999451
1:20.262546318927328

Epoch: 590, iteration: 0
Autoencoder Loss: 0.0006533187115564942
Discriminator Loss: 0.7733508348464966
Generator Loss: 0.5757706165313721
1:20.585081181014658

Epoch: 595, iteration: 0
Autoencoder Loss: 0.0006844112649559975
Discriminator Loss: 0.7170513868331909
Generator Loss: 0.7639341950416565
1:20.528674580557976

Epoch: 600, iteration: 0
Autoencoder Loss: 0.000662748352624476
Discriminator Loss: 0.7979552745819092
Generator Loss: 0.5998167991638184
1:20.36144873203601

Epoch: 605, iteration: 0
Autoencoder Loss: 0.0006562837515957654
Discriminator Loss: 0.752198338508606
Generator Loss: 0.727885901927948
1:20.325262465784128

Epoch: 610, iteration: 0
Autoencoder Loss: 0.0006667329580523074
Discriminator Loss: 0.7806190252304077
Generator Loss: 0.577210545539856
1:20.50265428582223

Epoch: 615, iteration: 0
Autoencoder Loss: 0.0006369511829689145
Discriminator Loss: 0.7020529508590698
Generator Loss: 0.6881181001663208
1:20.482675533602787

Epoch: 620, iteration: 0
Autoencoder Loss: 0.0006731479079462588
Discriminator Loss: 0.7614718675613403
Generator Loss: 0.5444176197052002
1:20.32632784108623

Epoch: 625, iteration: 0
Autoencoder Loss: 0.0008062641718424857
Discriminator Loss: 0.7610445022583008
Generator Loss: 0.7970187664031982
1:20.542606712921003

Epoch: 630, iteration: 0
Autoencoder Loss: 0.0006385059095919132
Discriminator Loss: 0.8536213636398315
Generator Loss: 0.6137855052947998
1:20.44898878121095

Epoch: 635, iteration: 0
Autoencoder Loss: 0.0006109853857196867
Discriminator Loss: 0.7480511665344238
Generator Loss: 0.6488412618637085
1:20.376103940356266

Epoch: 640, iteration: 0
Autoencoder Loss: 0.0006213377346284688
Discriminator Loss: 0.673014760017395
Generator Loss: 0.6550270915031433
1:20.57568951887618

Epoch: 645, iteration: 0
Autoencoder Loss: 0.0006690535810776055
Discriminator Loss: 0.6877760291099548
Generator Loss: 0.6251801252365112
1:20.289030532266658

Epoch: 650, iteration: 0
Autoencoder Loss: 0.001183709711767733
Discriminator Loss: 0.8010556697845459
Generator Loss: 0.699116587638855
1:19.927240487254444

Epoch: 655, iteration: 0
Autoencoder Loss: 0.000872518343385309
Discriminator Loss: 0.8903472423553467
Generator Loss: 0.6941874027252197
1:20.42797418317605

Epoch: 660, iteration: 0
Autoencoder Loss: 0.0006180546479299664
Discriminator Loss: 0.7870946526527405
Generator Loss: 0.6142246127128601
1:20.655028070717727

Epoch: 665, iteration: 0
Autoencoder Loss: 0.0007527051493525505
Discriminator Loss: 0.6719744205474854
Generator Loss: 0.712933361530304
1:20.363412664755888

Epoch: 670, iteration: 0
Autoencoder Loss: 0.0007136076455935836
Discriminator Loss: 0.6446706056594849
Generator Loss: 0.8989951610565186
1:20.446418117823097

Epoch: 675, iteration: 0
Autoencoder Loss: 0.0008846835698932409
Discriminator Loss: 0.7538406848907471
Generator Loss: 0.7945592403411865
1:20.438931255726477

Epoch: 680, iteration: 0
Autoencoder Loss: 0.0006501771858893335
Discriminator Loss: 0.7771201133728027
Generator Loss: 0.6334347724914551
1:20.78562837712255

Epoch: 685, iteration: 0
Autoencoder Loss: 0.0006659789942204952
Discriminator Loss: 0.7453218102455139
Generator Loss: 0.5660083889961243
1:20.598009753451592

Epoch: 690, iteration: 0
Autoencoder Loss: 0.0006704435218125582
Discriminator Loss: 0.6721388101577759
Generator Loss: 0.7129381895065308
1:20.390550377564036

Epoch: 695, iteration: 0
Autoencoder Loss: 0.0007281724247150123
Discriminator Loss: 0.748226523399353
Generator Loss: 0.6143116354942322
1:20.369021925573165

Epoch: 700, iteration: 0
Autoencoder Loss: 0.0008211192907765508
Discriminator Loss: 0.7283413410186768
Generator Loss: 0.7888203263282776
1:20.273783313038397

Epoch: 705, iteration: 0
Autoencoder Loss: 0.0006553169805556536
Discriminator Loss: 0.771652340888977
Generator Loss: 0.6391229033470154
1:20.482434649618206

Epoch: 710, iteration: 0
Autoencoder Loss: 0.0006728038424625993
Discriminator Loss: 0.775202214717865
Generator Loss: 0.6096193194389343
1:20.618319972292156

Epoch: 715, iteration: 0
Autoencoder Loss: 0.0006699801306240261
Discriminator Loss: 0.7278463244438171
Generator Loss: 0.65988689661026
1:20.633247100683455

Epoch: 720, iteration: 0
Autoencoder Loss: 0.0006788461469113827
Discriminator Loss: 0.6763640642166138
Generator Loss: 0.6886159181594849
1:20.305183526394984

Epoch: 725, iteration: 0
Autoencoder Loss: 0.0009038191055878997
Discriminator Loss: 0.7279965281486511
Generator Loss: 0.7380773425102234
1:20.776780760185453

Epoch: 730, iteration: 0
Autoencoder Loss: 0.0007794941193424165
Discriminator Loss: 0.8581360578536987
Generator Loss: 0.6463577151298523
1:20.374848882963747

Epoch: 735, iteration: 0
Autoencoder Loss: 0.0006368288304656744
Discriminator Loss: 0.7783358693122864
Generator Loss: 0.6266427040100098
1:20.585783601533162

Epoch: 740, iteration: 0
Autoencoder Loss: 0.0006332268239930272
Discriminator Loss: 0.6803524494171143
Generator Loss: 0.6631893515586853
1:20.570580838062323

Epoch: 745, iteration: 0
Autoencoder Loss: 0.0006668422720395029
Discriminator Loss: 0.7160165309906006
Generator Loss: 0.6074371337890625
1:20.483389636971424

Epoch: 750, iteration: 0
Autoencoder Loss: 0.0007603368139825761
Discriminator Loss: 0.7352687120437622
Generator Loss: 0.7157781720161438
1:20.63308497602862

Epoch: 755, iteration: 0
Autoencoder Loss: 0.0007327935891225934
Discriminator Loss: 0.8361637592315674
Generator Loss: 0.6572312116622925
1:20.559977381111185

Epoch: 760, iteration: 0
Autoencoder Loss: 0.00067520682932809
Discriminator Loss: 0.7864450812339783
Generator Loss: 0.5974963903427124
1:20.674523173282914

Epoch: 765, iteration: 0
Autoencoder Loss: 0.0006729405140504241
Discriminator Loss: 0.7075619697570801
Generator Loss: 0.6718499064445496
1:20.6775099169934

Epoch: 770, iteration: 0
Autoencoder Loss: 0.0006451641675084829
Discriminator Loss: 0.6845791339874268
Generator Loss: 0.6987525820732117
1:20.18338594187672

Epoch: 775, iteration: 0
Autoencoder Loss: 0.000728046812582761
Discriminator Loss: 0.6882146000862122
Generator Loss: 0.8318552374839783
1:20.1857262052406

Epoch: 780, iteration: 0
Autoencoder Loss: 0.0007463275687769055
Discriminator Loss: 0.7828949093818665
Generator Loss: 0.694018542766571
1:20.696128047757067

Epoch: 785, iteration: 0
Autoencoder Loss: 0.0006500500603578985
Discriminator Loss: 0.722642183303833
Generator Loss: 0.7760696411132812
1:20.530339819487722

Epoch: 790, iteration: 0
Autoencoder Loss: 0.0005897031514905393
Discriminator Loss: 0.7117612361907959
Generator Loss: 0.6258848309516907
1:20.67930831734923

Epoch: 795, iteration: 0
Autoencoder Loss: 0.0005901113036088645
Discriminator Loss: 0.7216421961784363
Generator Loss: 0.5630924701690674
1:20.3812062533477

Epoch: 800, iteration: 0
Autoencoder Loss: 0.000716583919711411
Discriminator Loss: 0.6695745587348938
Generator Loss: 0.7797977328300476
1:20.072263609168534

Epoch: 805, iteration: 0
Autoencoder Loss: 0.001164361834526062
Discriminator Loss: 0.7194228172302246
Generator Loss: 1.168725609779358
1:20.376492339115522

Epoch: 810, iteration: 0
Autoencoder Loss: 0.0005983830778859556
Discriminator Loss: 0.8206263780593872
Generator Loss: 0.5971492528915405
1:20.645655155207674

Epoch: 815, iteration: 0
Autoencoder Loss: 0.0006758279050700366
Discriminator Loss: 0.7118954658508301
Generator Loss: 0.6777060627937317
1:20.452747132189305

Epoch: 820, iteration: 0
Autoencoder Loss: 0.0006556343869306147
Discriminator Loss: 0.7000190019607544
Generator Loss: 0.6302374601364136
1:20.45648208613255

Epoch: 825, iteration: 0
Autoencoder Loss: 0.0007869668188504875
Discriminator Loss: 0.7247691750526428
Generator Loss: 0.7577931880950928
1:20.040906464635547

Epoch: 830, iteration: 0
Autoencoder Loss: 0.0008074941579252481
Discriminator Loss: 0.7461674213409424
Generator Loss: 1.0527701377868652
1:20.444385272277007

Epoch: 835, iteration: 0
Autoencoder Loss: 0.0006705052801407874
Discriminator Loss: 0.8219289779663086
Generator Loss: 0.6056218147277832
1:20.649968452570736

Epoch: 840, iteration: 0
Autoencoder Loss: 0.000672457623295486
Discriminator Loss: 0.7406558990478516
Generator Loss: 0.624278724193573
1:20.402250447815394

Epoch: 845, iteration: 0
Autoencoder Loss: 0.0006639808416366577
Discriminator Loss: 0.7168434858322144
Generator Loss: 0.6470022201538086
1:20.599742268615966

Epoch: 850, iteration: 0
Autoencoder Loss: 0.0006978213205002248
Discriminator Loss: 0.6928256750106812
Generator Loss: 0.619279146194458
1:20.63948178597522

Epoch: 855, iteration: 0
Autoencoder Loss: 0.0006421427824534476
Discriminator Loss: 0.649946928024292
Generator Loss: 0.6707382202148438
1:20.605234810517715

Epoch: 860, iteration: 0
Autoencoder Loss: 0.000741459196433425
Discriminator Loss: 0.7627161741256714
Generator Loss: 0.5824772715568542
1:20.436740911918143

Epoch: 865, iteration: 0
Autoencoder Loss: 0.0012219407362863421
Discriminator Loss: 0.6879592537879944
Generator Loss: 1.3571946620941162
1:19.85623140687504

Epoch: 870, iteration: 0
Autoencoder Loss: 0.0006346594891510904
Discriminator Loss: 0.8480395674705505
Generator Loss: 0.6465284824371338
1:20.79915711935296

Epoch: 875, iteration: 0
Autoencoder Loss: 0.0006210222491063178
Discriminator Loss: 0.7744913697242737
Generator Loss: 0.5841827392578125
1:20.689246729539306

Epoch: 880, iteration: 0
Autoencoder Loss: 0.0006546016084030271
Discriminator Loss: 0.6623362302780151
Generator Loss: 0.681792140007019
1:20.55144094811089

Epoch: 885, iteration: 0
Autoencoder Loss: 0.0006580832996405661
Discriminator Loss: 0.6348504424095154
Generator Loss: 0.7295954823493958
1:20.18779916600963

Epoch: 890, iteration: 0
Autoencoder Loss: 0.0007959251524880528
Discriminator Loss: 0.7349791526794434
Generator Loss: 0.7796902656555176
1:20.275262799171948

Epoch: 895, iteration: 0
Autoencoder Loss: 0.0007575491326861084
Discriminator Loss: 0.7914757132530212
Generator Loss: 0.7747987508773804
1:20.588178332977805

Epoch: 900, iteration: 0
Autoencoder Loss: 0.0005987351178191602
Discriminator Loss: 0.7653223276138306
Generator Loss: 0.6215527057647705
1:20.832110322556364

Epoch: 905, iteration: 0
Autoencoder Loss: 0.000616936944425106
Discriminator Loss: 0.6765042543411255
Generator Loss: 0.6846359968185425
1:20.594883586702966

Epoch: 910, iteration: 0
Autoencoder Loss: 0.000643958686850965
Discriminator Loss: 0.6689313054084778
Generator Loss: 0.6388819813728333
1:20.795142605270872

Epoch: 915, iteration: 0
Autoencoder Loss: 0.0008328381809405982
Discriminator Loss: 0.6782037019729614
Generator Loss: 0.868767261505127
1:20.356034514248023

Epoch: 920, iteration: 0
Autoencoder Loss: 0.0006977638695389032
Discriminator Loss: 0.7668696641921997
Generator Loss: 0.7711690664291382
1:20.644777088474374

Epoch: 925, iteration: 0
Autoencoder Loss: 0.000696997856721282
Discriminator Loss: 0.7616410255432129
Generator Loss: 0.6503109335899353
1:20.560206393464334

Epoch: 930, iteration: 0
Autoencoder Loss: 0.0006474799010902643
Discriminator Loss: 0.7288362383842468
Generator Loss: 0.6265672445297241
1:20.669389377710022

Epoch: 935, iteration: 0
Autoencoder Loss: 0.0006145582301542163
Discriminator Loss: 0.7393231391906738
Generator Loss: 0.5965408086776733
1:20.569686296001315

Epoch: 940, iteration: 0
Autoencoder Loss: 0.000635881966445595
Discriminator Loss: 0.7043676376342773
Generator Loss: 0.7452290058135986
1:20.504461563080326

Epoch: 945, iteration: 0
Autoencoder Loss: 0.0006621168577112257
Discriminator Loss: 0.7682843208312988
Generator Loss: 0.6171569228172302
1:20.467918111048114

Epoch: 950, iteration: 0
Autoencoder Loss: 0.0006903690518811345
Discriminator Loss: 0.7836899757385254
Generator Loss: 0.7138687372207642
1:20.50026454139597

Epoch: 955, iteration: 0
Autoencoder Loss: 0.0006489612860605121
Discriminator Loss: 0.7923159599304199
Generator Loss: 0.6318082809448242
1:20.735145796779484

Epoch: 960, iteration: 0
Autoencoder Loss: 0.0006269285804592073
Discriminator Loss: 0.7210855484008789
Generator Loss: 0.6305069327354431
1:20.617271367003184

Epoch: 965, iteration: 0
Autoencoder Loss: 0.0006013931706547737
Discriminator Loss: 0.6744953393936157
Generator Loss: 0.672380268573761
1:20.463025723590647

Epoch: 970, iteration: 0
Autoencoder Loss: 0.0006484663463197649
Discriminator Loss: 0.7496660947799683
Generator Loss: 0.5746449828147888
1:20.6109924485869

Epoch: 975, iteration: 0
Autoencoder Loss: 0.0008017959771677852
Discriminator Loss: 0.724587082862854
Generator Loss: 0.9625447392463684
1:19.90661792105447

Epoch: 980, iteration: 0
Autoencoder Loss: 0.0006515702116303146
Discriminator Loss: 0.8104783296585083
Generator Loss: 0.6079245805740356
1:20.590026470040634

Epoch: 985, iteration: 0
Autoencoder Loss: 0.000618841266259551
Discriminator Loss: 0.738156795501709
Generator Loss: 0.6554805040359497
1:20.547076043430337

Epoch: 990, iteration: 0
Autoencoder Loss: 0.00064990104874596
Discriminator Loss: 0.7498642206192017
Generator Loss: 0.563179075717926
1:20.422238933010878

Epoch: 995, iteration: 0
Autoencoder Loss: 0.0006272913888096809
Discriminator Loss: 0.6847459077835083
Generator Loss: 0.644834578037262
1:20.602390207348122

Epoch: 1000, iteration: 0
Autoencoder Loss: 0.0008284550858661532
Discriminator Loss: 0.7100756168365479
Generator Loss: 0.7232945561408997
1:20.212821819079302

Epoch: 1005, iteration: 0
Autoencoder Loss: 0.000760587106924504
Discriminator Loss: 0.7954007387161255
Generator Loss: 0.8407273292541504
1:20.409629087596926

Epoch: 1010, iteration: 0
Autoencoder Loss: 0.0006684878608211875
Discriminator Loss: 0.8078114986419678
Generator Loss: 0.6335870027542114
1:20.51927337184605

Epoch: 1015, iteration: 0
Autoencoder Loss: 0.0006278978544287384
Discriminator Loss: 0.727473258972168
Generator Loss: 0.6034792065620422
1:20.587915510246575

Epoch: 1020, iteration: 0
Autoencoder Loss: 0.0006584381917491555
Discriminator Loss: 0.6953691840171814
Generator Loss: 0.655462384223938
1:20.57320043717184

Epoch: 1025, iteration: 0
Autoencoder Loss: 0.0006904326728545129
Discriminator Loss: 0.6846820712089539
Generator Loss: 0.8458462953567505
1:20.18965445101191

Epoch: 1030, iteration: 0
Autoencoder Loss: 0.0006842533475719392
Discriminator Loss: 0.7069109678268433
Generator Loss: 0.9086207151412964
1:20.330408649970074

Epoch: 1035, iteration: 0
Autoencoder Loss: 0.0006417605909518898
Discriminator Loss: 0.7658848166465759
Generator Loss: 0.6103236079216003
1:20.513493644307964

Epoch: 1040, iteration: 0
Autoencoder Loss: 0.0006727781728841364
Discriminator Loss: 0.670166552066803
Generator Loss: 0.7447868585586548
1:20.408800082918134

Epoch: 1045, iteration: 0
Autoencoder Loss: 0.0006275461055338383
Discriminator Loss: 0.7634799480438232
Generator Loss: 0.5492835640907288
1:20.516431249745622

Epoch: 1050, iteration: 0
Autoencoder Loss: 0.0007490942371077836
Discriminator Loss: 0.7487539052963257
Generator Loss: 0.7078656554222107
1:20.690234588188233

Epoch: 1055, iteration: 0
Autoencoder Loss: 0.0006703560356982052
Discriminator Loss: 0.7844470143318176
Generator Loss: 0.7166847586631775
1:20.408527125148733

Epoch: 1060, iteration: 0
Autoencoder Loss: 0.0006057382561266422
Discriminator Loss: 0.755037248134613
Generator Loss: 0.645982027053833
1:20.486910781137503

Epoch: 1065, iteration: 0
Autoencoder Loss: 0.000619670725427568
Discriminator Loss: 0.732303261756897
Generator Loss: 0.6029953360557556
1:20.63256044516157

Epoch: 1070, iteration: 0
Autoencoder Loss: 0.0006553213461302221
Discriminator Loss: 0.6713951826095581
Generator Loss: 0.7500514388084412
1:20.39087267694488

Epoch: 1075, iteration: 0
Autoencoder Loss: 0.0006511578103527427
Discriminator Loss: 0.6961532831192017
Generator Loss: 0.7912431955337524
1:20.383366773703223

Epoch: 1080, iteration: 0
Autoencoder Loss: 0.0007334997062571347
Discriminator Loss: 0.7725996971130371
Generator Loss: 0.7121762037277222
1:20.505852196248156

Epoch: 1085, iteration: 0
Autoencoder Loss: 0.0006502016331069171
Discriminator Loss: 0.7546215057373047
Generator Loss: 0.6311704516410828
1:20.459020280265598

Epoch: 1090, iteration: 0
Autoencoder Loss: 0.0006418488337658346
Discriminator Loss: 0.7036901712417603
Generator Loss: 0.7016920447349548
1:20.5186848193018

Epoch: 1095, iteration: 0
Autoencoder Loss: 0.0005816203192807734
Discriminator Loss: 0.7211357355117798
Generator Loss: 0.6139890551567078
1:20.358830859237052

Epoch: 1100, iteration: 0
Autoencoder Loss: 0.0006797148962505162
Discriminator Loss: 0.757320761680603
Generator Loss: 0.5890856981277466
1:20.313110971457263

Epoch: 1105, iteration: 0
Autoencoder Loss: 0.0007282746955752373
Discriminator Loss: 0.6544236540794373
Generator Loss: 0.9826275110244751
1:20.404648398076077

Epoch: 1110, iteration: 0
Autoencoder Loss: 0.0006216213223524392
Discriminator Loss: 0.7535707354545593
Generator Loss: 0.6187024712562561
1:20.45196822014717

Epoch: 1115, iteration: 0
Autoencoder Loss: 0.0005718186148442328
Discriminator Loss: 0.7230680584907532
Generator Loss: 0.6033761501312256
1:20.66044169495388

Epoch: 1120, iteration: 0
Autoencoder Loss: 0.000589604489505291
Discriminator Loss: 0.7096605896949768
Generator Loss: 0.6197071671485901
1:20.646369837679014

Epoch: 1125, iteration: 0
Autoencoder Loss: 0.0008217438007704914
Discriminator Loss: 0.7431033849716187
Generator Loss: 0.7280328273773193
1:19.859855558800014

Epoch: 1130, iteration: 0
Autoencoder Loss: 0.0007622588309459388
Discriminator Loss: 0.8188133239746094
Generator Loss: 0.8068546652793884
1:20.6419899851154

Epoch: 1135, iteration: 0
Autoencoder Loss: 0.0005819895886816084
Discriminator Loss: 0.8098775148391724
Generator Loss: 0.6122360229492188
1:20.45572288514988

Epoch: 1140, iteration: 0
Autoencoder Loss: 0.0005576570983976126
Discriminator Loss: 0.6937127113342285
Generator Loss: 0.6365439295768738
1:20.60543773290979

Epoch: 1145, iteration: 0
Autoencoder Loss: 0.0006307892617769539
Discriminator Loss: 0.648465096950531
Generator Loss: 0.6030494570732117
1:20.437598990073667

Epoch: 1150, iteration: 0
Autoencoder Loss: 0.0006885227630846202
Discriminator Loss: 0.7055295705795288
Generator Loss: 0.6481953859329224
1:20.498357111672494

Epoch: 1155, iteration: 0
Autoencoder Loss: 0.0013310271315276623
Discriminator Loss: 0.7761957049369812
Generator Loss: 1.329796314239502
1:20.897606095570374

Epoch: 1160, iteration: 0
Autoencoder Loss: 0.0006462843157351017
Discriminator Loss: 0.8801369667053223
Generator Loss: 0.6945502758026123
1:20.714250334875175

Epoch: 1165, iteration: 0
Autoencoder Loss: 0.0006930310628376901
Discriminator Loss: 0.7998298406600952
Generator Loss: 0.607496976852417
1:20.570017087567866

Epoch: 1170, iteration: 0
Autoencoder Loss: 0.000575500656850636
Discriminator Loss: 0.7108791470527649
Generator Loss: 0.6563428640365601
1:20.63240118356608

Epoch: 1175, iteration: 0
Autoencoder Loss: 0.000698420568369329
Discriminator Loss: 0.7087793350219727
Generator Loss: 0.5703141689300537
1:20.63993171310966

Epoch: 1180, iteration: 0
Autoencoder Loss: 0.0007565714768134058
Discriminator Loss: 0.6191651821136475
Generator Loss: 0.8865852952003479
1:20.17529045798911

Epoch: 1185, iteration: 0
Autoencoder Loss: 0.0006913277320563793
Discriminator Loss: 0.7567890882492065
Generator Loss: 0.617103099822998
1:20.512357487545113

Epoch: 1190, iteration: 0
Autoencoder Loss: 0.0007105754921212792
Discriminator Loss: 0.7424979209899902
Generator Loss: 0.7094240188598633
1:20.31783517857269

Epoch: 1195, iteration: 0
Autoencoder Loss: 0.000677631760481745
Discriminator Loss: 0.7867258787155151
Generator Loss: 0.6921190023422241
1:20.706051713415047

Epoch: 1200, iteration: 0
Autoencoder Loss: 0.000653378083370626
Discriminator Loss: 0.7907712459564209
Generator Loss: 0.6453772783279419
1:20.623347763436783

Epoch: 1205, iteration: 0
Autoencoder Loss: 0.0006208185805007815
Discriminator Loss: 0.7475111484527588
Generator Loss: 0.6001175045967102
1:20.617508998787667

Epoch: 1210, iteration: 0
Autoencoder Loss: 0.0006002312293276191
Discriminator Loss: 0.6536505222320557
Generator Loss: 0.7073444128036499
1:20.441553762573747

Epoch: 1215, iteration: 0
Autoencoder Loss: 0.0006543593481183052
Discriminator Loss: 0.7014790773391724
Generator Loss: 0.5964597463607788
1:20.44467855710429

Epoch: 1220, iteration: 0
Autoencoder Loss: 0.0007918225019238889
Discriminator Loss: 0.7039119005203247
Generator Loss: 0.9097276329994202
1:20.392380580231055

Epoch: 1225, iteration: 0
Autoencoder Loss: 0.0006663667154498398
Discriminator Loss: 0.8250242471694946
Generator Loss: 0.5689213275909424
1:20.566601430371954

Epoch: 1230, iteration: 0
Autoencoder Loss: 0.0006872504018247128
Discriminator Loss: 0.7639300227165222
Generator Loss: 0.6446337103843689
1:20.614771067588652

Epoch: 1235, iteration: 0
Autoencoder Loss: 0.0006822867435403168
Discriminator Loss: 0.7489782571792603
Generator Loss: 0.6653289794921875
1:20.4777667753092

Epoch: 1240, iteration: 0
Autoencoder Loss: 0.0007315100519917905
Discriminator Loss: 0.7731055021286011
Generator Loss: 0.6331700086593628
1:20.433591735690243

Epoch: 1245, iteration: 0
Autoencoder Loss: 0.0006610286072827876
Discriminator Loss: 0.7321712970733643
Generator Loss: 0.6749133467674255
1:20.51847996966455

Epoch: 1250, iteration: 0
Autoencoder Loss: 0.0006294030463322997
Discriminator Loss: 0.69730144739151
Generator Loss: 0.6588503122329712
1:20.65084693810872

Epoch: 1255, iteration: 0
Autoencoder Loss: 0.0006421069265343249
Discriminator Loss: 0.7162684202194214
Generator Loss: 0.5808895230293274
1:20.552248259030712

Epoch: 1260, iteration: 0
Autoencoder Loss: 0.0008003999246284366
Discriminator Loss: 0.7278298139572144
Generator Loss: 0.7789359092712402
1:20.238095302780476

Epoch: 1265, iteration: 0
Autoencoder Loss: 0.0007170442258939147
Discriminator Loss: 0.8250764608383179
Generator Loss: 0.7361839413642883
1:20.722261792378212

Epoch: 1270, iteration: 0
Autoencoder Loss: 0.0006180817144922912
Discriminator Loss: 0.7782280445098877
Generator Loss: 0.6247972249984741
1:20.586719108376187

Epoch: 1275, iteration: 0
Autoencoder Loss: 0.0006801981362514198
Discriminator Loss: 0.7385165691375732
Generator Loss: 0.5979918241500854
1:20.48137077688686

Epoch: 1280, iteration: 0
Autoencoder Loss: 0.0006151560228317976
Discriminator Loss: 0.6989424228668213
Generator Loss: 0.6275678873062134
1:20.327287232246555

Epoch: 1285, iteration: 0
Autoencoder Loss: 0.0006278934306465089
Discriminator Loss: 0.7084930539131165
Generator Loss: 0.5999773144721985
1:20.177536749788246

Epoch: 1290, iteration: 0
Autoencoder Loss: 0.0007843574858270586
Discriminator Loss: 0.8238774538040161
Generator Loss: 0.6517494320869446
1:20.330701278205208

Epoch: 1295, iteration: 0
Autoencoder Loss: 0.0006824162555858493
Discriminator Loss: 0.8099246621131897
Generator Loss: 0.7034884095191956
1:20.353421625975464

Epoch: 1300, iteration: 0
Autoencoder Loss: 0.0006489905645139515
Discriminator Loss: 0.7803313732147217
Generator Loss: 0.6378368735313416
1:20.56186254619697

Epoch: 1305, iteration: 0
Autoencoder Loss: 0.0006310400203801692
Discriminator Loss: 0.7114769220352173
Generator Loss: 0.689465343952179
1:20.364467236562838

Epoch: 1310, iteration: 0
Autoencoder Loss: 0.0005542262806557119
Discriminator Loss: 0.7093102931976318
Generator Loss: 0.6410279273986816
1:20.364727325603887

Epoch: 1315, iteration: 0
Autoencoder Loss: 0.0006095287972129881
Discriminator Loss: 0.7137255668640137
Generator Loss: 0.6186858415603638
1:20.482738205714934

Epoch: 1320, iteration: 0
Autoencoder Loss: 0.000711646513082087
Discriminator Loss: 0.6780185699462891
Generator Loss: 0.7253379225730896
1:20.430541194057056

Epoch: 1325, iteration: 0
Autoencoder Loss: 0.0009294631890952587
Discriminator Loss: 0.7575842142105103
Generator Loss: 0.770750880241394
1:20.316637206575372

Epoch: 1330, iteration: 0
Autoencoder Loss: 0.0005696569569408894
Discriminator Loss: 0.8265823125839233
Generator Loss: 0.6460770964622498
1:20.53009477700339

Epoch: 1335, iteration: 0
Autoencoder Loss: 0.0006911060190759599
Discriminator Loss: 0.770717442035675
Generator Loss: 0.6126827001571655
1:20.510882974684325

Epoch: 1340, iteration: 0
Autoencoder Loss: 0.0006051500095054507
Discriminator Loss: 0.7055133581161499
Generator Loss: 0.7191036343574524
1:20.406975773717527

Epoch: 1345, iteration: 0
Autoencoder Loss: 0.000650467409286648
Discriminator Loss: 0.8565901517868042
Generator Loss: 0.4770621359348297
1:20.431597754886447

Epoch: 1350, iteration: 0
Autoencoder Loss: 0.0006777083617635071
Discriminator Loss: 0.7643088102340698
Generator Loss: 0.6229416728019714
1:20.545734074244866

Epoch: 1355, iteration: 0
Autoencoder Loss: 0.0006472381064668298
Discriminator Loss: 0.7388187646865845
Generator Loss: 0.7388672232627869
1:20.075277463617894

Epoch: 1360, iteration: 0
Autoencoder Loss: 0.0006141458870843053
Discriminator Loss: 0.7562950849533081
Generator Loss: 0.6420268416404724
1:20.417851492944262

Epoch: 1365, iteration: 0
Autoencoder Loss: 0.0006653178716078401
Discriminator Loss: 0.7474442720413208
Generator Loss: 0.6101633906364441
1:20.316790573067365

Epoch: 1370, iteration: 0
Autoencoder Loss: 0.0007133480976335704
Discriminator Loss: 0.7974945306777954
Generator Loss: 0.5924660563468933
1:20.249319085116166

Epoch: 1375, iteration: 0
Autoencoder Loss: 0.0006558774621225893
Discriminator Loss: 0.8007131814956665
Generator Loss: 0.6968305110931396
1:20.576025734332216

Epoch: 1380, iteration: 0
Autoencoder Loss: 0.0006187443505041301
Discriminator Loss: 0.7349311709403992
Generator Loss: 0.6887043118476868
1:20.518324126261152

Epoch: 1385, iteration: 0
Autoencoder Loss: 0.000621199666056782
Discriminator Loss: 0.7293384075164795
Generator Loss: 0.5476056933403015
1:20.379913256229546

Epoch: 1390, iteration: 0
Autoencoder Loss: 0.000605342211201787
Discriminator Loss: 0.6667815446853638
Generator Loss: 0.6166579127311707
1:20.536242114473385

Epoch: 1395, iteration: 0
Autoencoder Loss: 0.0007925215759314597
Discriminator Loss: 0.6936731338500977
Generator Loss: 0.7446163892745972
1:20.666221165877726

Epoch: 1400, iteration: 0
Autoencoder Loss: 0.0007769276853650808
Discriminator Loss: 0.775731086730957
Generator Loss: 0.8044094443321228
1:20.27428445243496

Epoch: 1405, iteration: 0
Autoencoder Loss: 0.00058352155610919
Discriminator Loss: 0.8253796100616455
Generator Loss: 0.6394008994102478
1:20.544309224372853

Epoch: 1410, iteration: 0
Autoencoder Loss: 0.0006033953395672143
Discriminator Loss: 0.7955990433692932
Generator Loss: 0.5520036220550537
1:20.268052506314763

Epoch: 1415, iteration: 0
Autoencoder Loss: 0.0006247760611586273
Discriminator Loss: 0.7123725414276123
Generator Loss: 0.6373043060302734
1:20.20655196809683

Epoch: 1420, iteration: 0
Autoencoder Loss: 0.0006318176747299731
Discriminator Loss: 0.7079683542251587
Generator Loss: 0.6383717060089111
1:20.411754238279308

Epoch: 1425, iteration: 0
Autoencoder Loss: 0.0007569526205770671
Discriminator Loss: 0.6782540082931519
Generator Loss: 0.9408662915229797
1:19.988515191438697

Epoch: 1430, iteration: 0
Autoencoder Loss: 0.0006526430370286107
Discriminator Loss: 0.803305983543396
Generator Loss: 0.6663129925727844
1:20.392458332754956

Epoch: 1435, iteration: 0
Autoencoder Loss: 0.0005913880304433405
Discriminator Loss: 0.8036871552467346
Generator Loss: 0.5976214408874512
1:20.5218797483456

Epoch: 1440, iteration: 0
Autoencoder Loss: 0.0006305694696493447
Discriminator Loss: 0.7147277593612671
Generator Loss: 0.7358627319335938
1:20.388246631038548

Epoch: 1445, iteration: 0
Autoencoder Loss: 0.0006661670631729066
Discriminator Loss: 0.7310760021209717
Generator Loss: 0.6799074411392212
1:20.59188893497957

Epoch: 1450, iteration: 0
Autoencoder Loss: 0.0005905719590373337
Discriminator Loss: 0.7400221824645996
Generator Loss: 0.5885949730873108
1:20.297115575736907

Epoch: 1455, iteration: 0
Autoencoder Loss: 0.0006604535155929625
Discriminator Loss: 0.7372076511383057
Generator Loss: 0.637778639793396
1:20.416940784940103

Epoch: 1460, iteration: 0
Autoencoder Loss: 0.0007000816403888166
Discriminator Loss: 0.8432497978210449
Generator Loss: 0.5730371475219727
1:20.04041508355099

Epoch: 1465, iteration: 0
Autoencoder Loss: 0.0005521950661204755
Discriminator Loss: 0.8099986910820007
Generator Loss: 0.6203205585479736
1:20.323028765489063

Epoch: 1470, iteration: 0
Autoencoder Loss: 0.0005716801970265806
Discriminator Loss: 0.7281111478805542
Generator Loss: 0.6097331047058105
1:20.209969542406853

Epoch: 1475, iteration: 0
Autoencoder Loss: 0.000616079312749207
Discriminator Loss: 0.6800762414932251
Generator Loss: 0.6583862900733948
1:20.275213396606027

Epoch: 1480, iteration: 0
Autoencoder Loss: 0.000639383215457201
Discriminator Loss: 0.7190753221511841
Generator Loss: 0.6400339007377625
1:20.324885109895284

Epoch: 1485, iteration: 0
Autoencoder Loss: 0.0006590633420273662
Discriminator Loss: 0.7078402042388916
Generator Loss: 0.8902221918106079
1:20.409206177589134

Epoch: 1490, iteration: 0
Autoencoder Loss: 0.0006459913565777242
Discriminator Loss: 0.764363169670105
Generator Loss: 0.6312808990478516
1:20.48956599778098

Epoch: 1495, iteration: 0
Autoencoder Loss: 0.0006493543623946607
Discriminator Loss: 0.7220215797424316
Generator Loss: 0.689425528049469
1:20.422743777064515

Epoch: 1500, iteration: 0
Autoencoder Loss: 0.0005605539190582931
Discriminator Loss: 0.7326104640960693
Generator Loss: 0.6473272442817688
1:20.341215565815563

Epoch: 1505, iteration: 0
Autoencoder Loss: 0.0006089867674745619
Discriminator Loss: 0.707587718963623
Generator Loss: 0.5785664319992065
1:20.46227486358081

Epoch: 1510, iteration: 0
Autoencoder Loss: 0.0006458254065364599
Discriminator Loss: 0.7385338544845581
Generator Loss: 0.5644673109054565
1:20.261566685128773

Epoch: 1515, iteration: 0
Autoencoder Loss: 0.0008026417344808578
Discriminator Loss: 0.7668502926826477
Generator Loss: 0.7692133784294128
1:20.004462978450267

Epoch: 1520, iteration: 0
Autoencoder Loss: 0.000585269124712795
Discriminator Loss: 0.8656885623931885
Generator Loss: 0.6028385758399963
1:20.296079249493467

Epoch: 1525, iteration: 0
Autoencoder Loss: 0.0006282312679104507
Discriminator Loss: 0.7618221044540405
Generator Loss: 0.6531943678855896
1:20.2551348012112

Epoch: 1530, iteration: 0
Autoencoder Loss: 0.0005799320060759783
Discriminator Loss: 0.7240427732467651
Generator Loss: 0.6156104207038879
1:20.28161065528856

Epoch: 1535, iteration: 0
Autoencoder Loss: 0.0006382891442626715
Discriminator Loss: 0.7030804753303528
Generator Loss: 0.6647825837135315
1:20.195630535373155

Epoch: 1540, iteration: 0
Autoencoder Loss: 0.0007047833641991019
Discriminator Loss: 0.6606879234313965
Generator Loss: 1.0138870477676392
1:20.185210361825412

Epoch: 1545, iteration: 0
Autoencoder Loss: 0.000672713911626488
Discriminator Loss: 0.7886228561401367
Generator Loss: 0.7470314502716064
1:20.525958280887785

Epoch: 1550, iteration: 0
Autoencoder Loss: 0.0005814378382638097
Discriminator Loss: 0.7593801021575928
Generator Loss: 0.6385650634765625
1:20.410420465523906

Epoch: 1555, iteration: 0
Autoencoder Loss: 0.0006055852863937616
Discriminator Loss: 0.6752442121505737
Generator Loss: 0.7209041714668274
1:20.492707908948418

Epoch: 1560, iteration: 0
Autoencoder Loss: 0.0007189828320406377
Discriminator Loss: 0.7102044820785522
Generator Loss: 0.7082805037498474
1:20.213761806367234

Epoch: 1565, iteration: 0
Autoencoder Loss: 0.0007202908163890243
Discriminator Loss: 0.7620949149131775
Generator Loss: 0.7691487669944763
1:20.51438244935611

Epoch: 1570, iteration: 0
Autoencoder Loss: 0.0006369579932652414
Discriminator Loss: 0.7391008138656616
Generator Loss: 0.6841859817504883
1:20.59481065245275

Epoch: 1575, iteration: 0
Autoencoder Loss: 0.000599407241679728
Discriminator Loss: 0.6848850250244141
Generator Loss: 0.6263958215713501
1:20.45004293513034

Epoch: 1580, iteration: 0
Autoencoder Loss: 0.0006005663308314979
Discriminator Loss: 0.6580543518066406
Generator Loss: 0.5990626811981201
1:20.296354444143745

Epoch: 1585, iteration: 0
Autoencoder Loss: 0.003413406666368246
Discriminator Loss: 0.6625926494598389
Generator Loss: 1.1144320964813232
1:20.826799244401254

Epoch: 1590, iteration: 0
Autoencoder Loss: 0.0006910418160259724
Discriminator Loss: 0.9182947278022766
Generator Loss: 0.6739092469215393
1:20.457884148052926

Epoch: 1595, iteration: 0
Autoencoder Loss: 0.0006082570762373507
Discriminator Loss: 0.8133523464202881
Generator Loss: 0.68206787109375
1:20.27691047506441

Epoch: 1600, iteration: 0
Autoencoder Loss: 0.0005941297858953476
Discriminator Loss: 0.7585287094116211
Generator Loss: 0.6270246505737305
1:20.395656782613997

Epoch: 1605, iteration: 0
Autoencoder Loss: 0.000598010781686753
Discriminator Loss: 0.7248657941818237
Generator Loss: 0.5974541902542114
1:20.462845114747456

Epoch: 1610, iteration: 0
Autoencoder Loss: 0.0006075915298424661
Discriminator Loss: 0.7175548076629639
Generator Loss: 0.5864344239234924
1:20.468222984506443

Epoch: 1615, iteration: 0
Autoencoder Loss: 0.0006985811633057892
Discriminator Loss: 0.7318557500839233
Generator Loss: 0.5929468274116516
1:20.143005441401694

Epoch: 1620, iteration: 0
Autoencoder Loss: 0.000723078497685492
Discriminator Loss: 0.7423217296600342
Generator Loss: 0.6864703297615051
1:20.409666479524525

Epoch: 1625, iteration: 0
Autoencoder Loss: 0.0006540700560435653
Discriminator Loss: 0.7509994506835938
Generator Loss: 0.7012940645217896
1:20.28466126388502

Epoch: 1630, iteration: 0
Autoencoder Loss: 0.0006767871091142297
Discriminator Loss: 0.8026883602142334
Generator Loss: 0.6144534349441528
1:20.285896346234694

Epoch: 1635, iteration: 0
Autoencoder Loss: 0.0005924921133555472
Discriminator Loss: 0.7426987886428833
Generator Loss: 0.68289715051651
1:20.39844092296002

Epoch: 1640, iteration: 0
Autoencoder Loss: 0.0005978510016575456
Discriminator Loss: 0.7327014207839966
Generator Loss: 0.5862341523170471
1:20.427627340459125

Epoch: 1645, iteration: 0
Autoencoder Loss: 0.0007579447701573372
Discriminator Loss: 0.7353185415267944
Generator Loss: 0.6490445137023926
1:20.1236512066819

Epoch: 1650, iteration: 0
Autoencoder Loss: 0.0006846002652309835
Discriminator Loss: 0.8089529275894165
Generator Loss: 0.6640406847000122
1:20.499249882666252

Epoch: 1655, iteration: 0
Autoencoder Loss: 0.0005894495407119393
Discriminator Loss: 0.7835602164268494
Generator Loss: 0.6567593812942505
1:20.40900319833833

Epoch: 1660, iteration: 0
Autoencoder Loss: 0.0006585966912098229
Discriminator Loss: 0.764710545539856
Generator Loss: 0.6246231198310852
1:20.51369138154817

Epoch: 1665, iteration: 0
Autoencoder Loss: 0.0006480615120381117
Discriminator Loss: 0.7084325551986694
Generator Loss: 0.6836829781532288
1:20.382884946469638

Epoch: 1670, iteration: 0
Autoencoder Loss: 0.0006200827192515135
Discriminator Loss: 0.675701379776001
Generator Loss: 0.7170049548149109
1:20.097588971992963

Epoch: 1675, iteration: 0
Autoencoder Loss: 0.0006958339363336563
Discriminator Loss: 0.7130109071731567
Generator Loss: 0.7605471014976501
1:20.407124164754748

Epoch: 1680, iteration: 0
Autoencoder Loss: 0.0006318683736026287
Discriminator Loss: 0.7705553770065308
Generator Loss: 0.6433457136154175
1:20.335620426544633

Epoch: 1685, iteration: 0
Autoencoder Loss: 0.0007157100480981171
Discriminator Loss: 0.7732776403427124
Generator Loss: 0.6051639318466187
1:20.38870236188398

Epoch: 1690, iteration: 0
Autoencoder Loss: 0.000596835627220571
Discriminator Loss: 0.7562140822410583
Generator Loss: 0.6209926605224609
1:20.499920264365493

Epoch: 1695, iteration: 0
Autoencoder Loss: 0.0006193763110786676
Discriminator Loss: 0.7166163325309753
Generator Loss: 0.6563652157783508
1:20.55383205733871

Epoch: 1700, iteration: 0
Autoencoder Loss: 0.0006176565075293183
Discriminator Loss: 0.6968181729316711
Generator Loss: 0.6363006234169006
1:20.530942419188627

Epoch: 1705, iteration: 0
Autoencoder Loss: 0.0006042252643965185
Discriminator Loss: 0.6813177466392517
Generator Loss: 0.6189982891082764
1:20.321076452030663

Epoch: 1710, iteration: 0
Autoencoder Loss: 0.0008168499334715307
Discriminator Loss: 0.715612530708313
Generator Loss: 0.7085815668106079
1:20.21487100768034

Epoch: 1715, iteration: 0
Autoencoder Loss: 0.000979147618636489
Discriminator Loss: 0.8475693464279175
Generator Loss: 0.8359929323196411
1:20.474328758720823

Epoch: 1720, iteration: 0
Autoencoder Loss: 0.0006528540980070829
Discriminator Loss: 0.8284062147140503
Generator Loss: 0.6519033312797546
1:20.56164656334996

Epoch: 1725, iteration: 0
Autoencoder Loss: 0.0005969141493551433
Discriminator Loss: 0.7353948950767517
Generator Loss: 0.6469234824180603
1:20.53021386842106

Epoch: 1730, iteration: 0
Autoencoder Loss: 0.0005828284774906933
Discriminator Loss: 0.6903142929077148
Generator Loss: 0.6167879700660706
1:20.416540815531352

Epoch: 1735, iteration: 0
Autoencoder Loss: 0.0006729405140504241
Discriminator Loss: 0.6996405124664307
Generator Loss: 0.5889878273010254
1:20.270204798142487

Epoch: 1740, iteration: 0
Autoencoder Loss: 0.000723716919310391
Discriminator Loss: 0.723743200302124
Generator Loss: 0.6896370649337769
1:20.186339521937583

Epoch: 1745, iteration: 0
Autoencoder Loss: 0.0006586239906027913
Discriminator Loss: 0.7567884922027588
Generator Loss: 0.7038620114326477
1:20.353499228269317

Epoch: 1750, iteration: 0
Autoencoder Loss: 0.0006030529038980603
Discriminator Loss: 0.7662757635116577
Generator Loss: 0.6476426124572754
1:20.342558682991164

Epoch: 1755, iteration: 0
Autoencoder Loss: 0.0006156776798889041
Discriminator Loss: 0.7254478931427002
Generator Loss: 0.6565111875534058
1:20.351081646378827

Epoch: 1760, iteration: 0
Autoencoder Loss: 0.0005694204592145979
Discriminator Loss: 0.7339011430740356
Generator Loss: 0.5590598583221436
1:20.244335603229917

Epoch: 1765, iteration: 0
Autoencoder Loss: 0.0006960021564736962
Discriminator Loss: 0.6699928045272827
Generator Loss: 0.8218552470207214
1:20.286974421122

Epoch: 1770, iteration: 0
Autoencoder Loss: 0.0006415077368728817
Discriminator Loss: 0.8164798021316528
Generator Loss: 0.580801248550415
1:20.37115370495335

Epoch: 1775, iteration: 0
Autoencoder Loss: 0.0006555311847478151
Discriminator Loss: 0.7478868365287781
Generator Loss: 0.7097987532615662
1:20.393883068409863

Epoch: 1780, iteration: 0
Autoencoder Loss: 0.0005786335677839816
Discriminator Loss: 0.7583835124969482
Generator Loss: 0.5539389252662659
1:20.30714384126067

Epoch: 1785, iteration: 0
Autoencoder Loss: 0.000645614112727344
Discriminator Loss: 0.6744731664657593
Generator Loss: 0.7589907646179199
1:20.446897687057465

Epoch: 1790, iteration: 0
Autoencoder Loss: 0.0008072223863564432
Discriminator Loss: 0.6732233762741089
Generator Loss: 1.0110106468200684
1:20.18373202933286

Epoch: 1795, iteration: 0
Autoencoder Loss: 0.0006175569142214954
Discriminator Loss: 0.7945054769515991
Generator Loss: 0.6379528641700745
1:20.457123979849317

Epoch: 1800, iteration: 0
Autoencoder Loss: 0.0005973164224997163
Discriminator Loss: 0.735910177230835
Generator Loss: 0.6392384767532349
1:20.562597183196605

Epoch: 1805, iteration: 0
Autoencoder Loss: 0.0005853170296177268
Discriminator Loss: 0.6970705986022949
Generator Loss: 0.6410863995552063
1:20.375939715844773

Epoch: 1810, iteration: 0
Autoencoder Loss: 0.000561364518944174
Discriminator Loss: 0.7012764811515808
Generator Loss: 0.6084869503974915
1:20.312206632717718

Epoch: 1815, iteration: 0
Autoencoder Loss: 0.0007874844595789909
Discriminator Loss: 0.7210644483566284
Generator Loss: 0.7354552149772644
1:20.436803392634836

Epoch: 1820, iteration: 0
Autoencoder Loss: 0.0008398240897804499
Discriminator Loss: 0.7432467937469482
Generator Loss: 0.84185391664505
1:20.46706514734916

Epoch: 1825, iteration: 0
Autoencoder Loss: 0.0006016790866851807
Discriminator Loss: 0.7901666760444641
Generator Loss: 0.6375856399536133
1:20.49176414623188

Epoch: 1830, iteration: 0
Autoencoder Loss: 0.0005822203820571303
Discriminator Loss: 0.7407366633415222
Generator Loss: 0.6136339902877808
1:20.40886741655114

Epoch: 1835, iteration: 0
Autoencoder Loss: 0.0005350052379071712
Discriminator Loss: 0.7329049110412598
Generator Loss: 0.5810399055480957
1:20.39773431063853

Epoch: 1840, iteration: 0
Autoencoder Loss: 0.000731229898519814
Discriminator Loss: 0.78693687915802
Generator Loss: 0.7041515111923218
1:20.44985376473949

Epoch: 1845, iteration: 0
Autoencoder Loss: 0.0006136364536359906
Discriminator Loss: 0.7849789261817932
Generator Loss: 0.6243548393249512
1:20.574179081235563

Epoch: 1850, iteration: 0
Autoencoder Loss: 0.0006214301683939993
Discriminator Loss: 0.715770959854126
Generator Loss: 0.6960116028785706
1:20.36559296816964

Epoch: 1855, iteration: 0
Autoencoder Loss: 0.0005626954953186214
Discriminator Loss: 0.6849684715270996
Generator Loss: 0.6785613298416138
1:20.297264920708642

Epoch: 1860, iteration: 0
Autoencoder Loss: 0.0005894424975849688
Discriminator Loss: 0.7494652271270752
Generator Loss: 0.5183002352714539
1:20.329581437592886

Epoch: 1865, iteration: 0
Autoencoder Loss: 0.0007484981324523687
Discriminator Loss: 0.6436139345169067
Generator Loss: 1.1396788358688354
1:20.264146248206693

Epoch: 1870, iteration: 0
Autoencoder Loss: 0.0006074256380088627
Discriminator Loss: 0.8827698230743408
Generator Loss: 0.6199909448623657
1:20.557115325622306

Epoch: 1875, iteration: 0
Autoencoder Loss: 0.000617886136751622
Discriminator Loss: 0.7928228974342346
Generator Loss: 0.6809728741645813
1:20.45988935960393

Epoch: 1880, iteration: 0
Autoencoder Loss: 0.000615992525126785
Discriminator Loss: 0.7353484630584717
Generator Loss: 0.6324096918106079
1:20.518387995481717

Epoch: 1885, iteration: 0
Autoencoder Loss: 0.0006364816799759865
Discriminator Loss: 0.7064860463142395
Generator Loss: 0.6780240535736084
1:20.421158560770074

Epoch: 1890, iteration: 0
Autoencoder Loss: 0.0006619851337745786
Discriminator Loss: 0.7231417894363403
Generator Loss: 0.6239927411079407
1:20.479943606038514

Epoch: 1895, iteration: 0
Autoencoder Loss: 0.0006677822675555944
Discriminator Loss: 0.7059913873672485
Generator Loss: 0.6437973976135254
1:20.57950131435113

Epoch: 1900, iteration: 0
Autoencoder Loss: 0.0006563640781678259
Discriminator Loss: 0.6891114115715027
Generator Loss: 0.7006775140762329
1:20.18724709058409

Epoch: 1905, iteration: 0
Autoencoder Loss: 0.0007495710160583258
Discriminator Loss: 0.7013503313064575
Generator Loss: 0.8727056384086609
1:20.319869892944634

Epoch: 1910, iteration: 0
Autoencoder Loss: 0.0006505726487375796
Discriminator Loss: 0.8184573650360107
Generator Loss: 0.639703631401062
1:20.41443367879839

Epoch: 1915, iteration: 0
Autoencoder Loss: 0.0005555834504775703
Discriminator Loss: 0.7627888917922974
Generator Loss: 0.6325934529304504
1:20.27524227689499

Epoch: 1920, iteration: 0
Autoencoder Loss: 0.0005979198613204062
Discriminator Loss: 0.7271279692649841
Generator Loss: 0.644766628742218
1:20.31358394444277

Epoch: 1925, iteration: 0
Autoencoder Loss: 0.0005769474082626402
Discriminator Loss: 0.7049446105957031
Generator Loss: 0.6476800441741943
1:20.437057288422608

Epoch: 1930, iteration: 0
Autoencoder Loss: 0.0006700371741317213
Discriminator Loss: 0.8251162767410278
Generator Loss: 0.5079354047775269
1:20.11806415498057

Epoch: 1935, iteration: 0
Autoencoder Loss: 0.0006585943046957254
Discriminator Loss: 0.7647777795791626
Generator Loss: 0.7163400053977966
1:20.34222498482157

Epoch: 1940, iteration: 0
Autoencoder Loss: 0.0006150074186734855
Discriminator Loss: 0.7810940742492676
Generator Loss: 0.5759580135345459
1:20.4817504469807

Epoch: 1945, iteration: 0
Autoencoder Loss: 0.0005346211837604642
Discriminator Loss: 0.7512446641921997
Generator Loss: 0.6529449820518494
1:20.414602351123598

Epoch: 1950, iteration: 0
Autoencoder Loss: 0.000562718661967665
Discriminator Loss: 0.7096601724624634
Generator Loss: 0.6275070309638977
1:20.362214774073397

Epoch: 1955, iteration: 0
Autoencoder Loss: 0.0006759557290934026
Discriminator Loss: 0.7886805534362793
Generator Loss: 0.535923957824707
1:20.52537692275038

Epoch: 1960, iteration: 0
Autoencoder Loss: 0.0006439514108933508
Discriminator Loss: 0.7676256895065308
Generator Loss: 0.6688352227210999
1:20.26308846255133

Epoch: 1965, iteration: 0
Autoencoder Loss: 0.0006262371316552162
Discriminator Loss: 0.7656758427619934
Generator Loss: 0.6960217952728271
1:20.551622955513004

Epoch: 1970, iteration: 0
Autoencoder Loss: 0.0005061536794528365
Discriminator Loss: 0.7300567626953125
Generator Loss: 0.619692325592041
1:20.488146707964667

